{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbecb334-de9e-40e3-8cbe-4beaf9eb4c2c",
   "metadata": {},
   "source": [
    "\n",
    "FinTech Data Generator - Week 1 Sprint 0\n",
    "========================================\n",
    "\n",
    "This notebook creates realistic financial datasets for our 11-week FinTech project.\n",
    "We'll generate stock prices, crypto data, economic indicators, portfolio holdings, \n",
    "and customer demographics that mirror real-world financial data patterns.\n",
    "\n",
    "Learning Objectives:\n",
    "- Understand financial data structures (OHLCV format)\n",
    "- Learn about time series data generation using statistical models\n",
    "- Practice working with pandas DataFrames\n",
    "- Set up reproducible data pipelines using random seeds\n",
    "\n",
    "Key Concepts:\n",
    "- Geometric Brownian Motion for price modeling\n",
    "- Log-normal distributions for financial variables\n",
    "- Time series patterns and volatility clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd8ba87-4a55-49bc-ae7c-a34a2f400ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ðŸ“Š Ready to generate realistic financial datasets for our FinTech project\n",
      "ðŸŽ¯ This data will support all 11 weeks of our Agile development sprints\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports for data manipulation and file operations\n",
    "import pandas as pd              # Data manipulation and analysis\n",
    "import numpy as np              # Numerical computing and random number generation\n",
    "from datetime import datetime, timedelta  # Date and time handling\n",
    "import random                   # Additional random number generation\n",
    "import os                      # Operating system interface for file operations\n",
    "from typing import Tuple, List, Dict  # Type hints for better code documentation\n",
    "\n",
    "# Display settings for better output formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ðŸ“Š Ready to generate realistic financial datasets for our FinTech project\")\n",
    "print(\"ðŸŽ¯ This data will support all 11 weeks of our Agile development sprints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8954f-a918-4a54-b87a-03542aeeb2f8",
   "metadata": {},
   "source": [
    "Class-Based Data Generation Architecture\n",
    "=======================================\n",
    "\n",
    "We use Object-Oriented Programming (OOP) to organize our data generation logic.\n",
    "The FinancialDataGenerator class encapsulates all methods and market constants,\n",
    "making our code modular, reusable, and easy to maintain - key Agile principles!\n",
    "\n",
    "Key Financial Concepts:\n",
    "- Stock symbols represent publicly traded companies\n",
    "- Crypto symbols represent digital assets with 24/7 trading\n",
    "- Economic indicators measure macroeconomic health\n",
    "- Each asset class has different volatility and behavior patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb79db3-289c-4f9a-8fe9-47ea1320c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ­ FinancialDataGenerator initialized with seed=42\n",
      "ðŸ“ˆ Configured for 30 stock symbols\n",
      "ðŸ’° Configured for 15 crypto symbols\n",
      "ðŸ“Š Tracking 10 economic indicators\n",
      "ðŸ”„ All random generators seeded for reproducible results\n",
      "\n",
      "âœ… Generator class created successfully!\n",
      "ðŸ“ Next: We'll implement individual data generation methods\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FinancialDataGenerator:\n",
    "    \"\"\"\n",
    "    Comprehensive mock financial data generator for FinTech projects.\n",
    "    \n",
    "    This class (In Python, a class is a blueprint for generating objects (instances) that share the same data-attributes and behavior (methods),\n",
    "    creates realistic datasets that simulate:\n",
    "    1. Stock market behavior (geometric Brownian motion)\n",
    "    2. Cryptocurrency volatility (higher volatility, 24/7 trading)\n",
    "    3. Economic indicators (mean-reverting time series)\n",
    "    4. Portfolio allocations (risk-based asset allocation)\n",
    "    5. Customer demographics (realistic distributions)\n",
    "    \n",
    "    Design Pattern: This follows the Factory Pattern - one class that creates\n",
    "    multiple types of related objects (different financial datasets).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize the generator with predefined market data and random seed.\n",
    "        \n",
    "        Args:\n",
    "            seed: Random seed for reproducibility (crucial for testing and validation)\n",
    "        \n",
    "        Why use a seed?\n",
    "        - Ensures our data generation is reproducible\n",
    "        - Critical for debugging and validation\n",
    "        - Allows team members to generate identical datasets\n",
    "        - Follows best practices in quantitative finance\n",
    "        \"\"\"\n",
    "        # Set random seeds for reproducible results\n",
    "        np.random.seed(seed)  # NumPy random operations\n",
    "        random.seed(seed)     # Python random module operations\n",
    "        \n",
    "        # Define major stock symbols - representing different sectors and market caps\n",
    "        # These are real S&P 500 companies for realistic modeling\n",
    "        self.stock_symbols = [\n",
    "            # Technology Giants (FAANG + others)\n",
    "            'AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'META', 'NVDA', \n",
    "            \n",
    "            # Financial Services\n",
    "            'JPM', 'BAC', 'V', 'MA', \n",
    "            \n",
    "            # Healthcare & Consumer Goods\n",
    "            'JNJ', 'PG', 'UNH', 'PFE', 'KO', 'WMT',\n",
    "            \n",
    "            # Entertainment & Retail\n",
    "            'DIS', 'HD', 'NKE', 'COST',\n",
    "            \n",
    "            # Software & Cloud\n",
    "            'ADBE', 'CRM', 'ORCL', 'CSCO',\n",
    "            \n",
    "            # Traditional Industries\n",
    "            'T', 'VZ', 'XOM', 'CVX', 'IBM'\n",
    "        ]\n",
    "        \n",
    "        # Major cryptocurrency symbols by market capitalization (as of 2024-2025)\n",
    "        # Note: Crypto markets are more volatile and trade 24/7\n",
    "        self.crypto_symbols = [\n",
    "            'BTC',   # Bitcoin - digital gold, store of value\n",
    "            'ETH',   # Ethereum - smart contract platform\n",
    "            'BNB',   # Binance Coin - exchange token\n",
    "            'XRP',   # Ripple - cross-border payments\n",
    "            'ADA',   # Cardano - proof-of-stake blockchain\n",
    "            'DOGE',  # Dogecoin - meme coin with high volatility\n",
    "            'SOL',   # Solana - high-performance blockchain\n",
    "            'TRX',   # Tron - decentralized entertainment platform\n",
    "            'DOT',   # Polkadot - interoperability protocol\n",
    "            'MATIC', # Polygon - Ethereum scaling solution\n",
    "            'SHIB',  # Shiba Inu - another meme coin\n",
    "            'AVAX',  # Avalanche - smart contracts platform\n",
    "            'LTC',   # Litecoin - Bitcoin fork\n",
    "            'UNI',   # Uniswap - decentralized exchange token\n",
    "            'LINK'   # Chainlink - oracle network\n",
    "        ]\n",
    "        \n",
    "        # Key macroeconomic indicators that affect financial markets\n",
    "        # These drive fundamental analysis and economic forecasting\n",
    "        self.economic_indicators = [\n",
    "            'GDP_GROWTH',           # Gross Domestic Product growth rate\n",
    "            'INFLATION_RATE',       # Consumer Price Index changes\n",
    "            'UNEMPLOYMENT_RATE',    # Labor market health\n",
    "            'INTEREST_RATE',        # Federal funds rate (monetary policy)\n",
    "            'CONSUMER_CONFIDENCE',  # Consumer sentiment index\n",
    "            'RETAIL_SALES',         # Consumer spending patterns\n",
    "            'INDUSTRIAL_PRODUCTION',# Manufacturing output\n",
    "            'HOUSING_STARTS',       # Real estate market health\n",
    "            'TRADE_BALANCE',        # Imports vs exports\n",
    "            'MONEY_SUPPLY'          # M2 money supply (liquidity)\n",
    "        ]\n",
    "        \n",
    "        print(f\"ðŸ­ FinancialDataGenerator initialized with seed={seed}\")\n",
    "        print(f\"ðŸ“ˆ Configured for {len(self.stock_symbols)} stock symbols\")\n",
    "        print(f\"ðŸ’° Configured for {len(self.crypto_symbols)} crypto symbols\") \n",
    "        print(f\"ðŸ“Š Tracking {len(self.economic_indicators)} economic indicators\")\n",
    "        print(\"ðŸ”„ All random generators seeded for reproducible results\")\n",
    "\n",
    "# Test the class initialization\n",
    "generator = FinancialDataGenerator(seed=42)\n",
    "print(\"\\nâœ… Generator class created successfully!\")\n",
    "print(\"ðŸ“ Next: We'll implement individual data generation methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc638db3-25bf-43a9-99b1-84274e04f36a",
   "metadata": {},
   "source": [
    "Stock Price Modeling: Geometric Brownian Motion (GBM)\n",
    "====================================================\n",
    "\n",
    "Financial Theory Background:\n",
    "- Stock prices follow a random walk with drift\n",
    "- Daily returns are approximately normally distributed\n",
    "- Prices cannot go negative (geometric vs arithmetic Brownian motion)\n",
    "- Volatility clustering: periods of high/low volatility tend to cluster\n",
    "\n",
    "The GBM Formula: S(t+1) = S(t) * exp(Î¼*dt + Ïƒ*sqrt(dt)*Z)\n",
    "Where:\n",
    "- S(t) = current stock price\n",
    "- Î¼ = drift (expected return)\n",
    "- Ïƒ = volatility (standard deviation of returns)\n",
    "- Z = random normal variable\n",
    "- dt = time step (1 day = 1/252 years)\n",
    "\n",
    "OHLCV Format:\n",
    "- Open: First trade price of the day\n",
    "- High: Highest price during the day\n",
    "- Low: Lowest price during the day\n",
    "- Close: Last trade price of the day\n",
    "- Volume: Number of shares traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d908a54b-7bf7-4a45-becb-e57cb021bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing stock price generation with 3 symbols...\n",
      "ðŸ“… Generating stock data for 23 trading days\n",
      "ðŸ“ˆ Creating price series for 3 symbols\n",
      "  ðŸ“Š Processing AAPL (1/3)\n",
      "  ðŸ“Š Processing GOOGL (2/3)\n",
      "  ðŸ“Š Processing TSLA (3/3)\n",
      "âœ… Generated 69 stock price records\n",
      "ðŸ“Š Data shape: (69, 7)\n",
      "\n",
      "ðŸ“ˆ Sample Stock Data:\n",
      "        Date Symbol    Open    High     Low   Close   Volume\n",
      "0 2024-01-01   AAPL  195.47  215.52  195.47  208.73  3126595\n",
      "1 2024-01-02   AAPL  208.88  218.17  208.88  218.04  8566710\n",
      "2 2024-01-03   AAPL  217.65  221.85  217.65  221.28  2209596\n",
      "3 2024-01-04   AAPL  219.81  223.62  219.81  222.72   498495\n",
      "4 2024-01-05   AAPL  224.40  224.40  216.30  218.74  1278784\n",
      "\n",
      "ðŸ“Š Price range for AAPL: $192.08 - $222.72\n",
      "âœ… Stock price generation method working correctly!\n"
     ]
    }
   ],
   "source": [
    "def generate_stock_prices(self, \n",
    "                         symbols: List[str] = None,\n",
    "                         start_date: str = '2020-01-01',\n",
    "                         end_date: str = '2024-12-31',\n",
    "                         initial_price_range: Tuple[float, float] = (20, 500)) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate realistic stock price data using Geometric Brownian Motion.\n",
    "    \n",
    "    This method simulates how stock prices evolve over time, incorporating:\n",
    "    1. Random price movements (market efficiency)\n",
    "    2. Volatility clustering (periods of high/low volatility)\n",
    "    3. Mean reversion tendencies (prices don't drift too far from fundamentals)\n",
    "    4. Realistic trading volumes correlated with price volatility\n",
    "    \n",
    "    Args:\n",
    "        symbols: List of stock symbols to generate (default: first 20 predefined)\n",
    "        start_date: Start date for price series\n",
    "        end_date: End date for price series  \n",
    "        initial_price_range: Range for starting stock prices\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, Symbol, Open, High, Low, Close, Volume\n",
    "        \n",
    "    Financial Insights:\n",
    "        - Higher volatility stocks have more dramatic price swings\n",
    "        - Volume increases during high volatility periods (realistic behavior)\n",
    "        - Mean reversion prevents prices from drifting to unrealistic levels\n",
    "        - Weekend gaps are handled by excluding weekends from trading days\n",
    "    \"\"\"\n",
    "    if symbols is None:\n",
    "        symbols = self.stock_symbols[:20]  # Use first 20 symbols for manageable dataset\n",
    "        \n",
    "    # Create business day range (exclude weekends - NYSE is closed Sat/Sun)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    business_days = date_range[date_range.weekday < 5]  # Monday=0, Friday=4\n",
    "    \n",
    "    print(f\"ðŸ“… Generating stock data for {len(business_days)} trading days\")\n",
    "    print(f\"ðŸ“ˆ Creating price series for {len(symbols)} symbols\")\n",
    "    \n",
    "    all_stock_data = []\n",
    "    \n",
    "    for i, symbol in enumerate(symbols):\n",
    "        print(f\"  ðŸ“Š Processing {symbol} ({i+1}/{len(symbols)})\")\n",
    "        \n",
    "        # Initialize stock-specific parameters\n",
    "        initial_price = np.random.uniform(*initial_price_range)\n",
    "        annual_volatility = np.random.uniform(0.15, 0.45)  # 15-45% annual volatility\n",
    "        daily_volatility = annual_volatility / np.sqrt(252)  # Convert to daily\n",
    "        \n",
    "        # Store prices for mean reversion calculation\n",
    "        prices = [initial_price]\n",
    "        volumes = []\n",
    "        \n",
    "        # Generate daily price evolution\n",
    "        for day_idx, date in enumerate(business_days):\n",
    "            # Base daily return components\n",
    "            base_drift = np.random.normal(0.0008, 0.002)  # ~20% annual drift with variation\n",
    "            volatility_shock = np.random.normal(0, daily_volatility)\n",
    "            \n",
    "            # Add mean reversion after 30 days (prevents unrealistic price drift)\n",
    "            if day_idx > 30:\n",
    "                # Calculate 30-day moving average\n",
    "                recent_avg = np.mean(prices[-30:])\n",
    "                mean_reversion_force = (recent_avg - prices[-1]) * 0.001\n",
    "                base_drift += mean_reversion_force\n",
    "            \n",
    "            # Apply geometric Brownian motion formula\n",
    "            price_multiplier = np.exp(base_drift + volatility_shock)\n",
    "            new_price = prices[-1] * price_multiplier\n",
    "            \n",
    "            # Apply circuit breakers (realistic market limits)\n",
    "            # No stock can drop more than 30% or gain more than 50% in one day\n",
    "            new_price = max(new_price, prices[-1] * 0.70)  # Max 30% daily drop\n",
    "            new_price = min(new_price, prices[-1] * 1.50)  # Max 50% daily gain\n",
    "            \n",
    "            prices.append(new_price)\n",
    "            \n",
    "            # Generate realistic trading volume\n",
    "            # Volume correlates with volatility (high volatility = high volume)\n",
    "            base_volume = np.random.lognormal(15, 1)  # Log-normal distribution for volume\n",
    "            volatility_multiplier = abs(volatility_shock) * 5 + 1\n",
    "            daily_volume = int(base_volume * volatility_multiplier)\n",
    "            volumes.append(daily_volume)\n",
    "        \n",
    "        # Convert daily close prices to OHLCV format\n",
    "        for day_idx, date in enumerate(business_days):\n",
    "            close_price = prices[day_idx + 1]  # +1 because prices[0] is initial\n",
    "            previous_close = prices[day_idx]\n",
    "            \n",
    "            # Generate intraday price range\n",
    "            intraday_volatility = abs(np.random.normal(0, daily_volatility * close_price))\n",
    "            \n",
    "            # Calculate OHLC with realistic constraints\n",
    "            high_price = close_price + np.random.uniform(0, 1) * intraday_volatility\n",
    "            low_price = close_price - np.random.uniform(0, 1) * intraday_volatility  \n",
    "            open_price = previous_close + np.random.normal(0, daily_volatility * previous_close * 0.3)\n",
    "            \n",
    "            # Ensure OHLC logical consistency: Low â‰¤ Open,Close â‰¤ High\n",
    "            high_price = max(high_price, open_price, close_price)\n",
    "            low_price = min(low_price, open_price, close_price)\n",
    "            \n",
    "            # Add to dataset\n",
    "            all_stock_data.append({\n",
    "                'Date': date,\n",
    "                'Symbol': symbol,\n",
    "                'Open': round(open_price, 2),\n",
    "                'High': round(high_price, 2), \n",
    "                'Low': round(low_price, 2),\n",
    "                'Close': round(close_price, 2),\n",
    "                'Volume': volumes[day_idx]\n",
    "            })\n",
    "    \n",
    "    stock_df = pd.DataFrame(all_stock_data)\n",
    "    print(f\"âœ… Generated {len(stock_df):,} stock price records\")\n",
    "    print(f\"ðŸ“Š Data shape: {stock_df.shape}\")\n",
    "    return stock_df\n",
    "\n",
    "# Add the method to our generator class\n",
    "FinancialDataGenerator.generate_stock_prices = generate_stock_prices\n",
    "\n",
    "# Test the stock price generation\n",
    "print(\"ðŸ§ª Testing stock price generation with 3 symbols...\")\n",
    "test_stocks = generator.generate_stock_prices(\n",
    "    symbols=['AAPL', 'GOOGL', 'TSLA'], \n",
    "    start_date='2024-01-01', \n",
    "    end_date='2024-01-31'\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Sample Stock Data:\")\n",
    "print(test_stocks.head())\n",
    "print(f\"\\nðŸ“Š Price range for AAPL: ${test_stocks[test_stocks['Symbol']=='AAPL']['Close'].min():.2f} - ${test_stocks[test_stocks['Symbol']=='AAPL']['Close'].max():.2f}\")\n",
    "print(\"âœ… Stock price generation method working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cb193-cb34-492e-9aca-4b13e60f26e5",
   "metadata": {},
   "source": [
    "print(test_stocks[test_stocks['Symbol'] == 'AAPL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0927de-cfb4-42d2-9370-01ce0b3b4b2a",
   "metadata": {},
   "source": [
    "Cryptocurrency Market Characteristics\n",
    "====================================\n",
    "\n",
    "Key Differences from Traditional Assets:\n",
    "1. 24/7 Trading: No market closure, continuous price discovery\n",
    "2. Higher Volatility: 50-120% annual volatility vs 15-45% for stocks  \n",
    "3. Less Liquidity: More susceptible to large price swings\n",
    "4. Market Sentiment: Heavily influenced by news, social media, regulatory events\n",
    "5. Technological Factors: Network upgrades, adoption metrics affect prices\n",
    "\n",
    "Time Frequency: 6-hour intervals (4 data points per day)\n",
    "This provides sufficient granularity while keeping dataset manageable.\n",
    "\n",
    "DeFi & Crypto Fundamentals:\n",
    "- Bitcoin: Digital gold, store of value narrative\n",
    "- Ethereum: Smart contract platform, powers DeFi ecosystem\n",
    "- Altcoins: Various use cases (payments, DeFi, NFTs, gaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2a675c-07d6-4ee2-b3ba-60ef17c11c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing crypto price generation with BTC and ETH...\n",
      "â° Generating crypto data for 25 6-hour intervals\n",
      "ðŸ’Ž Creating price series for 2 cryptocurrencies\n",
      "ðŸŒ Modeling 24/7 global crypto markets\n",
      "  ðŸ’° Processing BTC (1/2)\n",
      "  ðŸ’° Processing ETH (2/2)\n",
      "âœ… Generated 50 cryptocurrency price records\n",
      "ðŸ“Š Data shape: (50, 7)\n",
      "\n",
      "ðŸ’Ž Sample Cryptocurrency Data:\n",
      "            Timestamp Symbol      Open      High       Low     Close  Volume\n",
      "0 2024-01-01 00:00:00    BTC  49291.92  49742.25  49291.92  49621.41   53815\n",
      "1 2024-01-01 06:00:00    BTC  48645.36  48844.56  48645.36  48788.78   82863\n",
      "2 2024-01-01 12:00:00    BTC  48484.04  50399.66  48484.04  50310.54  226355\n",
      "3 2024-01-01 18:00:00    BTC  49839.12  50870.34  49326.46  50450.39  142297\n",
      "4 2024-01-02 00:00:00    BTC  51631.66  51631.66  50589.41  50950.55  557573\n",
      "\n",
      "ðŸ“Š BTC price range: $42166.45 - $51512.48\n",
      "ðŸ“Š ETH price range: $3115.87 - $3497.23\n",
      "âœ… Cryptocurrency price generation working correctly!\n",
      "ðŸŒ Note: Crypto data includes 24/7 trading with 6-hour intervals\n"
     ]
    }
   ],
   "source": [
    "def generate_crypto_prices(self,\n",
    "                          symbols: List[str] = None,\n",
    "                          start_date: str = '2020-01-01', \n",
    "                          end_date: str = '2024-12-31') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate cryptocurrency price data with realistic 24/7 market behavior.\n",
    "    \n",
    "    Crypto markets exhibit unique characteristics:\n",
    "    - Much higher volatility (50-120% annually)\n",
    "    - 24/7 trading (no weekend gaps)\n",
    "    - Sentiment-driven price action\n",
    "    - Lower liquidity leads to more extreme movements\n",
    "    - Different behavior patterns for weekends vs weekdays\n",
    "    \n",
    "    Args:\n",
    "        symbols: List of crypto symbols (default: top 10 by market cap)\n",
    "        start_date: Start date for generation\n",
    "        end_date: End date for generation\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Timestamp, Symbol, Open, High, Low, Close, Volume\n",
    "        \n",
    "    Technical Implementation:\n",
    "        - 6-hour intervals (4 data points per day)\n",
    "        - Higher volatility parameters than stocks\n",
    "        - Weekend and night-time volume adjustments\n",
    "        - Realistic initial price ranges for major cryptocurrencies\n",
    "    \"\"\"\n",
    "    if symbols is None:\n",
    "        symbols = self.crypto_symbols[:10]  # Top 10 cryptocurrencies\n",
    "    \n",
    "    # Crypto trades 24/7 - generate 6-hour intervals\n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date, freq='h')\n",
    "    # Take every 6th hour: 00:00, 06:00, 12:00, 18:00 UTC\n",
    "    crypto_timestamps = full_date_range[::6]\n",
    "    \n",
    "    print(f\"â° Generating crypto data for {len(crypto_timestamps)} 6-hour intervals\")\n",
    "    print(f\"ðŸ’Ž Creating price series for {len(symbols)} cryptocurrencies\")\n",
    "    print(\"ðŸŒ Modeling 24/7 global crypto markets\")\n",
    "    \n",
    "    all_crypto_data = []\n",
    "    \n",
    "    # Realistic initial price ranges for major cryptocurrencies (USD)\n",
    "    # These reflect approximate price levels as of 2024-2025\n",
    "    initial_price_ranges = {\n",
    "        'BTC': (30000, 60000),    # Bitcoin: $30k-60k range\n",
    "        'ETH': (2000, 4000),      # Ethereum: $2k-4k range  \n",
    "        'BNB': (300, 600),        # Binance Coin: $300-600\n",
    "        'XRP': (0.5, 1.5),        # Ripple: $0.50-1.50\n",
    "        'ADA': (0.3, 1.2),        # Cardano: $0.30-1.20\n",
    "        'DOGE': (0.05, 0.3),      # Dogecoin: $0.05-0.30\n",
    "        'SOL': (50, 200),         # Solana: $50-200\n",
    "        'TRX': (0.06, 0.12),      # Tron: $0.06-0.12\n",
    "        'DOT': (5, 30),           # Polkadot: $5-30\n",
    "        'MATIC': (0.5, 2.5)       # Polygon: $0.50-2.50\n",
    "    }\n",
    "    \n",
    "    for i, symbol in enumerate(symbols):\n",
    "        print(f\"  ðŸ’° Processing {symbol} ({i+1}/{len(symbols)})\")\n",
    "        \n",
    "        # Set initial price and volatility for this crypto\n",
    "        price_range = initial_price_ranges.get(symbol, (1, 100))  # Default range for unlisted coins\n",
    "        initial_price = np.random.uniform(*price_range)\n",
    "        \n",
    "        # Crypto volatility is much higher than stocks\n",
    "        annual_volatility = np.random.uniform(0.5, 1.2)  # 50-120% annual volatility\n",
    "        six_hour_volatility = annual_volatility / np.sqrt(365 * 4)  # Convert to 6-hour periods\n",
    "        \n",
    "        prices = [initial_price]\n",
    "        volumes = []\n",
    "        \n",
    "        # Generate price evolution for each 6-hour period\n",
    "        for period_idx, timestamp in enumerate(crypto_timestamps):\n",
    "            # Base price movement\n",
    "            base_drift = np.random.normal(0, 0.001)  # Slightly positive expected return\n",
    "            volatility_shock = np.random.normal(0, six_hour_volatility)\n",
    "            \n",
    "            # Weekend effect: Crypto markets are less active on weekends\n",
    "            if timestamp.weekday() >= 5:  # Saturday=5, Sunday=6\n",
    "                base_drift *= 0.7  # Reduced weekend activity\n",
    "            \n",
    "            # Night time effect: Reduced activity during US night hours\n",
    "            if timestamp.hour < 6 or timestamp.hour > 22:\n",
    "                base_drift *= 0.5  # Lower overnight activity\n",
    "            \n",
    "            # Apply geometric Brownian motion with higher volatility bounds\n",
    "            price_multiplier = np.exp(base_drift + volatility_shock)\n",
    "            new_price = prices[-1] * price_multiplier\n",
    "            \n",
    "            # Crypto circuit breakers (more lenient than stocks due to higher volatility)\n",
    "            new_price = max(new_price, prices[-1] * 0.5)   # Max 50% period drop\n",
    "            new_price = min(new_price, prices[-1] * 2.0)   # Max 100% period gain\n",
    "            \n",
    "            prices.append(new_price)\n",
    "            \n",
    "            # Generate trading volume (crypto volumes are typically lower than stocks)\n",
    "            base_volume = np.random.lognormal(12, 1.5)  # Smaller base volume than stocks\n",
    "            volatility_multiplier = abs(volatility_shock) * 10 + 1  # Higher sensitivity to volatility\n",
    "            period_volume = int(base_volume * volatility_multiplier)\n",
    "            volumes.append(period_volume)\n",
    "        \n",
    "        # Convert to OHLCV format for each 6-hour period\n",
    "        for period_idx, timestamp in enumerate(crypto_timestamps):\n",
    "            close_price = prices[period_idx + 1]\n",
    "            previous_close = prices[period_idx]\n",
    "            \n",
    "            # Generate intraday range for 6-hour period\n",
    "            period_volatility = abs(np.random.normal(0, six_hour_volatility * close_price * 2))\n",
    "            \n",
    "            # Calculate OHLC\n",
    "            high_price = close_price + np.random.uniform(0, 1) * period_volatility\n",
    "            low_price = close_price - np.random.uniform(0, 1) * period_volatility\n",
    "            open_price = previous_close + np.random.normal(0, six_hour_volatility * previous_close)\n",
    "            \n",
    "            # Ensure OHLC consistency\n",
    "            high_price = max(high_price, open_price, close_price)\n",
    "            low_price = min(low_price, open_price, close_price)\n",
    "            \n",
    "            # Add to dataset with appropriate precision\n",
    "            # Crypto prices need more decimal places due to wide price ranges\n",
    "            decimal_places = 6 if close_price < 10 else 2\n",
    "            \n",
    "            all_crypto_data.append({\n",
    "                'Timestamp': timestamp,\n",
    "                'Symbol': symbol,\n",
    "                'Open': round(open_price, decimal_places),\n",
    "                'High': round(high_price, decimal_places),\n",
    "                'Low': round(low_price, decimal_places), \n",
    "                'Close': round(close_price, decimal_places),\n",
    "                'Volume': volumes[period_idx]\n",
    "            })\n",
    "    \n",
    "    crypto_df = pd.DataFrame(all_crypto_data)\n",
    "    print(f\"âœ… Generated {len(crypto_df):,} cryptocurrency price records\")\n",
    "    print(f\"ðŸ“Š Data shape: {crypto_df.shape}\")\n",
    "    return crypto_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_crypto_prices = generate_crypto_prices\n",
    "\n",
    "# Test cryptocurrency generation\n",
    "print(\"ðŸ§ª Testing crypto price generation with BTC and ETH...\")\n",
    "test_crypto = generator.generate_crypto_prices(\n",
    "    symbols=['BTC', 'ETH'],\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-01-07'  # One week for testing\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’Ž Sample Cryptocurrency Data:\")\n",
    "print(test_crypto.head())\n",
    "print(f\"\\nðŸ“Š BTC price range: ${test_crypto[test_crypto['Symbol']=='BTC']['Close'].min():.2f} - ${test_crypto[test_crypto['Symbol']=='BTC']['Close'].max():.2f}\")\n",
    "print(f\"ðŸ“Š ETH price range: ${test_crypto[test_crypto['Symbol']=='ETH']['Close'].min():.2f} - ${test_crypto[test_crypto['Symbol']=='ETH']['Close'].max():.2f}\")\n",
    "print(\"âœ… Cryptocurrency price generation working correctly!\")\n",
    "print(\"ðŸŒ Note: Crypto data includes 24/7 trading with 6-hour intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23332460-06e1-43c5-9779-86bd7726e1aa",
   "metadata": {},
   "source": [
    "Macroeconomic Indicators and Market Impact\n",
    "=========================================\n",
    "\n",
    "Economic indicators are crucial for:\n",
    "1. Fundamental Analysis: Understanding economic health\n",
    "2. Market Prediction: Economic data drives asset prices\n",
    "3. Risk Assessment: Economic cycles affect all investments\n",
    "4. Policy Analysis: Central bank decisions impact markets\n",
    "\n",
    "Key Indicators We Model:\n",
    "- GDP Growth: Overall economic expansion/contraction\n",
    "- Inflation Rate: Price level changes (CPI-based)\n",
    "- Unemployment Rate: Labor market health\n",
    "- Interest Rate: Federal funds rate (monetary policy)\n",
    "- Consumer Confidence: Sentiment indicator\n",
    "- Retail Sales: Consumer spending patterns\n",
    "- Industrial Production: Manufacturing output\n",
    "- Housing Starts: Real estate market health\n",
    "\n",
    "Time Series Properties:\n",
    "- Mean Reversion: Economic indicators tend to revert to long-term averages\n",
    "- Persistence: Current values influence future values\n",
    "- Seasonality: Some indicators have seasonal patterns\n",
    "- Structural Breaks: Economic crises can shift baseline levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e7acd3-1fcf-4ece-9c17-12bdb9e76c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing economic data generation...\n",
      "ðŸ“Š Generating economic indicators for 6 periods\n",
      "ðŸ“… Frequency: ME (6 data points)\n",
      "ðŸ›ï¸ Modeling key macroeconomic relationships\n",
      "  ðŸ“ˆ Processing period 1/6: 2024-01\n",
      "  ðŸ“ˆ Processing period 2/6: 2024-02\n",
      "  ðŸ“ˆ Processing period 3/6: 2024-03\n",
      "  ðŸ“ˆ Processing period 4/6: 2024-04\n",
      "  ðŸ“ˆ Processing period 5/6: 2024-05\n",
      "  ðŸ“ˆ Processing period 6/6: 2024-06\n",
      "âœ… Generated 60 economic data points\n",
      "ðŸ“Š Data shape: (60, 3)\n",
      "\n",
      "ðŸ“ˆ Economic Indicator Ranges:\n",
      "  GDP_GROWTH: 2.28 to 2.72\n",
      "  INFLATION_RATE: 2.08 to 3.16\n",
      "  UNEMPLOYMENT_RATE: 4.37 to 4.62\n",
      "  INTEREST_RATE: 1.22 to 1.45\n",
      "  CONSUMER_CONFIDENCE: 95.45 to 106.08\n",
      "  RETAIL_SALES: 0.48 to 2.16\n",
      "  INDUSTRIAL_PRODUCTION: 0.67 to 1.94\n",
      "  HOUSING_STARTS: 1201415.92 to 1280341.51\n",
      "  TRADE_BALANCE: -58678.27 to -47155.64\n",
      "  MONEY_SUPPLY: 15469.14 to 15469.14\n",
      "\n",
      "ðŸ›ï¸ Sample Economic Data:\n",
      "        Date              Indicator       Value\n",
      "0 2024-01-31             GDP_GROWTH        2.56\n",
      "1 2024-01-31         INFLATION_RATE        2.08\n",
      "2 2024-01-31      UNEMPLOYMENT_RATE        4.62\n",
      "3 2024-01-31          INTEREST_RATE        1.28\n",
      "4 2024-01-31    CONSUMER_CONFIDENCE      105.27\n",
      "5 2024-01-31           RETAIL_SALES        0.48\n",
      "6 2024-01-31  INDUSTRIAL_PRODUCTION        1.34\n",
      "7 2024-01-31         HOUSING_STARTS  1201415.92\n",
      "8 2024-01-31          TRADE_BALANCE   -49702.44\n",
      "9 2024-01-31           MONEY_SUPPLY    15469.14\n",
      "\n",
      "ðŸ“Š GDP Growth over test period:\n",
      "         Date  Value\n",
      "0  2024-01-31   2.56\n",
      "10 2024-02-29   2.40\n",
      "20 2024-03-31   2.28\n",
      "30 2024-04-30   2.72\n",
      "40 2024-05-31   2.43\n",
      "âœ… Economic indicators generation working correctly!\n",
      "ðŸ“ˆ Note: Data exhibits mean reversion and realistic bounds\n"
     ]
    }
   ],
   "source": [
    "def generate_economic_data(self,\n",
    "                          start_date: str = '2020-01-01',\n",
    "                          end_date: str = '2024-12-31', \n",
    "                          frequency: str = 'ME') -> pd.DataFrame:  # Changed from 'M' to 'ME'\n",
    "    \"\"\"\n",
    "    Generate macroeconomic indicator time series with realistic patterns.\n",
    "    \n",
    "    Economic indicators exhibit different behaviors than asset prices:\n",
    "    - Mean reversion to long-term equilibrium values\n",
    "    - Lower volatility than financial assets\n",
    "    - Autocorrelation (current values predict future values)\n",
    "    - Different measurement frequencies (monthly, quarterly)\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start date for data generation\n",
    "        end_date: End date for data generation\n",
    "        frequency: 'ME' for month-end, 'QE' for quarter-end, 'YE' for year-end\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, Indicator, Value\n",
    "        \n",
    "    Economic Theory Applied:\n",
    "    - Business Cycle: Indicators move together in cycles\n",
    "    - Phillips Curve: Inverse relationship between unemployment and inflation\n",
    "    - Taylor Rule: Interest rates respond to inflation and output gaps\n",
    "    \"\"\"\n",
    "    # Generate date range based on frequency\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=frequency)\n",
    "    \n",
    "    print(f\"ðŸ“Š Generating economic indicators for {len(date_range)} periods\")\n",
    "    print(f\"ðŸ“… Frequency: {frequency} ({len(date_range)} data points)\")\n",
    "    print(\"ðŸ›ï¸ Modeling key macroeconomic relationships\")\n",
    "    \n",
    "    all_economic_data = []\n",
    "    \n",
    "    # Historical baseline values (approximately US averages 2020-2024)\n",
    "    # These represent \"normal\" economic conditions\n",
    "    baseline_values = {\n",
    "        'GDP_GROWTH': 2.5,          # 2.5% annual GDP growth\n",
    "        'INFLATION_RATE': 2.0,      # 2% Fed (as well as ECB) inflation target\n",
    "        'UNEMPLOYMENT_RATE': 5.0,   # ~5% natural rate of unemployment\n",
    "        'INTEREST_RATE': 1.5,       # Federal funds rate\n",
    "        'CONSUMER_CONFIDENCE': 100.0, # Index value (100 = baseline)\n",
    "        'RETAIL_SALES': 0.5,        # Monthly % change\n",
    "        'INDUSTRIAL_PRODUCTION': 1.0, # Monthly % change\n",
    "        'HOUSING_STARTS': 1200000,  # Annual units (in thousands)\n",
    "        'TRADE_BALANCE': -50000,    # Million USD (negative = deficit)\n",
    "        'MONEY_SUPPLY': 15000       # Billion USD (M2 money supply)\n",
    "    }\n",
    "    \n",
    "    # Initialize current values at baseline\n",
    "    current_values = baseline_values.copy()\n",
    "    \n",
    "    # Generate data for each time period\n",
    "    for date_idx, date in enumerate(date_range):\n",
    "        print(f\"  ðŸ“ˆ Processing period {date_idx + 1}/{len(date_range)}: {date.strftime('%Y-%m')}\")\n",
    "        \n",
    "        for indicator in self.economic_indicators:\n",
    "            baseline = baseline_values[indicator]\n",
    "            current = current_values[indicator]\n",
    "            \n",
    "            # Mean reversion component\n",
    "            # Economic indicators tend to return to long-term averages\n",
    "            reversion_speed = 0.1  # 10% reversion per period\n",
    "            mean_reversion = (baseline - current) * reversion_speed\n",
    "            \n",
    "            # Random shock component (varies by indicator type)\n",
    "            if indicator in ['GDP_GROWTH', 'INFLATION_RATE', 'UNEMPLOYMENT_RATE']:\n",
    "                # Core economic indicators have moderate volatility\n",
    "                shock_std = 0.3\n",
    "            elif indicator == 'INTEREST_RATE':\n",
    "                # Interest rates change more gradually (Fed policy)\n",
    "                shock_std = 0.2\n",
    "            elif indicator == 'CONSUMER_CONFIDENCE':\n",
    "                # Sentiment can be quite volatile\n",
    "                shock_std = 5.0\n",
    "            elif indicator in ['RETAIL_SALES', 'INDUSTRIAL_PRODUCTION']:\n",
    "                # Monthly economic activity indicators\n",
    "                shock_std = 0.5\n",
    "            elif indicator == 'HOUSING_STARTS':\n",
    "                # Housing market can be quite volatile\n",
    "                shock_std = 50000\n",
    "            elif indicator == 'TRADE_BALANCE':\n",
    "                # Trade balance fluctuates with global conditions\n",
    "                shock_std = 10000\n",
    "            else:  # MONEY_SUPPLY\n",
    "                # Money supply grows steadily with occasional policy changes\n",
    "                shock_std = 500\n",
    "            \n",
    "            # Generate random shock\n",
    "            random_shock = np.random.normal(0, shock_std)\n",
    "            \n",
    "            # Calculate new value\n",
    "            new_value = current + mean_reversion + random_shock\n",
    "            \n",
    "            # Apply realistic bounds to prevent unrealistic values\n",
    "            if indicator == 'UNEMPLOYMENT_RATE':\n",
    "                new_value = max(2.0, min(15.0, new_value))  # 2-15% range\n",
    "            elif indicator == 'INFLATION_RATE':\n",
    "                new_value = max(-2.0, min(10.0, new_value))  # -2% to 10% range\n",
    "            elif indicator == 'INTEREST_RATE':\n",
    "                new_value = max(0.0, min(10.0, new_value))   # 0-10% range\n",
    "            elif indicator == 'CONSUMER_CONFIDENCE':\n",
    "                new_value = max(50, min(150, new_value))     # 50-150 index range\n",
    "            elif indicator == 'GDP_GROWTH':\n",
    "                new_value = max(-5.0, min(8.0, new_value))   # -5% to 8% growth range\n",
    "            elif indicator == 'HOUSING_STARTS':\n",
    "                new_value = max(500000, min(2000000, new_value))  # Realistic housing range\n",
    "            elif indicator == 'MONEY_SUPPLY':\n",
    "                new_value = max(new_value, current_values[indicator])  # Money supply rarely decreases\n",
    "            \n",
    "            # Update current value for next period\n",
    "            current_values[indicator] = new_value\n",
    "            \n",
    "            # Add to dataset\n",
    "            all_economic_data.append({\n",
    "                'Date': date,\n",
    "                'Indicator': indicator,\n",
    "                'Value': round(new_value, 2)\n",
    "            })\n",
    "    \n",
    "    economic_df = pd.DataFrame(all_economic_data)\n",
    "    print(f\"âœ… Generated {len(economic_df):,} economic data points\")\n",
    "    print(f\"ðŸ“Š Data shape: {economic_df.shape}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nðŸ“ˆ Economic Indicator Ranges:\")\n",
    "    for indicator in self.economic_indicators:\n",
    "        indicator_data = economic_df[economic_df['Indicator'] == indicator]['Value']\n",
    "        print(f\"  {indicator}: {indicator_data.min():.2f} to {indicator_data.max():.2f}\")\n",
    "    \n",
    "    return economic_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_economic_data = generate_economic_data\n",
    "\n",
    "# Test economic data generation\n",
    "print(\"ðŸ§ª Testing economic data generation...\")\n",
    "test_economic = generator.generate_economic_data(\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-06-30',  # 6 months for testing\n",
    "    frequency='ME'  # Monthly data\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ›ï¸ Sample Economic Data:\")\n",
    "print(test_economic.head(10))\n",
    "\n",
    "# Show data for one specific indicator\n",
    "gdp_data = test_economic[test_economic['Indicator'] == 'GDP_GROWTH']\n",
    "print(f\"\\nðŸ“Š GDP Growth over test period:\")\n",
    "print(gdp_data[['Date', 'Value']].head())\n",
    "\n",
    "print(\"âœ… Economic indicators generation working correctly!\")\n",
    "print(\"ðŸ“ˆ Note: Data exhibits mean reversion and realistic bounds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f394e-165c-42d3-938b-3796037c7de9",
   "metadata": {},
   "source": [
    "Portfolio Management and Asset Allocation Theory\n",
    "===============================================\n",
    "\n",
    "Modern Portfolio Theory (MPT) Concepts:\n",
    "1. Risk-Return Tradeoff: Higher expected returns require higher risk\n",
    "2. Diversification: Spreading investments across asset classes\n",
    "3. Asset Allocation: Strategic mix of stocks, bonds, cash based on risk tolerance\n",
    "4. Rebalancing: Adjusting portfolio weights over time\n",
    "\n",
    "Risk Profiles:\n",
    "- Conservative: Capital preservation, lower volatility, higher bond allocation\n",
    "- Moderate: Balanced growth and income, mixed allocation\n",
    "- Aggressive: Growth-focused, higher equity allocation, higher volatility\n",
    "\n",
    "Key Metrics We Generate:\n",
    "- Portfolio Value: Total market value of holdings\n",
    "- Asset Weights: Percentage allocation to stocks, bonds, cash\n",
    "- Monthly Returns: Period-over-period performance\n",
    "- Risk Level: Conservative, Moderate, Aggressive classification\n",
    "\n",
    "This data supports:\n",
    "- Portfolio optimization algorithms\n",
    "- Risk management systems\n",
    "- Performance attribution analysis\n",
    "- Client reporting and advisory services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07563f0-a4ec-4a30-b148-f366653a9b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing portfolio data generation...\n",
      "ðŸ’¼ Generating portfolio data for 5 portfolios\n",
      "ðŸ“… Tracking 6 monthly periods\n",
      "ðŸ“Š Modeling Conservative, Moderate, and Aggressive risk profiles\n",
      "âœ… Generated 30 portfolio records\n",
      "ðŸ“Š Data shape: (30, 8)\n",
      "\n",
      "ðŸ“ˆ Portfolio Performance Summary by Risk Level:\n",
      "  Conservative: 9.0% return, 9.1% volatility, 44.5% stocks\n",
      "  Moderate: 7.7% return, 9.0% volatility, 57.1% stocks\n",
      "  Aggressive: 66.3% return, 16.9% volatility, 77.2% stocks\n",
      "\n",
      "ðŸ’¼ Sample Portfolio Data:\n",
      "        Date PortfolioID RiskLevel  TotalValue  StockWeight  BondWeight  \\\n",
      "0 2024-01-31      PF_001  Moderate   801471.58        0.515       0.388   \n",
      "1 2024-02-29      PF_001  Moderate   797281.44        0.519       0.386   \n",
      "2 2024-03-31      PF_001  Moderate   826790.11        0.542       0.365   \n",
      "3 2024-04-30      PF_001  Moderate   835570.01        0.538       0.371   \n",
      "4 2024-05-31      PF_001  Moderate   861796.67        0.545       0.359   \n",
      "\n",
      "   CashWeight  MonthlyReturn  \n",
      "0       0.097         0.0473  \n",
      "1       0.096        -0.0052  \n",
      "2       0.094         0.0370  \n",
      "3       0.092         0.0106  \n",
      "4       0.096         0.0314  \n",
      "\n",
      "ðŸ“Š Portfolio PF_001 Evolution:\n",
      "        Date  TotalValue  StockWeight  MonthlyReturn\n",
      "0 2024-01-31   801471.58        0.515         0.0473\n",
      "1 2024-02-29   797281.44        0.519        -0.0052\n",
      "2 2024-03-31   826790.11        0.542         0.0370\n",
      "3 2024-04-30   835570.01        0.538         0.0106\n",
      "4 2024-05-31   861796.67        0.545         0.0314\n",
      "âœ… Portfolio data generation working correctly!\n",
      "ðŸ’¡ Data includes realistic risk-based allocations and performance patterns\n"
     ]
    }
   ],
   "source": [
    "def generate_portfolio_data(self,\n",
    "                           n_portfolios: int = 100,\n",
    "                           start_date: str = '2020-01-01',\n",
    "                           end_date: str = '2024-12-31') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate realistic portfolio holdings and performance data.\n",
    "    \n",
    "    Each portfolio has:\n",
    "    - Consistent risk profile (Conservative/Moderate/Aggressive)\n",
    "    - Realistic asset allocation based on risk tolerance\n",
    "    - Monthly rebalancing with small drifts\n",
    "    - Returns correlated with allocation and market conditions\n",
    "    \n",
    "    Args:\n",
    "        n_portfolios: Number of unique portfolios to generate\n",
    "        start_date: Start date for portfolio tracking\n",
    "        end_date: End date for portfolio tracking\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, PortfolioID, RiskLevel, TotalValue, \n",
    "                              StockWeight, BondWeight, CashWeight, MonthlyReturn\n",
    "                              \n",
    "    Portfolio Theory Implementation:\n",
    "    - Risk-based asset allocation follows industry standards\n",
    "    - Returns follow normal distribution with risk-appropriate parameters\n",
    "    - Allocation drift simulates real-world portfolio management\n",
    "    - Performance is consistent with risk profile expectations\n",
    "    \"\"\"\n",
    "    # Generate monthly date range for portfolio snapshots\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='ME')  # Month end frequency\n",
    "    \n",
    "    print(f\"ðŸ’¼ Generating portfolio data for {n_portfolios} portfolios\")\n",
    "    print(f\"ðŸ“… Tracking {len(date_range)} monthly periods\")\n",
    "    print(\"ðŸ“Š Modeling Conservative, Moderate, and Aggressive risk profiles\")\n",
    "    \n",
    "    all_portfolio_data = []\n",
    "    \n",
    "    # Generate each portfolio's characteristics and evolution\n",
    "    for portfolio_id in range(1, n_portfolios + 1):\n",
    "        if portfolio_id % 20 == 0:  # Progress indicator\n",
    "            print(f\"  ðŸ’¼ Processing portfolio {portfolio_id}/{n_portfolios}\")\n",
    "        \n",
    "        # Randomly assign risk level (realistic distribution)\n",
    "        risk_level = np.random.choice(\n",
    "            ['Conservative', 'Moderate', 'Aggressive'], \n",
    "            p=[0.3, 0.5, 0.2]  # Most clients are moderate risk\n",
    "        )\n",
    "        \n",
    "        # Generate initial portfolio value (realistic range for different client types)\n",
    "        if risk_level == 'Conservative':\n",
    "            initial_value = np.random.uniform(500000, 5000000)  # Older, wealthier clients\n",
    "        elif risk_level == 'Moderate':\n",
    "            initial_value = np.random.uniform(100000, 2000000)  # Middle-market clients\n",
    "        else:  # Aggressive\n",
    "            initial_value = np.random.uniform(50000, 1000000)   # Younger, growth-oriented\n",
    "        \n",
    "        # Set risk-appropriate asset allocation and return expectations\n",
    "        if risk_level == 'Conservative':\n",
    "            # Capital preservation focus\n",
    "            base_stock_weight = np.random.uniform(0.3, 0.5)    # 30-50% stocks\n",
    "            base_bond_weight = np.random.uniform(0.4, 0.6)     # 40-60% bonds\n",
    "            base_cash_weight = 1 - base_stock_weight - base_bond_weight\n",
    "            expected_annual_return = 0.06  # 6% expected return\n",
    "            annual_volatility = 0.08       # 8% volatility\n",
    "            \n",
    "        elif risk_level == 'Moderate':\n",
    "            # Balanced growth and income\n",
    "            base_stock_weight = np.random.uniform(0.5, 0.7)    # 50-70% stocks\n",
    "            base_bond_weight = np.random.uniform(0.2, 0.4)     # 20-40% bonds\n",
    "            base_cash_weight = 1 - base_stock_weight - base_bond_weight\n",
    "            expected_annual_return = 0.08  # 8% expected return\n",
    "            annual_volatility = 0.12       # 12% volatility\n",
    "            \n",
    "        else:  # Aggressive\n",
    "            # Growth maximization\n",
    "            base_stock_weight = np.random.uniform(0.7, 0.9)    # 70-90% stocks\n",
    "            base_bond_weight = np.random.uniform(0.05, 0.2)    # 5-20% bonds\n",
    "            base_cash_weight = 1 - base_stock_weight - base_bond_weight\n",
    "            expected_annual_return = 0.10  # 10% expected return\n",
    "            annual_volatility = 0.18       # 18% volatility\n",
    "        \n",
    "        # Ensure weights sum to 1.0\n",
    "        total_weight = base_stock_weight + base_bond_weight + base_cash_weight\n",
    "        stock_weight = base_stock_weight / total_weight\n",
    "        bond_weight = base_bond_weight / total_weight\n",
    "        cash_weight = base_cash_weight / total_weight\n",
    "        \n",
    "        # Initialize portfolio tracking variables\n",
    "        current_value = initial_value\n",
    "        current_stock_weight = stock_weight\n",
    "        current_bond_weight = bond_weight\n",
    "        current_cash_weight = cash_weight\n",
    "        \n",
    "        # Generate monthly performance data\n",
    "        for date_idx, date in enumerate(date_range):\n",
    "            # Generate monthly return based on risk profile\n",
    "            # Convert annual parameters to monthly\n",
    "            monthly_expected_return = expected_annual_return / 12\n",
    "            monthly_volatility = annual_volatility / np.sqrt(12)\n",
    "            \n",
    "            # Add some market correlation (all portfolios affected by same market conditions)\n",
    "            market_factor = np.random.normal(0, 0.02)  # Common market movement\n",
    "            idiosyncratic_return = np.random.normal(monthly_expected_return, monthly_volatility)\n",
    "            monthly_return = idiosyncratic_return + market_factor * (stock_weight * 1.5)\n",
    "            \n",
    "            # Update portfolio value\n",
    "            current_value *= (1 + monthly_return)\n",
    "            \n",
    "            # Simulate allocation drift (realistic portfolio management)\n",
    "            # Weights drift slightly due to different asset class performance\n",
    "            drift_std = 0.02  # 2% standard deviation for weight changes\n",
    "            stock_drift = np.random.normal(0, drift_std)\n",
    "            bond_drift = np.random.normal(0, drift_std)\n",
    "            \n",
    "            current_stock_weight += stock_drift\n",
    "            current_bond_weight += bond_drift\n",
    "            \n",
    "            # Normalize weights to ensure they sum to 1.0\n",
    "            total_current_weight = current_stock_weight + current_bond_weight + current_cash_weight\n",
    "            current_stock_weight /= total_current_weight\n",
    "            current_bond_weight /= total_current_weight\n",
    "            current_cash_weight = 1 - current_stock_weight - current_bond_weight\n",
    "            \n",
    "            # Ensure no negative weights (realistic constraint)\n",
    "            current_stock_weight = max(0.05, min(0.95, current_stock_weight))\n",
    "            current_bond_weight = max(0.05, min(0.95, current_bond_weight))\n",
    "            current_cash_weight = max(0.05, min(0.95, current_cash_weight))\n",
    "            \n",
    "            # Re-normalize after applying bounds\n",
    "            total_bounded = current_stock_weight + current_bond_weight + current_cash_weight\n",
    "            current_stock_weight /= total_bounded\n",
    "            current_bond_weight /= total_bounded\n",
    "            current_cash_weight = 1 - current_stock_weight - current_bond_weight\n",
    "            \n",
    "            # Add record to dataset\n",
    "            all_portfolio_data.append({\n",
    "                'Date': date,\n",
    "                'PortfolioID': f'PF_{portfolio_id:03d}',\n",
    "                'RiskLevel': risk_level,\n",
    "                'TotalValue': round(current_value, 2),\n",
    "                'StockWeight': round(current_stock_weight, 3),\n",
    "                'BondWeight': round(current_bond_weight, 3),\n",
    "                'CashWeight': round(current_cash_weight, 3),\n",
    "                'MonthlyReturn': round(monthly_return, 4)\n",
    "            })\n",
    "    \n",
    "    portfolio_df = pd.DataFrame(all_portfolio_data)\n",
    "    print(f\"âœ… Generated {len(portfolio_df):,} portfolio records\")\n",
    "    print(f\"ðŸ“Š Data shape: {portfolio_df.shape}\")\n",
    "    \n",
    "    # Display summary statistics by risk level\n",
    "    print(\"\\nðŸ“ˆ Portfolio Performance Summary by Risk Level:\")\n",
    "    for risk_level in ['Conservative', 'Moderate', 'Aggressive']:\n",
    "        risk_data = portfolio_df[portfolio_df['RiskLevel'] == risk_level]\n",
    "        avg_return = risk_data['MonthlyReturn'].mean() * 12 * 100  # Annualized %\n",
    "        volatility = risk_data['MonthlyReturn'].std() * np.sqrt(12) * 100  # Annualized %\n",
    "        avg_stock_weight = risk_data['StockWeight'].mean() * 100\n",
    "        \n",
    "        print(f\"  {risk_level}: {avg_return:.1f}% return, {volatility:.1f}% volatility, {avg_stock_weight:.1f}% stocks\")\n",
    "    \n",
    "    return portfolio_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_portfolio_data = generate_portfolio_data\n",
    "\n",
    "# Test portfolio data generation\n",
    "print(\"ðŸ§ª Testing portfolio data generation...\")\n",
    "test_portfolios = generator.generate_portfolio_data(\n",
    "    n_portfolios=5,  # Small test set\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-06-30'\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’¼ Sample Portfolio Data:\")\n",
    "print(test_portfolios.head())\n",
    "\n",
    "# Show one portfolio's evolution over time\n",
    "portfolio_1 = test_portfolios[test_portfolios['PortfolioID'] == 'PF_001']\n",
    "print(f\"\\nðŸ“Š Portfolio PF_001 Evolution:\")\n",
    "print(portfolio_1[['Date', 'TotalValue', 'StockWeight', 'MonthlyReturn']].head())\n",
    "\n",
    "print(\"âœ… Portfolio data generation working correctly!\")\n",
    "print(\"ðŸ’¡ Data includes realistic risk-based allocations and performance patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf109c-f488-4d2d-99b7-2bcbd51209aa",
   "metadata": {},
   "source": [
    "FinTech Customer Analytics and Risk Modeling\n",
    "===========================================\n",
    "\n",
    "Customer data is crucial for:\n",
    "1. Credit Risk Assessment: Scoring models for lending decisions\n",
    "2. Customer Segmentation: Targeted product offerings and marketing\n",
    "3. Fraud Detection: Identifying unusual transaction patterns\n",
    "4. Regulatory Compliance: KYC (Know Your Customer) requirements\n",
    "5. Product Development: Understanding customer needs and behaviors\n",
    "\n",
    "Key Variables We Model:\n",
    "- Demographics: Age, income (realistic distributions)\n",
    "- Credit Profile: Credit score, existing loans\n",
    "- Account Behavior: Transaction frequency, amounts, tenure\n",
    "- Product Usage: Number of products, account balance\n",
    "- Risk Segmentation: High/Medium/Low risk classification\n",
    "\n",
    "Statistical Distributions Used:\n",
    "- Age: Normal distribution (mean=40, realistic range)\n",
    "- Income: Log-normal distribution (reflects real-world income inequality)\n",
    "- Credit Score: Normal distribution with realistic bounds (300-850)\n",
    "- Transaction Behavior: Poisson distribution for count data\n",
    "- Account Balance: Log-normal distribution\n",
    "\n",
    "This supports:\n",
    "- Credit scoring models\n",
    "- Customer lifetime value analysis\n",
    "- Churn prediction\n",
    "- Fraud detection systems\n",
    "- Regulatory reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d234e0-8193-4eb0-afe3-4db3cba9d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing customer data generation...\n",
      "ðŸ‘¥ Generating customer data for 1,000 customers\n",
      "ðŸ“Š Modeling realistic demographic and behavioral patterns\n",
      "ðŸŽ¯ Creating data suitable for credit scoring, segmentation, and analytics\n",
      "  ðŸ‘¤ Processing customer 1,000/1,000\n",
      "âœ… Generated 1,000 customer records\n",
      "ðŸ“Š Data shape: (1000, 11)\n",
      "\n",
      "ðŸ‘¥ Customer Demographics Summary:\n",
      "  Average Age: 40.2 years\n",
      "  Average Income: $41,936\n",
      "  Average Credit Score: 692\n",
      "  Average Account Balance: $7,453\n",
      "\n",
      "ðŸ“Š Risk Segment Distribution:\n",
      "  Low Risk: 288 customers (28.8%)\n",
      "  Medium Risk: 542 customers (54.2%)\n",
      "  High Risk: 170 customers (17.0%)\n",
      "\n",
      "ðŸ’³ Loan Penetration: 28 customers (2.8%)\n",
      "\n",
      "ðŸ‘¥ Sample Customer Data:\n",
      "    CustomerID  Age    Income  CreditScore  AccountAgeDays  AccountBalance  \\\n",
      "0  CUST_000001   53  32516.99          688            1918          610.48   \n",
      "1  CUST_000002   42  21347.37          779            1023         5575.62   \n",
      "2  CUST_000003   53  39070.54          741            1137        12302.13   \n",
      "3  CUST_000004   30  28511.34          652            1620         3961.15   \n",
      "4  CUST_000005   55  46769.92          493            1112          407.36   \n",
      "\n",
      "   MonthlyTransactions  AvgTransactionAmount  NumProducts  HasLoan RiskSegment  \n",
      "0                   47                 30.73            1    False      Medium  \n",
      "1                   50                 33.70            2    False         Low  \n",
      "2                   49                 20.82            2    False      Medium  \n",
      "3                   49                 22.66            1    False      Medium  \n",
      "4                   54                 74.83            1    False        High  \n",
      "\n",
      "ðŸ“ˆ Income vs Credit Score Correlation:\n",
      "Correlation coefficient: 0.087\n",
      "\n",
      "ðŸŽ¯ Risk Segment Statistics:\n",
      "  Low: Income=$44,205, Credit=802, Balance=$7,557\n",
      "  Medium: Income=$41,038, Credit=679, Balance=$6,467\n",
      "  High: Income=$40,958, Credit=548, Balance=$10,422\n",
      "âœ… Customer data generation working correctly!\n",
      "ðŸ’¡ Data includes realistic correlations and distributions suitable for ML modeling\n"
     ]
    }
   ],
   "source": [
    "def generate_customer_data(self, n_customers: int = 10000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate realistic customer demographic and account data for FinTech analysis.\n",
    "    \n",
    "    Creates a comprehensive customer database with correlated variables that\n",
    "    reflect real-world patterns in financial services:\n",
    "    - Income correlates with credit score and account balance\n",
    "    - Age affects risk tolerance and product usage\n",
    "    - Account tenure influences transaction behavior\n",
    "    - Risk segmentation based on credit score thresholds\n",
    "    \n",
    "    Args:\n",
    "        n_customers: Number of customer records to generate\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with customer demographics, account details, and risk metrics\n",
    "        \n",
    "    Data Science Applications:\n",
    "    - Feature engineering for ML models\n",
    "    - Customer segmentation analysis  \n",
    "    - Credit risk modeling\n",
    "    - Behavioral analytics\n",
    "    - A/B testing frameworks\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ‘¥ Generating customer data for {n_customers:,} customers\")\n",
    "    print(\"ðŸ“Š Modeling realistic demographic and behavioral patterns\")\n",
    "    print(\"ðŸŽ¯ Creating data suitable for credit scoring, segmentation, and analytics\")\n",
    "    \n",
    "    all_customer_data = []\n",
    "    \n",
    "    # Generate each customer's profile\n",
    "    for customer_id in range(1, n_customers + 1):\n",
    "        if customer_id % 1000 == 0:  # Progress indicator\n",
    "            print(f\"  ðŸ‘¤ Processing customer {customer_id:,}/{n_customers:,}\")\n",
    "        \n",
    "        # Demographics\n",
    "        # Age: Normal distribution centered at 40 with realistic bounds\n",
    "        age = np.random.normal(40, 15)\n",
    "        age = max(18, min(80, int(age)))  # Legal age bounds\n",
    "        \n",
    "        # Income: Log-normal distribution (realistic income inequality)\n",
    "        # This creates a right-skewed distribution like real income data\n",
    "        log_income = np.random.lognormal(10.5, 0.5)  # Parameters chosen for realistic range\n",
    "        income = max(20000, min(500000, log_income))  # Reasonable bounds\n",
    "        \n",
    "        # Credit Score: Normal distribution with income correlation\n",
    "        # Higher income generally correlates with higher credit scores\n",
    "        income_effect = (income - 60000) / 100000 * 50  # Income influence on credit\n",
    "        base_credit_score = np.random.normal(700, 100)  # Base score\n",
    "        credit_score = base_credit_score + income_effect\n",
    "        credit_score = max(300, min(850, int(credit_score)))  # FICO range bounds\n",
    "        \n",
    "        # Account Details\n",
    "        # Account age: Uniform distribution with some bias toward newer accounts\n",
    "        account_age_days = np.random.randint(30, 2000)  # 1 month to ~5.5 years\n",
    "        \n",
    "        # Account Balance: Log-normal with correlation to income and credit score\n",
    "        # Higher income and credit scores lead to higher balances\n",
    "        income_factor = income / 60000  # Normalize around median income\n",
    "        credit_factor = credit_score / 700  # Normalize around good credit\n",
    "        balance_multiplier = (income_factor + credit_factor) / 2\n",
    "        \n",
    "        base_balance = np.random.lognormal(8, 1.5)  # Base log-normal distribution\n",
    "        account_balance = max(0, base_balance * balance_multiplier)\n",
    "        \n",
    "        # Transaction Behavior\n",
    "        # Monthly transactions: Poisson distribution (count data)\n",
    "        # More active users tend to have higher incomes and longer tenure\n",
    "        activity_factor = min(2.0, income / 50000 + account_age_days / 1000)\n",
    "        base_transaction_rate = 25  # Average transactions per month\n",
    "        monthly_transactions = np.random.poisson(base_transaction_rate * activity_factor)\n",
    "        \n",
    "        # Average transaction amount: Log-normal with income correlation\n",
    "        base_transaction_amount = np.random.lognormal(4, 1)  # Base amount\n",
    "        transaction_income_factor = max(0.5, income / 60000)\n",
    "        avg_transaction_amount = base_transaction_amount * transaction_income_factor\n",
    "        \n",
    "        # Product Usage\n",
    "        # Number of products: Poisson with income/age correlation\n",
    "        # Older, wealthier customers typically have more products\n",
    "        age_factor = max(0.5, age / 40)\n",
    "        income_product_factor = max(0.5, income / 60000)\n",
    "        product_rate = 2 * age_factor * income_product_factor\n",
    "        num_products = max(1, np.random.poisson(product_rate))\n",
    "        \n",
    "        # Loan Status: Probability based on age, income, and credit score\n",
    "        # Younger people and those with good credit more likely to have loans\n",
    "        age_loan_factor = max(0.1, (40 - age) / 40)  # Younger = higher probability\n",
    "        credit_loan_factor = max(0.1, (credit_score - 600) / 250)  # Better credit = higher prob\n",
    "        loan_probability = 0.3 * age_loan_factor * credit_loan_factor\n",
    "        has_loan = np.random.choice([True, False], p=[loan_probability, 1 - loan_probability])\n",
    "        \n",
    "        # Risk Segmentation based on credit score (industry standard thresholds)\n",
    "        if credit_score < 600:\n",
    "            risk_segment = 'High'      # Subprime\n",
    "        elif credit_score < 750:\n",
    "            risk_segment = 'Medium'    # Near prime\n",
    "        else:\n",
    "            risk_segment = 'Low'       # Prime\n",
    "        \n",
    "        # Compile customer record\n",
    "        all_customer_data.append({\n",
    "            'CustomerID': f'CUST_{customer_id:06d}',\n",
    "            'Age': age,\n",
    "            'Income': round(income, 2),\n",
    "            'CreditScore': credit_score,\n",
    "            'AccountAgeDays': account_age_days,\n",
    "            'AccountBalance': round(account_balance, 2),\n",
    "            'MonthlyTransactions': monthly_transactions,\n",
    "            'AvgTransactionAmount': round(avg_transaction_amount, 2),\n",
    "            'NumProducts': num_products,\n",
    "            'HasLoan': has_loan,\n",
    "            'RiskSegment': risk_segment\n",
    "        })\n",
    "    \n",
    "    customer_df = pd.DataFrame(all_customer_data)\n",
    "    print(f\"âœ… Generated {len(customer_df):,} customer records\")\n",
    "    print(f\"ðŸ“Š Data shape: {customer_df.shape}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nðŸ‘¥ Customer Demographics Summary:\")\n",
    "    print(f\"  Average Age: {customer_df['Age'].mean():.1f} years\")\n",
    "    print(f\"  Average Income: ${customer_df['Income'].mean():,.0f}\")\n",
    "    print(f\"  Average Credit Score: {customer_df['CreditScore'].mean():.0f}\")\n",
    "    print(f\"  Average Account Balance: ${customer_df['AccountBalance'].mean():,.0f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Risk Segment Distribution:\")\n",
    "    risk_counts = customer_df['RiskSegment'].value_counts()\n",
    "    for segment in ['Low', 'Medium', 'High']:\n",
    "        count = risk_counts.get(segment, 0)\n",
    "        percentage = (count / len(customer_df)) * 100\n",
    "        print(f\"  {segment} Risk: {count:,} customers ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nðŸ’³ Loan Penetration: {customer_df['HasLoan'].sum():,} customers ({customer_df['HasLoan'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    return customer_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_customer_data = generate_customer_data\n",
    "\n",
    "# Test customer data generation\n",
    "print(\"ðŸ§ª Testing customer data generation...\")\n",
    "test_customers = generator.generate_customer_data(n_customers=1000)  # Smaller test set\n",
    "\n",
    "print(\"\\nðŸ‘¥ Sample Customer Data:\")\n",
    "print(test_customers.head())\n",
    "\n",
    "# Show correlation analysis\n",
    "print(\"\\nðŸ“ˆ Income vs Credit Score Correlation:\")\n",
    "correlation = test_customers['Income'].corr(test_customers['CreditScore'])\n",
    "print(f\"Correlation coefficient: {correlation:.3f}\")\n",
    "\n",
    "# Risk segment analysis\n",
    "print(\"\\nðŸŽ¯ Risk Segment Statistics:\")\n",
    "for segment in ['Low', 'Medium', 'High']:\n",
    "    segment_data = test_customers[test_customers['RiskSegment'] == segment]\n",
    "    if len(segment_data) > 0:\n",
    "        avg_income = segment_data['Income'].mean()\n",
    "        avg_credit = segment_data['CreditScore'].mean()\n",
    "        avg_balance = segment_data['AccountBalance'].me# Cell 8: Complete Dataset Generation and Export System\n",
    "\"\"\"\n",
    "Production Data Pipeline and Export System\n",
    "==========================================\n",
    "\n",
    "This final cell brings together all our data generation methods into a \n",
    "production-ready pipeline that creates a complete FinTech dataset suitable\n",
    "for all 11 weeks of our Agile development sprints.\n",
    "\n",
    "Data Outputs:\n",
    "1. stock_prices.csv - Daily OHLCV data for major stocks\n",
    "2. crypto_prices.csv - 6-hourly cryptocurrency data  \n",
    "3. economic_indicators.csv - Monthly macroeconomic indicators\n",
    "4. portfolio_data.csv - Monthly portfolio holdings and performance\n",
    "5. customer_data.csv - Customer demographics and behavior\n",
    "\n",
    "File Format: CSV (Comma-Separated Values)\n",
    "- Portable across all platforms and tools\n",
    "- Easy to import into Python, R, SQL databases\n",
    "- Human-readable for data inspection\n",
    "- Compatible with Excel, Google Sheets\n",
    "\n",
    "Data Governance:\n",
    "- Consistent date formats (ISO 8601)\n",
    "- Standardized column naming (snake_case)\n",
    "- Appropriate data types and precision\n",
    "- Comprehensive metadata and documentation\n",
    "\"\"\"\n",
    "\n",
    "def save_all_datasets(self, output_dir: str = 'mock_financial_data') -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate and save all financial datasets to CSV files.\n",
    "    \n",
    "    This method orchestrates the complete data generation pipeline:\n",
    "    1. Creates output directory structure\n",
    "    2. Generates all dataset types with appropriate parameters\n",
    "    3. Saves data in CSV format with proper encoding\n",
    "    4. Provides comprehensive logging and error handling\n",
    "    5. Returns datasets for immediate analysis\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory name for output files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all generated datasets\n",
    "        \n",
    "    Production Considerations:\n",
    "    - Error handling for file system operations\n",
    "    - Progress tracking for long-running operations  \n",
    "    - Memory-efficient processing for large datasets\n",
    "    - Consistent file naming conventions\n",
    "    - UTF-8 encoding for international compatibility\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"ðŸ“ Created output directory: {output_dir}\")\n",
    "    \n",
    "    print(\"\\nðŸ­ Starting complete financial dataset generation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Dictionary to store all generated datasets\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Generate Stock Price Data\n",
    "        print(\"ðŸ“ˆ Generating stock market data...\")\n",
    "        print(\"   - 20 major US stocks (S&P 500 components)\")\n",
    "        print(\"   - Daily OHLCV format, business days only\")\n",
    "        print(\"   - 5 years of historical data (2020-2024)\")\n",
    "        \n",
    "        stock_data = self.generate_stock_prices(\n",
    "            symbols=self.stock_symbols[:20],  # Top 20 stocks for performance\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['stock_prices.csv'] = stock_data\n",
    "        print(f\"   âœ… Generated {len(stock_data):,} stock price records\")\n",
    "        \n",
    "        # 2. Generate Cryptocurrency Data  \n",
    "        print(\"\\nðŸ’Ž Generating cryptocurrency data...\")\n",
    "        print(\"   - 10 major cryptocurrencies by market cap\")\n",
    "        print(\"   - 6-hourly OHLCV format, 24/7 trading\")\n",
    "        print(\"   - Higher volatility modeling\")\n",
    "        \n",
    "        crypto_data = self.generate_crypto_prices(\n",
    "            symbols=self.crypto_symbols[:10],  # Top 10 cryptos\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['crypto_prices.csv'] = crypto_data\n",
    "        print(f\"   âœ… Generated {len(crypto_data):,} crypto price records\")\n",
    "        \n",
    "        # 3. Generate Economic Indicators\n",
    "        print(\"\\nðŸ›ï¸ Generating macroeconomic data...\")\n",
    "        print(\"   - 10 key economic indicators\")\n",
    "        print(\"   - Monthly frequency with mean reversion\")\n",
    "        print(\"   - Realistic bounds and relationships\")\n",
    "        \n",
    "        economic_data = self.generate_economic_data(\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31',\n",
    "            frequency='ME'  # Month-end frequency\n",
    "        )\n",
    "        datasets['economic_indicators.csv'] = economic_data\n",
    "        print(f\"   âœ… Generated {len(economic_data):,} economic data points\")\n",
    "        \n",
    "        # 4. Generate Portfolio Data\n",
    "        print(\"\\nðŸ’¼ Generating portfolio management data...\")\n",
    "        print(\"   - 100 diversified investment portfolios\")\n",
    "        print(\"   - Risk-based asset allocation (Conservative/Moderate/Aggressive)\")\n",
    "        print(\"   - Monthly rebalancing and performance tracking\")\n",
    "        \n",
    "        portfolio_data = self.generate_portfolio_data(\n",
    "            n_portfolios=100,\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['portfolio_data.csv'] = portfolio_data\n",
    "        print(f\"   âœ… Generated {len(portfolio_data):,} portfolio records\")\n",
    "        \n",
    "        # 5. Generate Customer Data\n",
    "        print(\"\\nðŸ‘¥ Generating customer demographics...\")\n",
    "        print(\"   - 10,000 realistic customer profiles\")\n",
    "        print(\"   - Credit scores, income, transaction behavior\")\n",
    "        print(\"   - Risk segmentation for analytics\")\n",
    "        \n",
    "        customer_data = self.generate_customer_data(n_customers=10000)\n",
    "        datasets['customer_data.csv'] = customer_data\n",
    "        print(f\"   âœ… Generated {len(customer_data):,} customer records\")\n",
    "        \n",
    "        # Save all datasets to CSV files\n",
    "        print(f\"\\nðŸ’¾ Saving datasets to {output_dir}/...\")\n",
    "        for filename, dataframe in datasets.items():\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Save with UTF-8 encoding and proper formatting\n",
    "            dataframe.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            file_size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            \n",
    "            print(f\"   ðŸ“„ Saved {filename}\")\n",
    "            print(f\"      - {len(dataframe):an()\n",
    "        print(f\"  {segment}: Income=${avg_income:,.0f}, Credit={avg_credit:.0f}, Balance=${avg_balance:,.0f}\")\n",
    "\n",
    "print(\"âœ… Customer data generation working correctly!\")\n",
    "print(\"ðŸ’¡ Data includes realistic correlations and distributions suitable for ML modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed9d40-50c0-467e-b8f0-f3916d59c75c",
   "metadata": {},
   "source": [
    "Production Data Pipeline and Export System\n",
    "==========================================\n",
    "\n",
    "This final cell brings together all our data generation methods into a \n",
    "production-ready pipeline that creates a complete FinTech dataset suitable\n",
    "for all 11 weeks of our Agile development sprints.\n",
    "\n",
    "Data Outputs:\n",
    "1. stock_prices.csv - Daily OHLCV data for major stocks\n",
    "2. crypto_prices.csv - 6-hourly cryptocurrency data  \n",
    "3. economic_indicators.csv - Monthly macroeconomic indicators\n",
    "4. portfolio_data.csv - Monthly portfolio holdings and performance\n",
    "5. customer_data.csv - Customer demographics and behavior\n",
    "\n",
    "File Format: CSV (Comma-Separated Values)\n",
    "- Portable across all platforms and tools\n",
    "- Easy to import into Python, R, SQL databases\n",
    "- Human-readable for data inspection\n",
    "- Compatible with Excel, Google Sheets\n",
    "\n",
    "Data Governance:\n",
    "- Consistent date formats (ISO 8601)\n",
    "- Standardized column naming (snake_case)\n",
    "- Appropriate data types and precision\n",
    "- Comprehensive metadata and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "182e25eb-3979-4c36-b05d-86af585a2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting complete FinTech dataset generation pipeline...\n",
      "â±ï¸  This may take 2-3 minutes depending on your system...\n",
      "ðŸ“ Created output directory: mock_financial_data\n",
      "\n",
      "ðŸ­ Starting complete financial dataset generation...\n",
      "============================================================\n",
      "ðŸ“ˆ Generating stock market data...\n",
      "   - 20 major US stocks (S&P 500 components)\n",
      "   - Daily OHLCV format, business days only\n",
      "   - 5 years of historical data (2020-2024)\n",
      "ðŸ“… Generating stock data for 1305 trading days\n",
      "ðŸ“ˆ Creating price series for 20 symbols\n",
      "  ðŸ“Š Processing AAPL (1/20)\n",
      "  ðŸ“Š Processing GOOGL (2/20)\n",
      "  ðŸ“Š Processing MSFT (3/20)\n",
      "  ðŸ“Š Processing AMZN (4/20)\n",
      "  ðŸ“Š Processing TSLA (5/20)\n",
      "  ðŸ“Š Processing META (6/20)\n",
      "  ðŸ“Š Processing NVDA (7/20)\n",
      "  ðŸ“Š Processing JPM (8/20)\n",
      "  ðŸ“Š Processing BAC (9/20)\n",
      "  ðŸ“Š Processing V (10/20)\n",
      "  ðŸ“Š Processing MA (11/20)\n",
      "  ðŸ“Š Processing JNJ (12/20)\n",
      "  ðŸ“Š Processing PG (13/20)\n",
      "  ðŸ“Š Processing UNH (14/20)\n",
      "  ðŸ“Š Processing PFE (15/20)\n",
      "  ðŸ“Š Processing KO (16/20)\n",
      "  ðŸ“Š Processing WMT (17/20)\n",
      "  ðŸ“Š Processing DIS (18/20)\n",
      "  ðŸ“Š Processing HD (19/20)\n",
      "  ðŸ“Š Processing NKE (20/20)\n",
      "âœ… Generated 26,100 stock price records\n",
      "ðŸ“Š Data shape: (26100, 7)\n",
      "   âœ… Generated 26,100 stock price records\n",
      "\n",
      "ðŸ’Ž Generating cryptocurrency data...\n",
      "   - 10 major cryptocurrencies by market cap\n",
      "   - 6-hourly OHLCV format, 24/7 trading\n",
      "   - Higher volatility modeling\n",
      "â° Generating crypto data for 7305 6-hour intervals\n",
      "ðŸ’Ž Creating price series for 10 cryptocurrencies\n",
      "ðŸŒ Modeling 24/7 global crypto markets\n",
      "  ðŸ’° Processing BTC (1/10)\n",
      "  ðŸ’° Processing ETH (2/10)\n",
      "  ðŸ’° Processing BNB (3/10)\n",
      "  ðŸ’° Processing XRP (4/10)\n",
      "  ðŸ’° Processing ADA (5/10)\n",
      "  ðŸ’° Processing DOGE (6/10)\n",
      "  ðŸ’° Processing SOL (7/10)\n",
      "  ðŸ’° Processing TRX (8/10)\n",
      "  ðŸ’° Processing DOT (9/10)\n",
      "  ðŸ’° Processing MATIC (10/10)\n",
      "âœ… Generated 73,050 cryptocurrency price records\n",
      "ðŸ“Š Data shape: (73050, 7)\n",
      "   âœ… Generated 73,050 crypto price records\n",
      "\n",
      "ðŸ›ï¸ Generating macroeconomic data...\n",
      "   - 10 key economic indicators\n",
      "   - Monthly frequency with mean reversion\n",
      "   - Realistic bounds and relationships\n",
      "ðŸ“Š Generating economic indicators for 60 periods\n",
      "ðŸ“… Frequency: ME (60 data points)\n",
      "ðŸ›ï¸ Modeling key macroeconomic relationships\n",
      "  ðŸ“ˆ Processing period 1/60: 2020-01\n",
      "  ðŸ“ˆ Processing period 2/60: 2020-02\n",
      "  ðŸ“ˆ Processing period 3/60: 2020-03\n",
      "  ðŸ“ˆ Processing period 4/60: 2020-04\n",
      "  ðŸ“ˆ Processing period 5/60: 2020-05\n",
      "  ðŸ“ˆ Processing period 6/60: 2020-06\n",
      "  ðŸ“ˆ Processing period 7/60: 2020-07\n",
      "  ðŸ“ˆ Processing period 8/60: 2020-08\n",
      "  ðŸ“ˆ Processing period 9/60: 2020-09\n",
      "  ðŸ“ˆ Processing period 10/60: 2020-10\n",
      "  ðŸ“ˆ Processing period 11/60: 2020-11\n",
      "  ðŸ“ˆ Processing period 12/60: 2020-12\n",
      "  ðŸ“ˆ Processing period 13/60: 2021-01\n",
      "  ðŸ“ˆ Processing period 14/60: 2021-02\n",
      "  ðŸ“ˆ Processing period 15/60: 2021-03\n",
      "  ðŸ“ˆ Processing period 16/60: 2021-04\n",
      "  ðŸ“ˆ Processing period 17/60: 2021-05\n",
      "  ðŸ“ˆ Processing period 18/60: 2021-06\n",
      "  ðŸ“ˆ Processing period 19/60: 2021-07\n",
      "  ðŸ“ˆ Processing period 20/60: 2021-08\n",
      "  ðŸ“ˆ Processing period 21/60: 2021-09\n",
      "  ðŸ“ˆ Processing period 22/60: 2021-10\n",
      "  ðŸ“ˆ Processing period 23/60: 2021-11\n",
      "  ðŸ“ˆ Processing period 24/60: 2021-12\n",
      "  ðŸ“ˆ Processing period 25/60: 2022-01\n",
      "  ðŸ“ˆ Processing period 26/60: 2022-02\n",
      "  ðŸ“ˆ Processing period 27/60: 2022-03\n",
      "  ðŸ“ˆ Processing period 28/60: 2022-04\n",
      "  ðŸ“ˆ Processing period 29/60: 2022-05\n",
      "  ðŸ“ˆ Processing period 30/60: 2022-06\n",
      "  ðŸ“ˆ Processing period 31/60: 2022-07\n",
      "  ðŸ“ˆ Processing period 32/60: 2022-08\n",
      "  ðŸ“ˆ Processing period 33/60: 2022-09\n",
      "  ðŸ“ˆ Processing period 34/60: 2022-10\n",
      "  ðŸ“ˆ Processing period 35/60: 2022-11\n",
      "  ðŸ“ˆ Processing period 36/60: 2022-12\n",
      "  ðŸ“ˆ Processing period 37/60: 2023-01\n",
      "  ðŸ“ˆ Processing period 38/60: 2023-02\n",
      "  ðŸ“ˆ Processing period 39/60: 2023-03\n",
      "  ðŸ“ˆ Processing period 40/60: 2023-04\n",
      "  ðŸ“ˆ Processing period 41/60: 2023-05\n",
      "  ðŸ“ˆ Processing period 42/60: 2023-06\n",
      "  ðŸ“ˆ Processing period 43/60: 2023-07\n",
      "  ðŸ“ˆ Processing period 44/60: 2023-08\n",
      "  ðŸ“ˆ Processing period 45/60: 2023-09\n",
      "  ðŸ“ˆ Processing period 46/60: 2023-10\n",
      "  ðŸ“ˆ Processing period 47/60: 2023-11\n",
      "  ðŸ“ˆ Processing period 48/60: 2023-12\n",
      "  ðŸ“ˆ Processing period 49/60: 2024-01\n",
      "  ðŸ“ˆ Processing period 50/60: 2024-02\n",
      "  ðŸ“ˆ Processing period 51/60: 2024-03\n",
      "  ðŸ“ˆ Processing period 52/60: 2024-04\n",
      "  ðŸ“ˆ Processing period 53/60: 2024-05\n",
      "  ðŸ“ˆ Processing period 54/60: 2024-06\n",
      "  ðŸ“ˆ Processing period 55/60: 2024-07\n",
      "  ðŸ“ˆ Processing period 56/60: 2024-08\n",
      "  ðŸ“ˆ Processing period 57/60: 2024-09\n",
      "  ðŸ“ˆ Processing period 58/60: 2024-10\n",
      "  ðŸ“ˆ Processing period 59/60: 2024-11\n",
      "  ðŸ“ˆ Processing period 60/60: 2024-12\n",
      "âœ… Generated 600 economic data points\n",
      "ðŸ“Š Data shape: (600, 3)\n",
      "\n",
      "ðŸ“ˆ Economic Indicator Ranges:\n",
      "  GDP_GROWTH: 1.46 to 3.59\n",
      "  INFLATION_RATE: 1.29 to 4.00\n",
      "  UNEMPLOYMENT_RATE: 3.11 to 6.04\n",
      "  INTEREST_RATE: 0.29 to 1.76\n",
      "  CONSUMER_CONFIDENCE: 85.65 to 119.37\n",
      "  RETAIL_SALES: -0.71 to 3.66\n",
      "  INDUSTRIAL_PRODUCTION: -0.72 to 3.03\n",
      "  HOUSING_STARTS: 1024707.47 to 1381179.57\n",
      "  TRADE_BALANCE: -111225.35 to -27215.41\n",
      "  MONEY_SUPPLY: 15399.62 to 21076.51\n",
      "   âœ… Generated 600 economic data points\n",
      "\n",
      "ðŸ’¼ Generating portfolio management data...\n",
      "   - 100 diversified investment portfolios\n",
      "   - Risk-based asset allocation (Conservative/Moderate/Aggressive)\n",
      "   - Monthly rebalancing and performance tracking\n",
      "ðŸ’¼ Generating portfolio data for 100 portfolios\n",
      "ðŸ“… Tracking 60 monthly periods\n",
      "ðŸ“Š Modeling Conservative, Moderate, and Aggressive risk profiles\n",
      "  ðŸ’¼ Processing portfolio 20/100\n",
      "  ðŸ’¼ Processing portfolio 40/100\n",
      "  ðŸ’¼ Processing portfolio 60/100\n",
      "  ðŸ’¼ Processing portfolio 80/100\n",
      "  ðŸ’¼ Processing portfolio 100/100\n",
      "âœ… Generated 6,000 portfolio records\n",
      "ðŸ“Š Data shape: (6000, 8)\n",
      "\n",
      "ðŸ“ˆ Portfolio Performance Summary by Risk Level:\n",
      "  Conservative: 5.6% return, 9.1% volatility, 38.3% stocks\n",
      "  Moderate: 7.3% return, 13.5% volatility, 57.0% stocks\n",
      "  Aggressive: 11.0% return, 20.0% volatility, 76.1% stocks\n",
      "   âœ… Generated 6,000 portfolio records\n",
      "\n",
      "ðŸ‘¥ Generating customer demographics...\n",
      "   - 10,000 realistic customer profiles\n",
      "   - Credit scores, income, transaction behavior\n",
      "   - Risk segmentation for analytics\n",
      "ðŸ‘¥ Generating customer data for 10,000 customers\n",
      "ðŸ“Š Modeling realistic demographic and behavioral patterns\n",
      "ðŸŽ¯ Creating data suitable for credit scoring, segmentation, and analytics\n",
      "  ðŸ‘¤ Processing customer 1,000/10,000\n",
      "  ðŸ‘¤ Processing customer 2,000/10,000\n",
      "  ðŸ‘¤ Processing customer 3,000/10,000\n",
      "  ðŸ‘¤ Processing customer 4,000/10,000\n",
      "  ðŸ‘¤ Processing customer 5,000/10,000\n",
      "  ðŸ‘¤ Processing customer 6,000/10,000\n",
      "  ðŸ‘¤ Processing customer 7,000/10,000\n",
      "  ðŸ‘¤ Processing customer 8,000/10,000\n",
      "  ðŸ‘¤ Processing customer 9,000/10,000\n",
      "  ðŸ‘¤ Processing customer 10,000/10,000\n",
      "âœ… Generated 10,000 customer records\n",
      "ðŸ“Š Data shape: (10000, 11)\n",
      "\n",
      "ðŸ‘¥ Customer Demographics Summary:\n",
      "  Average Age: 39.8 years\n",
      "  Average Income: $41,638\n",
      "  Average Credit Score: 690\n",
      "  Average Account Balance: $7,754\n",
      "\n",
      "ðŸ“Š Risk Segment Distribution:\n",
      "  Low Risk: 2,855 customers (28.5%)\n",
      "  Medium Risk: 5,391 customers (53.9%)\n",
      "  High Risk: 1,754 customers (17.5%)\n",
      "\n",
      "ðŸ’³ Loan Penetration: 249 customers (2.5%)\n",
      "   âœ… Generated 10,000 customer records\n",
      "\n",
      "ðŸ’¾ Saving datasets to mock_financial_data/...\n",
      "   ðŸ“„ Saved stock_prices.csv\n",
      "      - 26,100 rows Ã— 7 columns\n",
      "      - File size: 1.3 MB\n",
      "   ðŸ“„ Saved crypto_prices.csv\n",
      "      - 73,050 rows Ã— 7 columns\n",
      "      - File size: 4.5 MB\n",
      "   ðŸ“„ Saved economic_indicators.csv\n",
      "      - 600 rows Ã— 3 columns\n",
      "      - File size: 0.0 MB\n",
      "   ðŸ“„ Saved portfolio_data.csv\n",
      "      - 6,000 rows Ã— 8 columns\n",
      "      - File size: 0.4 MB\n",
      "   ðŸ“„ Saved customer_data.csv\n",
      "      - 10,000 rows Ã— 11 columns\n",
      "      - File size: 0.6 MB\n",
      "\n",
      "ðŸŽ‰ All datasets successfully saved to 'mock_financial_data' directory!\n",
      "\n",
      "ðŸ“Š Dataset Generation Summary:\n",
      "   - Total records: 115,750\n",
      "   - Total file size: 6.7 MB\n",
      "   - Data coverage: 2020-2024 (5 years)\n",
      "   - Asset classes: Stocks, Crypto, Economic, Portfolio, Customer\n",
      "\n",
      "======================================================================\n",
      "ðŸ“‹ DATASET PREVIEW AND VALIDATION\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š STOCK PRICES:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "      Date Symbol   Open   High    Low  Close   Volume\n",
      "2020-01-01   AAPL 362.42 364.30 362.42 364.09  4598546\n",
      "2020-01-02   AAPL 365.91 365.91 357.94 357.98   367620\n",
      "2020-01-03   AAPL 356.91 356.91 352.20 353.07 29745876\n",
      "\n",
      "Data Info:\n",
      "  Shape: (26100, 7)\n",
      "  Columns: ['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "  Missing values: 0\n",
      "  Symbols: 20, Date range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "ðŸ“Š CRYPTO PRICES:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "          Timestamp Symbol     Open     High      Low    Close  Volume\n",
      "2020-01-01 00:00:00    BTC 37445.66 37641.73 37445.66 37607.94  513543\n",
      "2020-01-01 06:00:00    BTC 38265.57 38918.27 37993.31 38353.88   14045\n",
      "2020-01-01 12:00:00    BTC 39178.44 39178.44 36829.42 38377.20   20102\n",
      "\n",
      "Data Info:\n",
      "  Shape: (73050, 7)\n",
      "  Columns: ['Timestamp', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "  Missing values: 0\n",
      "  Cryptocurrencies: 10, Time range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "ðŸ“Š ECONOMIC INDICATORS:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "      Date         Indicator  Value\n",
      "2020-01-31        GDP_GROWTH   2.39\n",
      "2020-01-31    INFLATION_RATE   1.95\n",
      "2020-01-31 UNEMPLOYMENT_RATE   5.10\n",
      "\n",
      "Data Info:\n",
      "  Shape: (600, 3)\n",
      "  Columns: ['Date', 'Indicator', 'Value']\n",
      "  Missing values: 0\n",
      "  Indicators: 10, Value range: -111225.35 to 1381179.57\n",
      "\n",
      "ðŸ“Š PORTFOLIO DATA:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "      Date PortfolioID RiskLevel  TotalValue  StockWeight  BondWeight  CashWeight  MonthlyReturn\n",
      "2020-01-31      PF_001  Moderate  1242670.88        0.569       0.382       0.049         0.0273\n",
      "2020-02-29      PF_001  Moderate  1297316.35        0.567       0.383       0.050         0.0440\n",
      "2020-03-31      PF_001  Moderate  1212010.39        0.562       0.388       0.050        -0.0658\n",
      "\n",
      "Data Info:\n",
      "  Shape: (6000, 8)\n",
      "  Columns: ['Date', 'PortfolioID', 'RiskLevel', 'TotalValue', 'StockWeight', 'BondWeight', 'CashWeight', 'MonthlyReturn']\n",
      "  Missing values: 0\n",
      "  Portfolios: 100, Risk distribution: {np.str_('Moderate'): 2640, np.str_('Conservative'): 2100, np.str_('Aggressive'): 1260}\n",
      "\n",
      "ðŸ“Š CUSTOMER DATA:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      " CustomerID  Age   Income  CreditScore  AccountAgeDays  AccountBalance  MonthlyTransactions  AvgTransactionAmount  NumProducts  HasLoan RiskSegment\n",
      "CUST_000001   66 20000.00          621             764         1111.06                   17                 26.79            2    False      Medium\n",
      "CUST_000002   41 36815.04          590            1789       110834.08                   54                 72.19            1    False        High\n",
      "CUST_000003   26 52834.47          748            1853          466.99                   61                124.66            1    False      Medium\n",
      "\n",
      "Data Info:\n",
      "  Shape: (10000, 11)\n",
      "  Columns: ['CustomerID', 'Age', 'Income', 'CreditScore', 'AccountAgeDays', 'AccountBalance', 'MonthlyTransactions', 'AvgTransactionAmount', 'NumProducts', 'HasLoan', 'RiskSegment']\n",
      "  Missing values: 0\n",
      "  Average age: 39.8, Risk segments: {'Medium': 5391, 'Low': 2855, 'High': 1754}\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ¯ DATA GENERATION COMPLETE - READY FOR AGILE SPRINTS!\n",
      "======================================================================\n",
      "\n",
      "ðŸš€ Your FinTech Data Pipeline is Ready!\n",
      "\n",
      "Next Steps for Week 1 Sprint:\n",
      "1. ðŸ“‹ Complete your project charter (use this data for problem statement)\n",
      "2. ðŸ‘¥ Form your squad (5 diverse team members)  \n",
      "3. ðŸ“Š Set up JIRA board with first sprint tasks\n",
      "4. ðŸ’¾ Import raw data into PostgreSQL database\n",
      "5. ðŸ”— Create your first SQL joins between datasets\n",
      "\n",
      "Week 2 Preview - Data Wrangling Tasks:\n",
      "â€¢ Clean and validate all CSV files\n",
      "â€¢ Handle missing values and outliers  \n",
      "â€¢ Create tidy data formats for analysis\n",
      "â€¢ Build your first exploratory visualizations\n",
      "â€¢ Generate data quality reports\n",
      "\n",
      "ðŸŽ“ Learning Objectives Achieved:\n",
      "âœ… Understand financial data structures (OHLCV, customer profiles)\n",
      "âœ… Apply statistical distributions to model real-world data\n",
      "âœ… Implement Object-Oriented Programming principles\n",
      "âœ… Create reproducible data pipelines with proper error handling\n",
      "âœ… Generate production-ready datasets for FinTech applications\n",
      "\n",
      "Happy coding! ðŸ’»ðŸ“ˆ\n",
      "\n",
      "\n",
      "ðŸ” Running final data validation checks...\n",
      "âœ… All validation checks passed!\n",
      "ðŸŽ‰ Dataset is ready for production use in your FinTech projects!\n",
      "\n",
      "ðŸ“ All files saved in: C:\\Users\\georg\\mock_financial_data\n",
      "ðŸŽ¯ Ready to begin your 11-week FinTech development journey!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Complete Dataset Generation and Export System\n",
    "\"\"\"\n",
    "Production Data Pipeline and Export System\n",
    "==========================================\n",
    "\n",
    "This final cell brings together all our data generation methods into a \n",
    "production-ready pipeline that creates a complete FinTech dataset suitable\n",
    "for all 11 weeks of our Agile development sprints.\n",
    "\n",
    "Data Outputs:\n",
    "1. stock_prices.csv - Daily OHLCV data for major stocks\n",
    "2. crypto_prices.csv - 6-hourly cryptocurrency data  \n",
    "3. economic_indicators.csv - Monthly macroeconomic indicators\n",
    "4. portfolio_data.csv - Monthly portfolio holdings and performance\n",
    "5. customer_data.csv - Customer demographics and behavior\n",
    "\n",
    "File Format: CSV (Comma-Separated Values)\n",
    "- Portable across all platforms and tools\n",
    "- Easy to import into Python, R, SQL databases\n",
    "- Human-readable for data inspection\n",
    "- Compatible with Excel, Google Sheets\n",
    "\n",
    "Data Governance:\n",
    "- Consistent date formats (ISO 8601)\n",
    "- Standardized column naming (snake_case)\n",
    "- Appropriate data types and precision\n",
    "- Comprehensive metadata and documentation\n",
    "\"\"\"\n",
    "\n",
    "def save_all_datasets(self, output_dir: str = 'mock_financial_data') -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate and save all financial datasets to CSV files.\n",
    "    \n",
    "    This method orchestrates the complete data generation pipeline:\n",
    "    1. Creates output directory structure\n",
    "    2. Generates all dataset types with appropriate parameters\n",
    "    3. Saves data in CSV format with proper encoding\n",
    "    4. Provides comprehensive logging and error handling\n",
    "    5. Returns datasets for immediate analysis\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory name for output files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all generated datasets\n",
    "        \n",
    "    Production Considerations:\n",
    "    - Error handling for file system operations\n",
    "    - Progress tracking for long-running operations  \n",
    "    - Memory-efficient processing for large datasets\n",
    "    - Consistent file naming conventions\n",
    "    - UTF-8 encoding for international compatibility\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"ðŸ“ Created output directory: {output_dir}\")\n",
    "    \n",
    "    print(\"\\nðŸ­ Starting complete financial dataset generation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Dictionary to store all generated datasets\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Generate Stock Price Data\n",
    "        print(\"ðŸ“ˆ Generating stock market data...\")\n",
    "        print(\"   - 20 major US stocks (S&P 500 components)\")\n",
    "        print(\"   - Daily OHLCV format, business days only\")\n",
    "        print(\"   - 5 years of historical data (2020-2024)\")\n",
    "        \n",
    "        stock_data = self.generate_stock_prices(\n",
    "            symbols=self.stock_symbols[:20],  # Top 20 stocks for performance\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['stock_prices.csv'] = stock_data\n",
    "        print(f\"   âœ… Generated {len(stock_data):,} stock price records\")\n",
    "        \n",
    "        # 2. Generate Cryptocurrency Data  \n",
    "        print(\"\\nðŸ’Ž Generating cryptocurrency data...\")\n",
    "        print(\"   - 10 major cryptocurrencies by market cap\")\n",
    "        print(\"   - 6-hourly OHLCV format, 24/7 trading\")\n",
    "        print(\"   - Higher volatility modeling\")\n",
    "        \n",
    "        crypto_data = self.generate_crypto_prices(\n",
    "            symbols=self.crypto_symbols[:10],  # Top 10 cryptos\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['crypto_prices.csv'] = crypto_data\n",
    "        print(f\"   âœ… Generated {len(crypto_data):,} crypto price records\")\n",
    "        \n",
    "        # 3. Generate Economic Indicators\n",
    "        print(\"\\nðŸ›ï¸ Generating macroeconomic data...\")\n",
    "        print(\"   - 10 key economic indicators\")\n",
    "        print(\"   - Monthly frequency with mean reversion\")\n",
    "        print(\"   - Realistic bounds and relationships\")\n",
    "        \n",
    "        economic_data = self.generate_economic_data(\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31',\n",
    "            frequency='ME'  # Month-end frequency\n",
    "        )\n",
    "        datasets['economic_indicators.csv'] = economic_data\n",
    "        print(f\"   âœ… Generated {len(economic_data):,} economic data points\")\n",
    "        \n",
    "        # 4. Generate Portfolio Data\n",
    "        print(\"\\nðŸ’¼ Generating portfolio management data...\")\n",
    "        print(\"   - 100 diversified investment portfolios\")\n",
    "        print(\"   - Risk-based asset allocation (Conservative/Moderate/Aggressive)\")\n",
    "        print(\"   - Monthly rebalancing and performance tracking\")\n",
    "        \n",
    "        portfolio_data = self.generate_portfolio_data(\n",
    "            n_portfolios=100,\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['portfolio_data.csv'] = portfolio_data\n",
    "        print(f\"   âœ… Generated {len(portfolio_data):,} portfolio records\")\n",
    "        \n",
    "        # 5. Generate Customer Data\n",
    "        print(\"\\nðŸ‘¥ Generating customer demographics...\")\n",
    "        print(\"   - 10,000 realistic customer profiles\")\n",
    "        print(\"   - Credit scores, income, transaction behavior\")\n",
    "        print(\"   - Risk segmentation for analytics\")\n",
    "        \n",
    "        customer_data = self.generate_customer_data(n_customers=10000)\n",
    "        datasets['customer_data.csv'] = customer_data\n",
    "        print(f\"   âœ… Generated {len(customer_data):,} customer records\")\n",
    "        \n",
    "        # Save all datasets to CSV files\n",
    "        print(f\"\\nðŸ’¾ Saving datasets to {output_dir}/...\")\n",
    "        for filename, dataframe in datasets.items():\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Save with UTF-8 encoding and proper formatting\n",
    "            dataframe.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            file_size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            \n",
    "            print(f\"   ðŸ“„ Saved {filename}\")\n",
    "            print(f\"      - {len(dataframe):,} rows Ã— {len(dataframe.columns)} columns\")\n",
    "            print(f\"      - File size: {file_size_mb:.1f} MB\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ All datasets successfully saved to '{output_dir}' directory!\")\n",
    "        \n",
    "        # Generate data summary report\n",
    "        total_records = sum(len(df) for df in datasets.values())\n",
    "        total_size_mb = sum(os.path.getsize(os.path.join(output_dir, f)) for f in datasets.keys()) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Dataset Generation Summary:\")\n",
    "        print(f\"   - Total records: {total_records:,}\")\n",
    "        print(f\"   - Total file size: {total_size_mb:.1f} MB\")\n",
    "        print(f\"   - Data coverage: 2020-2024 (5 years)\")\n",
    "        print(f\"   - Asset classes: Stocks, Crypto, Economic, Portfolio, Customer\")\n",
    "        \n",
    "        return datasets\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during dataset generation: {str(e)}\")\n",
    "        print(\"ðŸ”§ Check file permissions and available disk space\")\n",
    "        raise\n",
    "\n",
    "# Add the master method to our generator class\n",
    "FinancialDataGenerator.save_all_datasets = save_all_datasets\n",
    "\n",
    "# Execute the complete data generation pipeline\n",
    "print(\"ðŸš€ Starting complete FinTech dataset generation pipeline...\")\n",
    "print(\"â±ï¸  This may take 2-3 minutes depending on your system...\")\n",
    "\n",
    "# Generate all datasets\n",
    "all_datasets = generator.save_all_datasets()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“‹ DATASET PREVIEW AND VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display sample data from each dataset for validation\n",
    "for filename, dataframe in all_datasets.items():\n",
    "    print(f\"\\nðŸ“Š {filename.upper().replace('_', ' ').replace('.CSV', '')}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"Sample data:\")\n",
    "    print(dataframe.head(3).to_string(index=False))\n",
    "    \n",
    "    # Show data types and basic statistics\n",
    "    print(f\"\\nData Info:\")\n",
    "    print(f\"  Shape: {dataframe.shape}\")\n",
    "    print(f\"  Columns: {list(dataframe.columns)}\")\n",
    "    \n",
    "    # Show data quality metrics\n",
    "    missing_data = dataframe.isnull().sum().sum()\n",
    "    print(f\"  Missing values: {missing_data}\")\n",
    "    \n",
    "    # Dataset-specific insights\n",
    "    if 'stock_prices' in filename:\n",
    "        unique_symbols = dataframe['Symbol'].nunique()\n",
    "        date_range = f\"{dataframe['Date'].min()} to {dataframe['Date'].max()}\"\n",
    "        print(f\"  Symbols: {unique_symbols}, Date range: {date_range}\")\n",
    "        \n",
    "    elif 'crypto_prices' in filename:\n",
    "        unique_symbols = dataframe['Symbol'].nunique()\n",
    "        timestamp_range = f\"{dataframe['Timestamp'].min()} to {dataframe['Timestamp'].max()}\"\n",
    "        print(f\"  Cryptocurrencies: {unique_symbols}, Time range: {timestamp_range}\")\n",
    "        \n",
    "    elif 'economic_indicators' in filename:\n",
    "        unique_indicators = dataframe['Indicator'].nunique()\n",
    "        value_range = f\"{dataframe['Value'].min():.2f} to {dataframe['Value'].max():.2f}\"\n",
    "        print(f\"  Indicators: {unique_indicators}, Value range: {value_range}\")\n",
    "        \n",
    "    elif 'portfolio_data' in filename:\n",
    "        unique_portfolios = dataframe['PortfolioID'].nunique()\n",
    "        risk_levels = dataframe['RiskLevel'].value_counts().to_dict()\n",
    "        print(f\"  Portfolios: {unique_portfolios}, Risk distribution: {risk_levels}\")\n",
    "        \n",
    "    elif 'customer_data' in filename:\n",
    "        risk_distribution = dataframe['RiskSegment'].value_counts().to_dict()\n",
    "        avg_age = dataframe['Age'].mean()\n",
    "        print(f\"  Average age: {avg_age:.1f}, Risk segments: {risk_distribution}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸŽ¯ DATA GENERATION COMPLETE - READY FOR AGILE SPRINTS!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸš€ Your FinTech Data Pipeline is Ready!\n",
    "\n",
    "Next Steps for Week 1 Sprint:\n",
    "1. ðŸ“‹ Complete your project charter (use this data for problem statement)\n",
    "2. ðŸ‘¥ Form your squad (5 diverse team members)  \n",
    "3. ðŸ“Š Set up JIRA board with first sprint tasks\n",
    "4. ðŸ’¾ Import raw data into PostgreSQL database\n",
    "5. ðŸ”— Create your first SQL joins between datasets\n",
    "\n",
    "Week 2 Preview - Data Wrangling Tasks:\n",
    "â€¢ Clean and validate all CSV files\n",
    "â€¢ Handle missing values and outliers  \n",
    "â€¢ Create tidy data formats for analysis\n",
    "â€¢ Build your first exploratory visualizations\n",
    "â€¢ Generate data quality reports\n",
    "\n",
    "ðŸŽ“ Learning Objectives Achieved:\n",
    "âœ… Understand financial data structures (OHLCV, customer profiles)\n",
    "âœ… Apply statistical distributions to model real-world data\n",
    "âœ… Implement Object-Oriented Programming principles\n",
    "âœ… Create reproducible data pipelines with proper error handling\n",
    "âœ… Generate production-ready datasets for FinTech applications\n",
    "\n",
    "Happy coding! ðŸ’»ðŸ“ˆ\n",
    "\"\"\")\n",
    "\n",
    "# Optional: Quick data validation checks\n",
    "print(\"\\nðŸ” Running final data validation checks...\")\n",
    "\n",
    "# Check for data consistency\n",
    "validation_passed = True\n",
    "\n",
    "# Validate date ranges\n",
    "stock_dates = pd.to_datetime(all_datasets['stock_prices.csv']['Date'])\n",
    "if stock_dates.min().year != 2020 or stock_dates.max().year != 2024:\n",
    "    print(\"âš ï¸  Stock date range validation failed\")\n",
    "    validation_passed = False\n",
    "\n",
    "# Validate OHLC consistency (High >= Low, etc.)\n",
    "stock_data = all_datasets['stock_prices.csv']\n",
    "ohlc_valid = (\n",
    "    (stock_data['High'] >= stock_data['Low']).all() and\n",
    "    (stock_data['High'] >= stock_data['Open']).all() and  \n",
    "    (stock_data['High'] >= stock_data['Close']).all() and\n",
    "    (stock_data['Low'] <= stock_data['Open']).all() and\n",
    "    (stock_data['Low'] <= stock_data['Close']).all()\n",
    ")\n",
    "\n",
    "if not ohlc_valid:\n",
    "    print(\"âš ï¸  OHLC consistency validation failed\")\n",
    "    validation_passed = False\n",
    "    \n",
    "# Validate customer credit scores are in valid range\n",
    "customer_data = all_datasets['customer_data.csv']\n",
    "credit_valid = (\n",
    "    (customer_data['CreditScore'] >= 300).all() and\n",
    "    (customer_data['CreditScore'] <= 850).all()\n",
    ")\n",
    "\n",
    "if not credit_valid:\n",
    "    print(\"âš ï¸  Credit score range validation failed\")\n",
    "    validation_passed = False\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"âœ… All validation checks passed!\")\n",
    "    print(\"ðŸŽ‰ Dataset is ready for production use in your FinTech projects!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Some validation checks failed - please review the data\")\n",
    "\n",
    "print(f\"\\nðŸ“ All files saved in: {os.path.abspath('mock_financial_data')}\")\n",
    "print(\"ðŸŽ¯ Ready to begin your 11-week FinTech development journey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b52cf-d5b5-4ae7-aae1-850648e3daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Agile Sprint Integration Guide and Next Steps\n",
    "\"\"\"\n",
    "Integration with 11-Week FinTech Development Sprints\n",
    "===================================================\n",
    "\n",
    "This data generator supports all phases of your Agile FinTech project:\n",
    "\n",
    "ðŸƒâ€â™‚ï¸ SPRINT ROADMAP:\n",
    "\n",
    "Week 1 - Startup Onboarding:\n",
    "â€¢ Use generated data in your project charter problem statement\n",
    "â€¢ Import CSVs into PostgreSQL for SQL practice  \n",
    "â€¢ Form diverse squads with complementary skills\n",
    "\n",
    "Week 2 - Data Wrangling:\n",
    "â€¢ Clean and validate all generated datasets\n",
    "â€¢ Practice pandas/polars operations on realistic data\n",
    "â€¢ Create data quality reports and visualizations\n",
    "\n",
    "Week 3 - Classical Econometrics:\n",
    "â€¢ Run OLS regressions on stock prices vs economic indicators\n",
    "â€¢ Test cointegration between BTC and ETH prices\n",
    "â€¢ Build CAPM models using generated returns\n",
    "\n",
    "Week 4 - Time Series Forecasting:\n",
    "â€¢ Forecast stock prices using ARIMA models\n",
    "â€¢ Apply Prophet to cryptocurrency data\n",
    "â€¢ Compare forecasting performance across assets\n",
    "\n",
    "Week 5 - ML & Regularization:\n",
    "â€¢ Use customer data for credit scoring models\n",
    "â€¢ Apply Ridge/Lasso to portfolio optimization\n",
    "â€¢ Implement prompt-assisted feature engineering\n",
    "\n",
    "Week 6 - Tree Ensembles:\n",
    "â€¢ Build fraud detection models with customer transaction data\n",
    "â€¢ Use Random Forest for portfolio risk classification\n",
    "â€¢ Apply SHAP for model interpretability\n",
    "\n",
    "Week 7 - Dimensionality Reduction:\n",
    "â€¢ Apply PCA to economic indicators\n",
    "â€¢ Cluster customers by behavior patterns\n",
    "â€¢ Factor analysis of portfolio returns\n",
    "\n",
    "Week 8 - Deep Learning:\n",
    "â€¢ LSTM forecasting of crypto prices (24/7 data advantage)\n",
    "â€¢ RNN for sequential customer behavior modeling\n",
    "â€¢ Neural networks for portfolio optimization\n",
    "\n",
    "Week 9 - Portfolio Analytics:\n",
    "â€¢ Backtest trading strategies using generated price data\n",
    "â€¢ Risk-parity portfolio construction\n",
    "â€¢ Performance attribution analysis\n",
    "\n",
    "Week 10 - Model Audit:\n",
    "â€¢ Cross-validation on all generated datasets\n",
    "â€¢ Stress testing with economic scenario analysis\n",
    "â€¢ Model validation frameworks\n",
    "\n",
    "Week 11 - Productization:\n",
    "â€¢ Deploy models as FastAPI services\n",
    "â€¢ Create dashboards using generated data\n",
    "â€¢ Final board presentation with real insights\n",
    "\n",
    "ðŸ”§ TECHNICAL INTEGRATION TIPS:\n",
    "\"\"\"\n",
    "\n",
    "# Helper functions for ongoing sprint work\n",
    "def quick_data_loader(dataset_name: str, data_dir: str = 'mock_financial_data') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Quick loader for sprint work - use in subsequent notebooks.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: One of 'stocks', 'crypto', 'economic', 'portfolio', 'customer'\n",
    "        data_dir: Directory containing the CSV files\n",
    "        \n",
    "    Returns:\n",
    "        Loaded and basic-processed DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    filename_map = {\n",
    "        'stocks': 'stock_prices.csv',\n",
    "        'crypto': 'crypto_prices.csv', \n",
    "        'economic': 'economic_indicators.csv',\n",
    "        'portfolio': 'portfolio_data.csv',\n",
    "        'customer': 'customer_data.csv'\n",
    "    }\n",
    "    \n",
    "    if dataset_name not in filename_map:\n",
    "        raise ValueError(f\"Dataset must be one of: {list(filename_map.keys())}\")\n",
    "    \n",
    "    filepath = os.path.join(data_dir, filename_map[dataset_name])\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "    \n",
    "    # Load with appropriate parsing\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Apply basic preprocessing based on dataset type\n",
    "    if dataset_name in ['stocks', 'crypto']:\n",
    "        # Parse date columns\n",
    "        date_col = 'Date' if dataset_name == 'stocks' else 'Timestamp'\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "        df = df.sort_values([date_col, 'Symbol']).reset_index(drop=True)\n",
    "        \n",
    "    elif dataset_name == 'economic':\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values(['Date', 'Indicator']).reset_index(drop=True)\n",
    "        \n",
    "    elif dataset_name == 'portfolio':\n",
    "        df['Date'] = pd.to_datetime(df['Date'])  \n",
    "        df = df.sort_values(['Date', 'PortfolioID']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"âœ… Loaded {dataset_name} data: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def create_sprint_workspace(sprint_number: int, sprint_name: str):\n",
    "    \"\"\"\n",
    "    Create organized workspace for each sprint.\n",
    "    \n",
    "    Args:\n",
    "        sprint_number: Week number (1-11)\n",
    "        sprint_name: Descriptive name for the sprint\n",
    "    \"\"\"\n",
    "    \n",
    "    workspace_dir = f\"sprint_{sprint_number:02d}_{sprint_name.lower().replace(' ', '_')}\"\n",
    "    \n",
    "    # Create directory structure\n",
    "    dirs_to_create = [\n",
    "        workspace_dir,\n",
    "        os.path.join(workspace_dir, 'notebooks'),\n",
    "        os.path.join(workspace_dir, 'data'),\n",
    "        os.path.join(workspace_dir, 'models'),\n",
    "        os.path.join(workspace_dir, 'reports'),\n",
    "        os.path.join(workspace_dir, 'src')\n",
    "    ]\n",
    "    \n",
    "    for dir_path in dirs_to_create:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Create template files\n",
    "    readme_content = f\"\"\"# Sprint {sprint_number}: {sprint_name}\n",
    "\n",
    "## Objectives\n",
    "- [Add your sprint objectives here]\n",
    "\n",
    "## Datasets Used\n",
    "- Stock prices: Daily OHLCV data\n",
    "- Crypto prices: 6-hourly data\n",
    "- Economic indicators: Monthly data\n",
    "- Portfolio data: Monthly holdings\n",
    "- Customer data: Demographics and behavior\n",
    "\n",
    "## Deliverables\n",
    "- [ ] Jupyter notebook with analysis\n",
    "- [ ] Data quality report\n",
    "- [ ] Model/analysis results\n",
    "- [ ] Brief presentation slides\n",
    "\n",
    "## Team Members\n",
    "- Product Owner: [Name]\n",
    "- Scrum Master: [Name] \n",
    "- Developers: [Names]\n",
    "\n",
    "## Sprint Retrospective\n",
    "- What went well:\n",
    "- What could be improved:\n",
    "- Action items for next sprint:\n",
    "\"\"\"\n",
    "    \n",
    "    with open(os.path.join(workspace_dir, 'README.md'), 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(f\"ðŸ“ Created sprint workspace: {workspace_dir}\")\n",
    "    print(f\"ðŸ“‹ Template README.md created\")\n",
    "    print(f\"ðŸŽ¯ Ready for Sprint {sprint_number}: {sprint_name}\")\n",
    "\n",
    "def generate_data_dictionary():\n",
    "    \"\"\"Generate comprehensive data dictionary for all datasets.\"\"\"\n",
    "    \n",
    "    data_dict = {\n",
    "        'stock_prices.csv': {\n",
    "            'description': 'Daily stock price data in OHLCV format',\n",
    "            'columns': {\n",
    "                'Date': 'Trading date (business days only)',\n",
    "                'Symbol': 'Stock ticker symbol',\n",
    "                'Open': 'Opening price (USD)',\n",
    "                'High': 'Highest price during trading day (USD)',\n",
    "                'Low': 'Lowest price during trading day (USD)',\n",
    "                'Close': 'Closing price (USD)',\n",
    "                'Volume': 'Number of shares traded'\n",
    "            },\n",
    "            'frequency': 'Daily (business days)',\n",
    "            'date_range': '2020-01-01 to 2024-12-31'\n",
    "        },\n",
    "        \n",
    "        'crypto_prices.csv': {\n",
    "            'description': '6-hourly cryptocurrency price data',\n",
    "            'columns': {\n",
    "                'Timestamp': 'Trading timestamp (6-hour intervals)',\n",
    "                'Symbol': 'Cryptocurrency symbol',\n",
    "                'Open': 'Opening price (USD)',\n",
    "                'High': 'Highest price during 6-hour period (USD)',\n",
    "                'Low': 'Lowest price during 6-hour period (USD)',\n",
    "                'Close': 'Closing price (USD)',\n",
    "                'Volume': 'Number of units traded'\n",
    "            },\n",
    "            'frequency': '6-hourly (24/7 trading)',\n",
    "            'date_range': '2020-01-01 to 2024-12-31'\n",
    "        },\n",
    "        \n",
    "        'economic_indicators.csv': {\n",
    "            'description': 'Monthly macroeconomic indicators',\n",
    "            'columns': {\n",
    "                'Date': 'Month-end date',\n",
    "                'Indicator': 'Economic indicator name',\n",
    "                'Value': 'Indicator value (units vary by indicator)'\n",
    "            },\n",
    "            'frequency': 'Monthly',\n",
    "            'indicators': [\n",
    "                'GDP_GROWTH: GDP growth rate (%)',\n",
    "                'INFLATION_RATE: CPI inflation rate (%)',\n",
    "                'UNEMPLOYMENT_RATE: Unemployment rate (%)',\n",
    "                'INTEREST_RATE: Federal funds rate (%)',\n",
    "                'CONSUMER_CONFIDENCE: Consumer confidence index',\n",
    "                'RETAIL_SALES: Retail sales growth (%)',\n",
    "                'INDUSTRIAL_PRODUCTION: Industrial production growth (%)',\n",
    "                'HOUSING_STARTS: Housing starts (thousands of units)',\n",
    "                'TRADE_BALANCE: Trade balance (million USD)',\n",
    "                'MONEY_SUPPLY: M2 money supply (billion USD)'\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        'portfolio_data.csv': {\n",
    "            'description': 'Monthly portfolio holdings and performance',\n",
    "            'columns': {\n",
    "                'Date': 'Month-end date',\n",
    "                'PortfolioID': 'Unique portfolio identifier',\n",
    "                'RiskLevel': 'Risk profile (Conservative/Moderate/Aggressive)',\n",
    "                'TotalValue': 'Total portfolio value (USD)',\n",
    "                'StockWeight': 'Percentage allocated to stocks (0-1)',\n",
    "                'BondWeight': 'Percentage allocated to bonds (0-1)',\n",
    "                'CashWeight': 'Percentage held in cash (0-1)',\n",
    "                'MonthlyReturn': 'Monthly return rate (decimal)'\n",
    "            },\n",
    "            'frequency': 'Monthly',\n",
    "            'portfolios': 100\n",
    "        },\n",
    "        \n",
    "        'customer_data.csv': {\n",
    "            'description': 'Customer demographics and account information',\n",
    "            'columns': {\n",
    "                'CustomerID': 'Unique customer identifier',\n",
    "                'Age': 'Customer age (years)',\n",
    "                'Income': 'Annual income (USD)',\n",
    "                'CreditScore': 'FICO credit score (300-850)',\n",
    "                'AccountAgeDays': 'Days since account opening',\n",
    "                'AccountBalance': 'Current account balance (USD)',\n",
    "                'MonthlyTransactions': 'Average monthly transaction count',\n",
    "                'AvgTransactionAmount': 'Average transaction amount (USD)',\n",
    "                'NumProducts': 'Number of financial products held',\n",
    "                'HasLoan': 'Boolean - customer has active loan',\n",
    "                'RiskSegment': 'Risk classification (High/Medium/Low)'\n",
    "            },\n",
    "            'frequency': 'Cross-sectional (one record per customer)',\n",
    "            'customers': 10000\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save data dictionary as JSON\n",
    "    import json\n",
    "    with open('mock_financial_data/data_dictionary.json', 'w') as f:\n",
    "        json.dump(data_dict, f, indent=2)\n",
    "    \n",
    "    print(\"ðŸ“– Data dictionary created: mock_financial_data/data_dictionary.json\")\n",
    "    return data_dict\n",
    "\n",
    "# Demo the helper functions\n",
    "print(\"ðŸ› ï¸ SPRINT INTEGRATION TOOLS READY!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the quick loader\n",
    "print(\"\\nðŸ“Š Testing quick data loader...\")\n",
    "try:\n",
    "    sample_stocks = quick_data_loader('stocks')\n",
    "    print(f\"   Sample stock data loaded: {sample_stocks.shape}\")\n",
    "    print(f\"   Date range: {sample_stocks['Date'].min()} to {sample_stocks['Date'].max()}\")\n",
    "    print(f\"   Symbols: {sorted(sample_stocks['Symbol'].unique())}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Data not yet generated: {e}\")\n",
    "\n",
    "# Create sample sprint workspace\n",
    "print(\"\\nðŸ“ Creating sample sprint workspace...\")\n",
    "create_sprint_workspace(1, \"Startup Onboarding\")\n",
    "\n",
    "# Generate data dictionary\n",
    "print(\"\\nðŸ“– Generating data dictionary...\")\n",
    "data_dict = generate_data_dictionary()\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸŽ¯ READY FOR AGILE DEVELOPMENT!\n",
    "\n",
    "Your FinTech data pipeline is complete and ready to support all 11 sprints.\n",
    "\n",
    "Key Integration Points:\n",
    "âœ… Realistic financial data across all major asset classes\n",
    "âœ… Production-ready CSV formats for easy import\n",
    "âœ… Helper functions for sprint-specific data loading\n",
    "âœ… Workspace templates for organized development\n",
    "âœ… Comprehensive data dictionary for reference\n",
    "\n",
    "Next Actions:\n",
    "1. ðŸ“‹ Complete your project charter using this data\n",
    "2. ðŸ‘¥ Form your cross-functional squad\n",
    "3. ðŸŽ¯ Set up JIRA board with Sprint 1 tasks\n",
    "4. ðŸ’¾ Import data into PostgreSQL database\n",
    "5. ðŸ“ˆ Begin exploratory data analysis\n",
    "\n",
    "Good luck with your FinTech development journey! ðŸš€\n",
    "\"\"\")\n",
    "\n",
    "# Final memory cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"\\nðŸ”§ Memory cleanup completed - ready for next sprint!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
