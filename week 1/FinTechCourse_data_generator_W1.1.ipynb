{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbecb334-de9e-40e3-8cbe-4beaf9eb4c2c",
   "metadata": {},
   "source": [
    "\n",
    "FinTech Data Generator - Week 1 Sprint 0\n",
    "========================================\n",
    "\n",
    "This notebook creates realistic financial datasets for our 11-week FinTech project.\n",
    "We'll generate stock prices, crypto data, economic indicators, portfolio holdings, \n",
    "and customer demographics that mirror real-world financial data patterns.\n",
    "\n",
    "Learning Objectives:\n",
    "- Understand financial data structures (OHLCV format)\n",
    "- Learn about time series data generation using statistical models\n",
    "- Practice working with pandas DataFrames\n",
    "- Set up reproducible data pipelines using random seeds\n",
    "\n",
    "Key Concepts:\n",
    "- Geometric Brownian Motion for price modeling\n",
    "- Log-normal distributions for financial variables\n",
    "- Time series patterns and volatility clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd8ba87-4a55-49bc-ae7c-a34a2f400ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üìä Ready to generate realistic financial datasets for our FinTech project\n",
      "üéØ This data will support all 11 weeks of our Agile development sprints\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports for data manipulation and file operations\n",
    "import pandas as pd              # Data manipulation and analysis\n",
    "import numpy as np              # Numerical computing and random number generation\n",
    "from datetime import datetime, timedelta  # Date and time handling\n",
    "import random                   # Additional random number generation\n",
    "import os                      # Operating system interface for file operations\n",
    "from typing import Tuple, List, Dict  # Type hints for better code documentation\n",
    "\n",
    "# Display settings for better output formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üìä Ready to generate realistic financial datasets for our FinTech project\")\n",
    "print(\"üéØ This data will support all 11 weeks of our Agile development sprints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8954f-a918-4a54-b87a-03542aeeb2f8",
   "metadata": {},
   "source": [
    "Class-Based Data Generation Architecture\n",
    "=======================================\n",
    "\n",
    "We use Object-Oriented Programming (OOP) to organize our data generation logic.\n",
    "The FinancialDataGenerator class encapsulates all methods and market constants,\n",
    "making our code modular, reusable, and easy to maintain - key Agile principles!\n",
    "\n",
    "Key Financial Concepts:\n",
    "- Stock symbols represent publicly traded companies\n",
    "- Crypto symbols represent digital assets with 24/7 trading\n",
    "- Economic indicators measure macroeconomic health\n",
    "- Each asset class has different volatility and behavior patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb79db3-289c-4f9a-8fe9-47ea1320c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè≠ FinancialDataGenerator initialized with seed=42\n",
      "üìà Configured for 30 stock symbols\n",
      "üí∞ Configured for 15 crypto symbols\n",
      "üìä Tracking 10 economic indicators\n",
      "üîÑ All random generators seeded for reproducible results\n",
      "\n",
      "‚úÖ Generator class created successfully!\n",
      "üìù Next: We'll implement individual data generation methods\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FinancialDataGenerator:\n",
    "    \"\"\"\n",
    "    Comprehensive mock financial data generator for FinTech projects.\n",
    "    \n",
    "    This class (In Python, a class is a blueprint for generating objects (instances) that share the same data-attributes and behavior (methods),\n",
    "    creates realistic datasets that simulate:\n",
    "    1. Stock market behavior (geometric Brownian motion)\n",
    "    2. Cryptocurrency volatility (higher volatility, 24/7 trading)\n",
    "    3. Economic indicators (mean-reverting time series)\n",
    "    4. Portfolio allocations (risk-based asset allocation)\n",
    "    5. Customer demographics (realistic distributions)\n",
    "    \n",
    "    Design Pattern: This follows the Factory Pattern - one class that creates\n",
    "    multiple types of related objects (different financial datasets).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize the generator with predefined market data and random seed.\n",
    "        \n",
    "        Args:\n",
    "            seed: Random seed for reproducibility (crucial for testing and validation)\n",
    "        \n",
    "        Why use a seed?\n",
    "        - Ensures our data generation is reproducible\n",
    "        - Critical for debugging and validation\n",
    "        - Allows team members to generate identical datasets\n",
    "        - Follows best practices in quantitative finance\n",
    "        \"\"\"\n",
    "        # Set random seeds for reproducible results\n",
    "        np.random.seed(seed)  # NumPy random operations\n",
    "        random.seed(seed)     # Python random module operations\n",
    "        \n",
    "        # Define major stock symbols - representing different sectors and market caps\n",
    "        # These are real S&P 500 companies for realistic modeling\n",
    "        self.stock_symbols = [\n",
    "            # Technology Giants (FAANG + others)\n",
    "            'AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'META', 'NVDA', \n",
    "            \n",
    "            # Financial Services\n",
    "            'JPM', 'BAC', 'V', 'MA', \n",
    "            \n",
    "            # Healthcare & Consumer Goods\n",
    "            'JNJ', 'PG', 'UNH', 'PFE', 'KO', 'WMT',\n",
    "            \n",
    "            # Entertainment & Retail\n",
    "            'DIS', 'HD', 'NKE', 'COST',\n",
    "            \n",
    "            # Software & Cloud\n",
    "            'ADBE', 'CRM', 'ORCL', 'CSCO',\n",
    "            \n",
    "            # Traditional Industries\n",
    "            'T', 'VZ', 'XOM', 'CVX', 'IBM'\n",
    "        ]\n",
    "        \n",
    "        # Major cryptocurrency symbols by market capitalization (as of 2024-2025)\n",
    "        # Note: Crypto markets are more volatile and trade 24/7\n",
    "        self.crypto_symbols = [\n",
    "            'BTC',   # Bitcoin - digital gold, store of value\n",
    "            'ETH',   # Ethereum - smart contract platform\n",
    "            'BNB',   # Binance Coin - exchange token\n",
    "            'XRP',   # Ripple - cross-border payments\n",
    "            'ADA',   # Cardano - proof-of-stake blockchain\n",
    "            'DOGE',  # Dogecoin - meme coin with high volatility\n",
    "            'SOL',   # Solana - high-performance blockchain\n",
    "            'TRX',   # Tron - decentralized entertainment platform\n",
    "            'DOT',   # Polkadot - interoperability protocol\n",
    "            'MATIC', # Polygon - Ethereum scaling solution\n",
    "            'SHIB',  # Shiba Inu - another meme coin\n",
    "            'AVAX',  # Avalanche - smart contracts platform\n",
    "            'LTC',   # Litecoin - Bitcoin fork\n",
    "            'UNI',   # Uniswap - decentralized exchange token\n",
    "            'LINK'   # Chainlink - oracle network\n",
    "        ]\n",
    "        \n",
    "        # Key macroeconomic indicators that affect financial markets\n",
    "        # These drive fundamental analysis and economic forecasting\n",
    "        self.economic_indicators = [\n",
    "            'GDP_GROWTH',           # Gross Domestic Product growth rate\n",
    "            'INFLATION_RATE',       # Consumer Price Index changes\n",
    "            'UNEMPLOYMENT_RATE',    # Labor market health\n",
    "            'INTEREST_RATE',        # Federal funds rate (monetary policy)\n",
    "            'CONSUMER_CONFIDENCE',  # Consumer sentiment index\n",
    "            'RETAIL_SALES',         # Consumer spending patterns\n",
    "            'INDUSTRIAL_PRODUCTION',# Manufacturing output\n",
    "            'HOUSING_STARTS',       # Real estate market health\n",
    "            'TRADE_BALANCE',        # Imports vs exports\n",
    "            'MONEY_SUPPLY'          # M2 money supply (liquidity)\n",
    "        ]\n",
    "        \n",
    "        print(f\"üè≠ FinancialDataGenerator initialized with seed={seed}\")\n",
    "        print(f\"üìà Configured for {len(self.stock_symbols)} stock symbols\")\n",
    "        print(f\"üí∞ Configured for {len(self.crypto_symbols)} crypto symbols\") \n",
    "        print(f\"üìä Tracking {len(self.economic_indicators)} economic indicators\")\n",
    "        print(\"üîÑ All random generators seeded for reproducible results\")\n",
    "\n",
    "# Test the class initialization\n",
    "generator = FinancialDataGenerator(seed=42)\n",
    "print(\"\\n‚úÖ Generator class created successfully!\")\n",
    "print(\"üìù Next: We'll implement individual data generation methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc638db3-25bf-43a9-99b1-84274e04f36a",
   "metadata": {},
   "source": [
    "Stock Price Modeling: Geometric Brownian Motion (GBM)\n",
    "====================================================\n",
    "\n",
    "Financial Theory Background:\n",
    "- Stock prices follow a random walk with drift\n",
    "- Daily returns are approximately normally distributed\n",
    "- Prices cannot go negative (geometric vs arithmetic Brownian motion)\n",
    "- Volatility clustering: periods of high/low volatility tend to cluster\n",
    "\n",
    "The GBM Formula: S(t+1) = S(t) * exp(Œº*dt + œÉ*sqrt(dt)*Z)\n",
    "Where:\n",
    "- S(t) = current stock price\n",
    "- Œº = drift (expected return)\n",
    "- œÉ = volatility (standard deviation of returns)\n",
    "- Z = random normal variable\n",
    "- dt = time step (1 day = 1/252 years)\n",
    "\n",
    "OHLCV Format:\n",
    "- Open: First trade price of the day\n",
    "- High: Highest price during the day\n",
    "- Low: Lowest price during the day\n",
    "- Close: Last trade price of the day\n",
    "- Volume: Number of shares traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d908a54b-7bf7-4a45-becb-e57cb021bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing stock price generation with 3 symbols...\n",
      "üìÖ Generating stock data for 23 trading days\n",
      "üìà Creating price series for 3 symbols\n",
      "  üìä Processing AAPL (1/3)\n",
      "  üìä Processing GOOGL (2/3)\n",
      "  üìä Processing TSLA (3/3)\n",
      "‚úÖ Generated 69 stock price records\n",
      "üìä Data shape: (69, 7)\n",
      "\n",
      "üìà Sample Stock Data:\n",
      "        Date Symbol    Open    High     Low   Close   Volume\n",
      "0 2024-01-01   AAPL  195.47  215.52  195.47  208.73  3126595\n",
      "1 2024-01-02   AAPL  208.88  218.17  208.88  218.04  8566710\n",
      "2 2024-01-03   AAPL  217.65  221.85  217.65  221.28  2209596\n",
      "3 2024-01-04   AAPL  219.81  223.62  219.81  222.72   498495\n",
      "4 2024-01-05   AAPL  224.40  224.40  216.30  218.74  1278784\n",
      "\n",
      "üìä Price range for AAPL: $192.08 - $222.72\n",
      "‚úÖ Stock price generation method working correctly!\n"
     ]
    }
   ],
   "source": [
    "def generate_stock_prices(self, \n",
    "                         symbols: List[str] = None,\n",
    "                         start_date: str = '2020-01-01',\n",
    "                         end_date: str = '2024-12-31',\n",
    "                         initial_price_range: Tuple[float, float] = (20, 500)) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate realistic stock price data using Geometric Brownian Motion.\n",
    "    \n",
    "    This method simulates how stock prices evolve over time, incorporating:\n",
    "    1. Random price movements (market efficiency)\n",
    "    2. Volatility clustering (periods of high/low volatility)\n",
    "    3. Mean reversion tendencies (prices don't drift too far from fundamentals)\n",
    "    4. Realistic trading volumes correlated with price volatility\n",
    "    \n",
    "    Args:\n",
    "        symbols: List of stock symbols to generate (default: first 20 predefined)\n",
    "        start_date: Start date for price series\n",
    "        end_date: End date for price series  \n",
    "        initial_price_range: Range for starting stock prices\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, Symbol, Open, High, Low, Close, Volume\n",
    "        \n",
    "    Financial Insights:\n",
    "        - Higher volatility stocks have more dramatic price swings\n",
    "        - Volume increases during high volatility periods (realistic behavior)\n",
    "        - Mean reversion prevents prices from drifting to unrealistic levels\n",
    "        - Weekend gaps are handled by excluding weekends from trading days\n",
    "    \"\"\"\n",
    "    if symbols is None:\n",
    "        symbols = self.stock_symbols[:20]  # Use first 20 symbols for manageable dataset\n",
    "        \n",
    "    # Create business day range (exclude weekends - NYSE is closed Sat/Sun)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    business_days = date_range[date_range.weekday < 5]  # Monday=0, Friday=4\n",
    "    \n",
    "    print(f\"üìÖ Generating stock data for {len(business_days)} trading days\")\n",
    "    print(f\"üìà Creating price series for {len(symbols)} symbols\")\n",
    "    \n",
    "    all_stock_data = []\n",
    "    \n",
    "    for i, symbol in enumerate(symbols):\n",
    "        print(f\"  üìä Processing {symbol} ({i+1}/{len(symbols)})\")\n",
    "        \n",
    "        # Initialize stock-specific parameters\n",
    "        initial_price = np.random.uniform(*initial_price_range)\n",
    "        annual_volatility = np.random.uniform(0.15, 0.45)  # 15-45% annual volatility\n",
    "        daily_volatility = annual_volatility / np.sqrt(252)  # Convert to daily\n",
    "        \n",
    "        # Store prices for mean reversion calculation\n",
    "        prices = [initial_price]\n",
    "        volumes = []\n",
    "        \n",
    "        # Generate daily price evolution\n",
    "        for day_idx, date in enumerate(business_days):\n",
    "            # Base daily return components\n",
    "            base_drift = np.random.normal(0.0008, 0.002)  # ~20% annual drift with variation\n",
    "            volatility_shock = np.random.normal(0, daily_volatility)\n",
    "            \n",
    "            # Add mean reversion after 30 days (prevents unrealistic price drift)\n",
    "            if day_idx > 30:\n",
    "                # Calculate 30-day moving average\n",
    "                recent_avg = np.mean(prices[-30:])\n",
    "                mean_reversion_force = (recent_avg - prices[-1]) * 0.001\n",
    "                base_drift += mean_reversion_force\n",
    "            \n",
    "            # Apply geometric Brownian motion formula\n",
    "            price_multiplier = np.exp(base_drift + volatility_shock)\n",
    "            new_price = prices[-1] * price_multiplier\n",
    "            \n",
    "            # Apply circuit breakers (realistic market limits)\n",
    "            # No stock can drop more than 30% or gain more than 50% in one day\n",
    "            new_price = max(new_price, prices[-1] * 0.70)  # Max 30% daily drop\n",
    "            new_price = min(new_price, prices[-1] * 1.50)  # Max 50% daily gain\n",
    "            \n",
    "            prices.append(new_price)\n",
    "            \n",
    "            # Generate realistic trading volume\n",
    "            # Volume correlates with volatility (high volatility = high volume)\n",
    "            base_volume = np.random.lognormal(15, 1)  # Log-normal distribution for volume\n",
    "            volatility_multiplier = abs(volatility_shock) * 5 + 1\n",
    "            daily_volume = int(base_volume * volatility_multiplier)\n",
    "            volumes.append(daily_volume)\n",
    "        \n",
    "        # Convert daily close prices to OHLCV format\n",
    "        for day_idx, date in enumerate(business_days):\n",
    "            close_price = prices[day_idx + 1]  # +1 because prices[0] is initial\n",
    "            previous_close = prices[day_idx]\n",
    "            \n",
    "            # Generate intraday price range\n",
    "            intraday_volatility = abs(np.random.normal(0, daily_volatility * close_price))\n",
    "            \n",
    "            # Calculate OHLC with realistic constraints\n",
    "            high_price = close_price + np.random.uniform(0, 1) * intraday_volatility\n",
    "            low_price = close_price - np.random.uniform(0, 1) * intraday_volatility  \n",
    "            open_price = previous_close + np.random.normal(0, daily_volatility * previous_close * 0.3)\n",
    "            \n",
    "            # Ensure OHLC logical consistency: Low ‚â§ Open,Close ‚â§ High\n",
    "            high_price = max(high_price, open_price, close_price)\n",
    "            low_price = min(low_price, open_price, close_price)\n",
    "            \n",
    "            # Add to dataset\n",
    "            all_stock_data.append({\n",
    "                'Date': date,\n",
    "                'Symbol': symbol,\n",
    "                'Open': round(open_price, 2),\n",
    "                'High': round(high_price, 2), \n",
    "                'Low': round(low_price, 2),\n",
    "                'Close': round(close_price, 2),\n",
    "                'Volume': volumes[day_idx]\n",
    "            })\n",
    "    \n",
    "    stock_df = pd.DataFrame(all_stock_data)\n",
    "    print(f\"‚úÖ Generated {len(stock_df):,} stock price records\")\n",
    "    print(f\"üìä Data shape: {stock_df.shape}\")\n",
    "    return stock_df\n",
    "\n",
    "# Add the method to our generator class\n",
    "FinancialDataGenerator.generate_stock_prices = generate_stock_prices\n",
    "\n",
    "# Test the stock price generation\n",
    "print(\"üß™ Testing stock price generation with 3 symbols...\")\n",
    "test_stocks = generator.generate_stock_prices(\n",
    "    symbols=['AAPL', 'GOOGL', 'TSLA'], \n",
    "    start_date='2024-01-01', \n",
    "    end_date='2024-01-31'\n",
    ")\n",
    "\n",
    "print(\"\\nüìà Sample Stock Data:\")\n",
    "print(test_stocks.head())\n",
    "print(f\"\\nüìä Price range for AAPL: ${test_stocks[test_stocks['Symbol']=='AAPL']['Close'].min():.2f} - ${test_stocks[test_stocks['Symbol']=='AAPL']['Close'].max():.2f}\")\n",
    "print(\"‚úÖ Stock price generation method working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cb193-cb34-492e-9aca-4b13e60f26e5",
   "metadata": {},
   "source": [
    "print(test_stocks[test_stocks['Symbol'] == 'AAPL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0927de-cfb4-42d2-9370-01ce0b3b4b2a",
   "metadata": {},
   "source": [
    "Cryptocurrency Market Characteristics\n",
    "====================================\n",
    "\n",
    "Key Differences from Traditional Assets:\n",
    "1. 24/7 Trading: No market closure, continuous price discovery\n",
    "2. Higher Volatility: 50-120% annual volatility vs 15-45% for stocks  \n",
    "3. Less Liquidity: More susceptible to large price swings\n",
    "4. Market Sentiment: Heavily influenced by news, social media, regulatory events\n",
    "5. Technological Factors: Network upgrades, adoption metrics affect prices\n",
    "\n",
    "Time Frequency: 6-hour intervals (4 data points per day)\n",
    "This provides sufficient granularity while keeping dataset manageable.\n",
    "\n",
    "DeFi & Crypto Fundamentals:\n",
    "- Bitcoin: Digital gold, store of value narrative\n",
    "- Ethereum: Smart contract platform, powers DeFi ecosystem\n",
    "- Altcoins: Various use cases (payments, DeFi, NFTs, gaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2a675c-07d6-4ee2-b3ba-60ef17c11c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing crypto price generation with BTC and ETH...\n",
      "‚è∞ Generating crypto data for 25 6-hour intervals\n",
      "üíé Creating price series for 2 cryptocurrencies\n",
      "üåç Modeling 24/7 global crypto markets\n",
      "  üí∞ Processing BTC (1/2)\n",
      "  üí∞ Processing ETH (2/2)\n",
      "‚úÖ Generated 50 cryptocurrency price records\n",
      "üìä Data shape: (50, 7)\n",
      "\n",
      "üíé Sample Cryptocurrency Data:\n",
      "            Timestamp Symbol      Open      High       Low     Close  Volume\n",
      "0 2024-01-01 00:00:00    BTC  49291.92  49742.25  49291.92  49621.41   53815\n",
      "1 2024-01-01 06:00:00    BTC  48645.36  48844.56  48645.36  48788.78   82863\n",
      "2 2024-01-01 12:00:00    BTC  48484.04  50399.66  48484.04  50310.54  226355\n",
      "3 2024-01-01 18:00:00    BTC  49839.12  50870.34  49326.46  50450.39  142297\n",
      "4 2024-01-02 00:00:00    BTC  51631.66  51631.66  50589.41  50950.55  557573\n",
      "\n",
      "üìä BTC price range: $42166.45 - $51512.48\n",
      "üìä ETH price range: $3115.87 - $3497.23\n",
      "‚úÖ Cryptocurrency price generation working correctly!\n",
      "üåç Note: Crypto data includes 24/7 trading with 6-hour intervals\n"
     ]
    }
   ],
   "source": [
    "def generate_crypto_prices(self,\n",
    "                          symbols: List[str] = None,\n",
    "                          start_date: str = '2020-01-01', \n",
    "                          end_date: str = '2024-12-31') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate cryptocurrency price data with realistic 24/7 market behavior.\n",
    "    \n",
    "    Crypto markets exhibit unique characteristics:\n",
    "    - Much higher volatility (50-120% annually)\n",
    "    - 24/7 trading (no weekend gaps)\n",
    "    - Sentiment-driven price action\n",
    "    - Lower liquidity leads to more extreme movements\n",
    "    - Different behavior patterns for weekends vs weekdays\n",
    "    \n",
    "    Args:\n",
    "        symbols: List of crypto symbols (default: top 10 by market cap)\n",
    "        start_date: Start date for generation\n",
    "        end_date: End date for generation\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Timestamp, Symbol, Open, High, Low, Close, Volume\n",
    "        \n",
    "    Technical Implementation:\n",
    "        - 6-hour intervals (4 data points per day)\n",
    "        - Higher volatility parameters than stocks\n",
    "        - Weekend and night-time volume adjustments\n",
    "        - Realistic initial price ranges for major cryptocurrencies\n",
    "    \"\"\"\n",
    "    if symbols is None:\n",
    "        symbols = self.crypto_symbols[:10]  # Top 10 cryptocurrencies\n",
    "    \n",
    "    # Crypto trades 24/7 - generate 6-hour intervals\n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date, freq='h')\n",
    "    # Take every 6th hour: 00:00, 06:00, 12:00, 18:00 UTC\n",
    "    crypto_timestamps = full_date_range[::6]\n",
    "    \n",
    "    print(f\"‚è∞ Generating crypto data for {len(crypto_timestamps)} 6-hour intervals\")\n",
    "    print(f\"üíé Creating price series for {len(symbols)} cryptocurrencies\")\n",
    "    print(\"üåç Modeling 24/7 global crypto markets\")\n",
    "    \n",
    "    all_crypto_data = []\n",
    "    \n",
    "    # Realistic initial price ranges for major cryptocurrencies (USD)\n",
    "    # These reflect approximate price levels as of 2024-2025\n",
    "    initial_price_ranges = {\n",
    "        'BTC': (30000, 60000),    # Bitcoin: $30k-60k range\n",
    "        'ETH': (2000, 4000),      # Ethereum: $2k-4k range  \n",
    "        'BNB': (300, 600),        # Binance Coin: $300-600\n",
    "        'XRP': (0.5, 1.5),        # Ripple: $0.50-1.50\n",
    "        'ADA': (0.3, 1.2),        # Cardano: $0.30-1.20\n",
    "        'DOGE': (0.05, 0.3),      # Dogecoin: $0.05-0.30\n",
    "        'SOL': (50, 200),         # Solana: $50-200\n",
    "        'TRX': (0.06, 0.12),      # Tron: $0.06-0.12\n",
    "        'DOT': (5, 30),           # Polkadot: $5-30\n",
    "        'MATIC': (0.5, 2.5)       # Polygon: $0.50-2.50\n",
    "    }\n",
    "    \n",
    "    for i, symbol in enumerate(symbols):\n",
    "        print(f\"  üí∞ Processing {symbol} ({i+1}/{len(symbols)})\")\n",
    "        \n",
    "        # Set initial price and volatility for this crypto\n",
    "        price_range = initial_price_ranges.get(symbol, (1, 100))  # Default range for unlisted coins\n",
    "        initial_price = np.random.uniform(*price_range)\n",
    "        \n",
    "        # Crypto volatility is much higher than stocks\n",
    "        annual_volatility = np.random.uniform(0.5, 1.2)  # 50-120% annual volatility\n",
    "        six_hour_volatility = annual_volatility / np.sqrt(365 * 4)  # Convert to 6-hour periods\n",
    "        \n",
    "        prices = [initial_price]\n",
    "        volumes = []\n",
    "        \n",
    "        # Generate price evolution for each 6-hour period\n",
    "        for period_idx, timestamp in enumerate(crypto_timestamps):\n",
    "            # Base price movement\n",
    "            base_drift = np.random.normal(0, 0.001)  # Slightly positive expected return\n",
    "            volatility_shock = np.random.normal(0, six_hour_volatility)\n",
    "            \n",
    "            # Weekend effect: Crypto markets are less active on weekends\n",
    "            if timestamp.weekday() >= 5:  # Saturday=5, Sunday=6\n",
    "                base_drift *= 0.7  # Reduced weekend activity\n",
    "            \n",
    "            # Night time effect: Reduced activity during US night hours\n",
    "            if timestamp.hour < 6 or timestamp.hour > 22:\n",
    "                base_drift *= 0.5  # Lower overnight activity\n",
    "            \n",
    "            # Apply geometric Brownian motion with higher volatility bounds\n",
    "            price_multiplier = np.exp(base_drift + volatility_shock)\n",
    "            new_price = prices[-1] * price_multiplier\n",
    "            \n",
    "            # Crypto circuit breakers (more lenient than stocks due to higher volatility)\n",
    "            new_price = max(new_price, prices[-1] * 0.5)   # Max 50% period drop\n",
    "            new_price = min(new_price, prices[-1] * 2.0)   # Max 100% period gain\n",
    "            \n",
    "            prices.append(new_price)\n",
    "            \n",
    "            # Generate trading volume (crypto volumes are typically lower than stocks)\n",
    "            base_volume = np.random.lognormal(12, 1.5)  # Smaller base volume than stocks\n",
    "            volatility_multiplier = abs(volatility_shock) * 10 + 1  # Higher sensitivity to volatility\n",
    "            period_volume = int(base_volume * volatility_multiplier)\n",
    "            volumes.append(period_volume)\n",
    "        \n",
    "        # Convert to OHLCV format for each 6-hour period\n",
    "        for period_idx, timestamp in enumerate(crypto_timestamps):\n",
    "            close_price = prices[period_idx + 1]\n",
    "            previous_close = prices[period_idx]\n",
    "            \n",
    "            # Generate intraday range for 6-hour period\n",
    "            period_volatility = abs(np.random.normal(0, six_hour_volatility * close_price * 2))\n",
    "            \n",
    "            # Calculate OHLC\n",
    "            high_price = close_price + np.random.uniform(0, 1) * period_volatility\n",
    "            low_price = close_price - np.random.uniform(0, 1) * period_volatility\n",
    "            open_price = previous_close + np.random.normal(0, six_hour_volatility * previous_close)\n",
    "            \n",
    "            # Ensure OHLC consistency\n",
    "            high_price = max(high_price, open_price, close_price)\n",
    "            low_price = min(low_price, open_price, close_price)\n",
    "            \n",
    "            # Add to dataset with appropriate precision\n",
    "            # Crypto prices need more decimal places due to wide price ranges\n",
    "            decimal_places = 6 if close_price < 10 else 2\n",
    "            \n",
    "            all_crypto_data.append({\n",
    "                'Timestamp': timestamp,\n",
    "                'Symbol': symbol,\n",
    "                'Open': round(open_price, decimal_places),\n",
    "                'High': round(high_price, decimal_places),\n",
    "                'Low': round(low_price, decimal_places), \n",
    "                'Close': round(close_price, decimal_places),\n",
    "                'Volume': volumes[period_idx]\n",
    "            })\n",
    "    \n",
    "    crypto_df = pd.DataFrame(all_crypto_data)\n",
    "    print(f\"‚úÖ Generated {len(crypto_df):,} cryptocurrency price records\")\n",
    "    print(f\"üìä Data shape: {crypto_df.shape}\")\n",
    "    return crypto_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_crypto_prices = generate_crypto_prices\n",
    "\n",
    "# Test cryptocurrency generation\n",
    "print(\"üß™ Testing crypto price generation with BTC and ETH...\")\n",
    "test_crypto = generator.generate_crypto_prices(\n",
    "    symbols=['BTC', 'ETH'],\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-01-07'  # One week for testing\n",
    ")\n",
    "\n",
    "print(\"\\nüíé Sample Cryptocurrency Data:\")\n",
    "print(test_crypto.head())\n",
    "print(f\"\\nüìä BTC price range: ${test_crypto[test_crypto['Symbol']=='BTC']['Close'].min():.2f} - ${test_crypto[test_crypto['Symbol']=='BTC']['Close'].max():.2f}\")\n",
    "print(f\"üìä ETH price range: ${test_crypto[test_crypto['Symbol']=='ETH']['Close'].min():.2f} - ${test_crypto[test_crypto['Symbol']=='ETH']['Close'].max():.2f}\")\n",
    "print(\"‚úÖ Cryptocurrency price generation working correctly!\")\n",
    "print(\"üåç Note: Crypto data includes 24/7 trading with 6-hour intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23332460-06e1-43c5-9779-86bd7726e1aa",
   "metadata": {},
   "source": [
    "Macroeconomic Indicators and Market Impact\n",
    "=========================================\n",
    "\n",
    "Economic indicators are crucial for:\n",
    "1. Fundamental Analysis: Understanding economic health\n",
    "2. Market Prediction: Economic data drives asset prices\n",
    "3. Risk Assessment: Economic cycles affect all investments\n",
    "4. Policy Analysis: Central bank decisions impact markets\n",
    "\n",
    "Key Indicators We Model:\n",
    "- GDP Growth: Overall economic expansion/contraction\n",
    "- Inflation Rate: Price level changes (CPI-based)\n",
    "- Unemployment Rate: Labor market health\n",
    "- Interest Rate: Federal funds rate (monetary policy)\n",
    "- Consumer Confidence: Sentiment indicator\n",
    "- Retail Sales: Consumer spending patterns\n",
    "- Industrial Production: Manufacturing output\n",
    "- Housing Starts: Real estate market health\n",
    "\n",
    "Time Series Properties:\n",
    "- Mean Reversion: Economic indicators tend to revert to long-term averages\n",
    "- Persistence: Current values influence future values\n",
    "- Seasonality: Some indicators have seasonal patterns\n",
    "- Structural Breaks: Economic crises can shift baseline levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e7acd3-1fcf-4ece-9c17-12bdb9e76c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing economic data generation...\n",
      "üìä Generating economic indicators for 6 periods\n",
      "üìÖ Frequency: ME (6 data points)\n",
      "üèõÔ∏è Modeling key macroeconomic relationships\n",
      "  üìà Processing period 1/6: 2024-01\n",
      "  üìà Processing period 2/6: 2024-02\n",
      "  üìà Processing period 3/6: 2024-03\n",
      "  üìà Processing period 4/6: 2024-04\n",
      "  üìà Processing period 5/6: 2024-05\n",
      "  üìà Processing period 6/6: 2024-06\n",
      "‚úÖ Generated 60 economic data points\n",
      "üìä Data shape: (60, 3)\n",
      "\n",
      "üìà Economic Indicator Ranges:\n",
      "  GDP_GROWTH: 2.28 to 2.72\n",
      "  INFLATION_RATE: 2.08 to 3.16\n",
      "  UNEMPLOYMENT_RATE: 4.37 to 4.62\n",
      "  INTEREST_RATE: 1.22 to 1.45\n",
      "  CONSUMER_CONFIDENCE: 95.45 to 106.08\n",
      "  RETAIL_SALES: 0.48 to 2.16\n",
      "  INDUSTRIAL_PRODUCTION: 0.67 to 1.94\n",
      "  HOUSING_STARTS: 1201415.92 to 1280341.51\n",
      "  TRADE_BALANCE: -58678.27 to -47155.64\n",
      "  MONEY_SUPPLY: 15469.14 to 15469.14\n",
      "\n",
      "üèõÔ∏è Sample Economic Data:\n",
      "        Date              Indicator       Value\n",
      "0 2024-01-31             GDP_GROWTH        2.56\n",
      "1 2024-01-31         INFLATION_RATE        2.08\n",
      "2 2024-01-31      UNEMPLOYMENT_RATE        4.62\n",
      "3 2024-01-31          INTEREST_RATE        1.28\n",
      "4 2024-01-31    CONSUMER_CONFIDENCE      105.27\n",
      "5 2024-01-31           RETAIL_SALES        0.48\n",
      "6 2024-01-31  INDUSTRIAL_PRODUCTION        1.34\n",
      "7 2024-01-31         HOUSING_STARTS  1201415.92\n",
      "8 2024-01-31          TRADE_BALANCE   -49702.44\n",
      "9 2024-01-31           MONEY_SUPPLY    15469.14\n",
      "\n",
      "üìä GDP Growth over test period:\n",
      "         Date  Value\n",
      "0  2024-01-31   2.56\n",
      "10 2024-02-29   2.40\n",
      "20 2024-03-31   2.28\n",
      "30 2024-04-30   2.72\n",
      "40 2024-05-31   2.43\n",
      "‚úÖ Economic indicators generation working correctly!\n",
      "üìà Note: Data exhibits mean reversion and realistic bounds\n"
     ]
    }
   ],
   "source": [
    "def generate_economic_data(self,\n",
    "                          start_date: str = '2020-01-01',\n",
    "                          end_date: str = '2024-12-31', \n",
    "                          frequency: str = 'ME') -> pd.DataFrame:  # Changed from 'M' to 'ME'\n",
    "    \"\"\"\n",
    "    Generate macroeconomic indicator time series with realistic patterns.\n",
    "    \n",
    "    Economic indicators exhibit different behaviors than asset prices:\n",
    "    - Mean reversion to long-term equilibrium values\n",
    "    - Lower volatility than financial assets\n",
    "    - Autocorrelation (current values predict future values)\n",
    "    - Different measurement frequencies (monthly, quarterly)\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start date for data generation\n",
    "        end_date: End date for data generation\n",
    "        frequency: 'ME' for month-end, 'QE' for quarter-end, 'YE' for year-end\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, Indicator, Value\n",
    "        \n",
    "    Economic Theory Applied:\n",
    "    - Business Cycle: Indicators move together in cycles\n",
    "    - Phillips Curve: Inverse relationship between unemployment and inflation\n",
    "    - Taylor Rule: Interest rates respond to inflation and output gaps\n",
    "    \"\"\"\n",
    "    # Generate date range based on frequency\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=frequency)\n",
    "    \n",
    "    print(f\"üìä Generating economic indicators for {len(date_range)} periods\")\n",
    "    print(f\"üìÖ Frequency: {frequency} ({len(date_range)} data points)\")\n",
    "    print(\"üèõÔ∏è Modeling key macroeconomic relationships\")\n",
    "    \n",
    "    all_economic_data = []\n",
    "    \n",
    "    # Historical baseline values (approximately US averages 2020-2024)\n",
    "    # These represent \"normal\" economic conditions\n",
    "    baseline_values = {\n",
    "        'GDP_GROWTH': 2.5,          # 2.5% annual GDP growth\n",
    "        'INFLATION_RATE': 2.0,      # 2% Fed (as well as ECB) inflation target\n",
    "        'UNEMPLOYMENT_RATE': 5.0,   # ~5% natural rate of unemployment\n",
    "        'INTEREST_RATE': 1.5,       # Federal funds rate\n",
    "        'CONSUMER_CONFIDENCE': 100.0, # Index value (100 = baseline)\n",
    "        'RETAIL_SALES': 0.5,        # Monthly % change\n",
    "        'INDUSTRIAL_PRODUCTION': 1.0, # Monthly % change\n",
    "        'HOUSING_STARTS': 1200000,  # Annual units (in thousands)\n",
    "        'TRADE_BALANCE': -50000,    # Million USD (negative = deficit)\n",
    "        'MONEY_SUPPLY': 15000       # Billion USD (M2 money supply)\n",
    "    }\n",
    "    \n",
    "    # Initialize current values at baseline\n",
    "    current_values = baseline_values.copy()\n",
    "    \n",
    "    # Generate data for each time period\n",
    "    for date_idx, date in enumerate(date_range):\n",
    "        print(f\"  üìà Processing period {date_idx + 1}/{len(date_range)}: {date.strftime('%Y-%m')}\")\n",
    "        \n",
    "        for indicator in self.economic_indicators:\n",
    "            baseline = baseline_values[indicator]\n",
    "            current = current_values[indicator]\n",
    "            \n",
    "            # Mean reversion component\n",
    "            # Economic indicators tend to return to long-term averages\n",
    "            reversion_speed = 0.1  # 10% reversion per period\n",
    "            mean_reversion = (baseline - current) * reversion_speed\n",
    "            \n",
    "            # Random shock component (varies by indicator type)\n",
    "            if indicator in ['GDP_GROWTH', 'INFLATION_RATE', 'UNEMPLOYMENT_RATE']:\n",
    "                # Core economic indicators have moderate volatility\n",
    "                shock_std = 0.3\n",
    "            elif indicator == 'INTEREST_RATE':\n",
    "                # Interest rates change more gradually (Fed policy)\n",
    "                shock_std = 0.2\n",
    "            elif indicator == 'CONSUMER_CONFIDENCE':\n",
    "                # Sentiment can be quite volatile\n",
    "                shock_std = 5.0\n",
    "            elif indicator in ['RETAIL_SALES', 'INDUSTRIAL_PRODUCTION']:\n",
    "                # Monthly economic activity indicators\n",
    "                shock_std = 0.5\n",
    "            elif indicator == 'HOUSING_STARTS':\n",
    "                # Housing market can be quite volatile\n",
    "                shock_std = 50000\n",
    "            elif indicator == 'TRADE_BALANCE':\n",
    "                # Trade balance fluctuates with global conditions\n",
    "                shock_std = 10000\n",
    "            else:  # MONEY_SUPPLY\n",
    "                # Money supply grows steadily with occasional policy changes\n",
    "                shock_std = 500\n",
    "            \n",
    "            # Generate random shock\n",
    "            random_shock = np.random.normal(0, shock_std)\n",
    "            \n",
    "            # Calculate new value\n",
    "            new_value = current + mean_reversion + random_shock\n",
    "            \n",
    "            # Apply realistic bounds to prevent unrealistic values\n",
    "            if indicator == 'UNEMPLOYMENT_RATE':\n",
    "                new_value = max(2.0, min(15.0, new_value))  # 2-15% range\n",
    "            elif indicator == 'INFLATION_RATE':\n",
    "                new_value = max(-2.0, min(10.0, new_value))  # -2% to 10% range\n",
    "            elif indicator == 'INTEREST_RATE':\n",
    "                new_value = max(0.0, min(10.0, new_value))   # 0-10% range\n",
    "            elif indicator == 'CONSUMER_CONFIDENCE':\n",
    "                new_value = max(50, min(150, new_value))     # 50-150 index range\n",
    "            elif indicator == 'GDP_GROWTH':\n",
    "                new_value = max(-5.0, min(8.0, new_value))   # -5% to 8% growth range\n",
    "            elif indicator == 'HOUSING_STARTS':\n",
    "                new_value = max(500000, min(2000000, new_value))  # Realistic housing range\n",
    "            elif indicator == 'MONEY_SUPPLY':\n",
    "                new_value = max(new_value, current_values[indicator])  # Money supply rarely decreases\n",
    "            \n",
    "            # Update current value for next period\n",
    "            current_values[indicator] = new_value\n",
    "            \n",
    "            # Add to dataset\n",
    "            all_economic_data.append({\n",
    "                'Date': date,\n",
    "                'Indicator': indicator,\n",
    "                'Value': round(new_value, 2)\n",
    "            })\n",
    "    \n",
    "    economic_df = pd.DataFrame(all_economic_data)\n",
    "    print(f\"‚úÖ Generated {len(economic_df):,} economic data points\")\n",
    "    print(f\"üìä Data shape: {economic_df.shape}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nüìà Economic Indicator Ranges:\")\n",
    "    for indicator in self.economic_indicators:\n",
    "        indicator_data = economic_df[economic_df['Indicator'] == indicator]['Value']\n",
    "        print(f\"  {indicator}: {indicator_data.min():.2f} to {indicator_data.max():.2f}\")\n",
    "    \n",
    "    return economic_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_economic_data = generate_economic_data\n",
    "\n",
    "# Test economic data generation\n",
    "print(\"üß™ Testing economic data generation...\")\n",
    "test_economic = generator.generate_economic_data(\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-06-30',  # 6 months for testing\n",
    "    frequency='ME'  # Monthly data\n",
    ")\n",
    "\n",
    "print(\"\\nüèõÔ∏è Sample Economic Data:\")\n",
    "print(test_economic.head(10))\n",
    "\n",
    "# Show data for one specific indicator\n",
    "gdp_data = test_economic[test_economic['Indicator'] == 'GDP_GROWTH']\n",
    "print(f\"\\nüìä GDP Growth over test period:\")\n",
    "print(gdp_data[['Date', 'Value']].head())\n",
    "\n",
    "print(\"‚úÖ Economic indicators generation working correctly!\")\n",
    "print(\"üìà Note: Data exhibits mean reversion and realistic bounds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f394e-165c-42d3-938b-3796037c7de9",
   "metadata": {},
   "source": [
    "Portfolio Management and Asset Allocation Theory\n",
    "===============================================\n",
    "\n",
    "Modern Portfolio Theory (MPT) Concepts:\n",
    "1. Risk-Return Tradeoff: Higher expected returns require higher risk\n",
    "2. Diversification: Spreading investments across asset classes\n",
    "3. Asset Allocation: Strategic mix of stocks, bonds, cash based on risk tolerance\n",
    "4. Rebalancing: Adjusting portfolio weights over time\n",
    "\n",
    "Risk Profiles:\n",
    "- Conservative: Capital preservation, lower volatility, higher bond allocation\n",
    "- Moderate: Balanced growth and income, mixed allocation\n",
    "- Aggressive: Growth-focused, higher equity allocation, higher volatility\n",
    "\n",
    "Key Metrics We Generate:\n",
    "- Portfolio Value: Total market value of holdings\n",
    "- Asset Weights: Percentage allocation to stocks, bonds, cash\n",
    "- Monthly Returns: Period-over-period performance\n",
    "- Risk Level: Conservative, Moderate, Aggressive classification\n",
    "\n",
    "This data supports:\n",
    "- Portfolio optimization algorithms\n",
    "- Risk management systems\n",
    "- Performance attribution analysis\n",
    "- Client reporting and advisory services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07563f0-a4ec-4a30-b148-f366653a9b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing portfolio data generation...\n",
      "üíº Generating portfolio data for 5 portfolios\n",
      "üìÖ Tracking 6 monthly periods\n",
      "üìä Modeling Conservative, Moderate, and Aggressive risk profiles\n",
      "‚úÖ Generated 30 portfolio records\n",
      "üìä Data shape: (30, 8)\n",
      "\n",
      "üìà Portfolio Performance Summary by Risk Level:\n",
      "  Conservative: 9.0% return, 9.1% volatility, 44.5% stocks\n",
      "  Moderate: 7.7% return, 9.0% volatility, 57.1% stocks\n",
      "  Aggressive: 66.3% return, 16.9% volatility, 77.2% stocks\n",
      "\n",
      "üíº Sample Portfolio Data:\n",
      "        Date PortfolioID RiskLevel  TotalValue  StockWeight  BondWeight  \\\n",
      "0 2024-01-31      PF_001  Moderate   801471.58        0.515       0.388   \n",
      "1 2024-02-29      PF_001  Moderate   797281.44        0.519       0.386   \n",
      "2 2024-03-31      PF_001  Moderate   826790.11        0.542       0.365   \n",
      "3 2024-04-30      PF_001  Moderate   835570.01        0.538       0.371   \n",
      "4 2024-05-31      PF_001  Moderate   861796.67        0.545       0.359   \n",
      "\n",
      "   CashWeight  MonthlyReturn  \n",
      "0       0.097         0.0473  \n",
      "1       0.096        -0.0052  \n",
      "2       0.094         0.0370  \n",
      "3       0.092         0.0106  \n",
      "4       0.096         0.0314  \n",
      "\n",
      "üìä Portfolio PF_001 Evolution:\n",
      "        Date  TotalValue  StockWeight  MonthlyReturn\n",
      "0 2024-01-31   801471.58        0.515         0.0473\n",
      "1 2024-02-29   797281.44        0.519        -0.0052\n",
      "2 2024-03-31   826790.11        0.542         0.0370\n",
      "3 2024-04-30   835570.01        0.538         0.0106\n",
      "4 2024-05-31   861796.67        0.545         0.0314\n",
      "‚úÖ Portfolio data generation working correctly!\n",
      "üí° Data includes realistic risk-based allocations and performance patterns\n"
     ]
    }
   ],
   "source": [
    "def generate_portfolio_data(self,\n",
    "                           n_portfolios: int = 100,\n",
    "                           start_date: str = '2020-01-01',\n",
    "                           end_date: str = '2024-12-31') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate realistic portfolio holdings and performance data.\n",
    "    \n",
    "    Each portfolio has:\n",
    "    - Consistent risk profile (Conservative/Moderate/Aggressive)\n",
    "    - Realistic asset allocation based on risk tolerance\n",
    "    - Monthly rebalancing with small drifts\n",
    "    - Returns correlated with allocation and market conditions\n",
    "    \n",
    "    Args:\n",
    "        n_portfolios: Number of unique portfolios to generate\n",
    "        start_date: Start date for portfolio tracking\n",
    "        end_date: End date for portfolio tracking\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, PortfolioID, RiskLevel, TotalValue, \n",
    "                              StockWeight, BondWeight, CashWeight, MonthlyReturn\n",
    "                              \n",
    "    Portfolio Theory Implementation:\n",
    "    - Risk-based asset allocation follows industry standards\n",
    "    - Returns follow normal distribution with risk-appropriate parameters\n",
    "    - Allocation drift simulates real-world portfolio management\n",
    "    - Performance is consistent with risk profile expectations\n",
    "    \"\"\"\n",
    "    # Generate monthly date range for portfolio snapshots\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='ME')  # Month end frequency\n",
    "    \n",
    "    print(f\"üíº Generating portfolio data for {n_portfolios} portfolios\")\n",
    "    print(f\"üìÖ Tracking {len(date_range)} monthly periods\")\n",
    "    print(\"üìä Modeling Conservative, Moderate, and Aggressive risk profiles\")\n",
    "    \n",
    "    all_portfolio_data = []\n",
    "    \n",
    "    # Generate each portfolio's characteristics and evolution\n",
    "    for portfolio_id in range(1, n_portfolios + 1):\n",
    "        if portfolio_id % 20 == 0:  # Progress indicator\n",
    "            print(f\"  üíº Processing portfolio {portfolio_id}/{n_portfolios}\")\n",
    "        \n",
    "        # Randomly assign risk level (realistic distribution)\n",
    "        risk_level = np.random.choice(\n",
    "            ['Conservative', 'Moderate', 'Aggressive'], \n",
    "            p=[0.3, 0.5, 0.2]  # Most clients are moderate risk\n",
    "        )\n",
    "        \n",
    "        # Generate initial portfolio value (realistic range for different client types)\n",
    "        if risk_level == 'Conservative':\n",
    "            initial_value = np.random.uniform(500000, 5000000)  # Older, wealthier clients\n",
    "        elif risk_level == 'Moderate':\n",
    "            initial_value = np.random.uniform(100000, 2000000)  # Middle-market clients\n",
    "        else:  # Aggressive\n",
    "            initial_value = np.random.uniform(50000, 1000000)   # Younger, growth-oriented\n",
    "        \n",
    "        # Set risk-appropriate asset allocation and return expectations\n",
    "        if risk_level == 'Conservative':\n",
    "            # Capital preservation focus\n",
    "            base_stock_weight = np.random.uniform(0.3, 0.5)    # 30-50% stocks\n",
    "            base_bond_weight = np.random.uniform(0.4, 0.6)     # 40-60% bonds\n",
    "            base_cash_weight = 1 - base_stock_weight - base_bond_weight\n",
    "            expected_annual_return = 0.06  # 6% expected return\n",
    "            annual_volatility = 0.08       # 8% volatility\n",
    "            \n",
    "        elif risk_level == 'Moderate':\n",
    "            # Balanced growth and income\n",
    "            base_stock_weight = np.random.uniform(0.5, 0.7)    # 50-70% stocks\n",
    "            base_bond_weight = np.random.uniform(0.2, 0.4)     # 20-40% bonds\n",
    "            base_cash_weight = 1 - base_stock_weight - base_bond_weight\n",
    "            expected_annual_return = 0.08  # 8% expected return\n",
    "            annual_volatility = 0.12       # 12% volatility\n",
    "            \n",
    "        else:  # Aggressive\n",
    "            # Growth maximization\n",
    "            base_stock_weight = np.random.uniform(0.7, 0.9)    # 70-90% stocks\n",
    "            base_bond_weight = np.random.uniform(0.05, 0.2)    # 5-20% bonds\n",
    "            base_cash_weight = 1 - base_stock_weight - base_bond_weight\n",
    "            expected_annual_return = 0.10  # 10% expected return\n",
    "            annual_volatility = 0.18       # 18% volatility\n",
    "        \n",
    "        # Ensure weights sum to 1.0\n",
    "        total_weight = base_stock_weight + base_bond_weight + base_cash_weight\n",
    "        stock_weight = base_stock_weight / total_weight\n",
    "        bond_weight = base_bond_weight / total_weight\n",
    "        cash_weight = base_cash_weight / total_weight\n",
    "        \n",
    "        # Initialize portfolio tracking variables\n",
    "        current_value = initial_value\n",
    "        current_stock_weight = stock_weight\n",
    "        current_bond_weight = bond_weight\n",
    "        current_cash_weight = cash_weight\n",
    "        \n",
    "        # Generate monthly performance data\n",
    "        for date_idx, date in enumerate(date_range):\n",
    "            # Generate monthly return based on risk profile\n",
    "            # Convert annual parameters to monthly\n",
    "            monthly_expected_return = expected_annual_return / 12\n",
    "            monthly_volatility = annual_volatility / np.sqrt(12)\n",
    "            \n",
    "            # Add some market correlation (all portfolios affected by same market conditions)\n",
    "            market_factor = np.random.normal(0, 0.02)  # Common market movement\n",
    "            idiosyncratic_return = np.random.normal(monthly_expected_return, monthly_volatility)\n",
    "            monthly_return = idiosyncratic_return + market_factor * (stock_weight * 1.5)\n",
    "            \n",
    "            # Update portfolio value\n",
    "            current_value *= (1 + monthly_return)\n",
    "            \n",
    "            # Simulate allocation drift (realistic portfolio management)\n",
    "            # Weights drift slightly due to different asset class performance\n",
    "            drift_std = 0.02  # 2% standard deviation for weight changes\n",
    "            stock_drift = np.random.normal(0, drift_std)\n",
    "            bond_drift = np.random.normal(0, drift_std)\n",
    "            \n",
    "            current_stock_weight += stock_drift\n",
    "            current_bond_weight += bond_drift\n",
    "            \n",
    "            # Normalize weights to ensure they sum to 1.0\n",
    "            total_current_weight = current_stock_weight + current_bond_weight + current_cash_weight\n",
    "            current_stock_weight /= total_current_weight\n",
    "            current_bond_weight /= total_current_weight\n",
    "            current_cash_weight = 1 - current_stock_weight - current_bond_weight\n",
    "            \n",
    "            # Ensure no negative weights (realistic constraint)\n",
    "            current_stock_weight = max(0.05, min(0.95, current_stock_weight))\n",
    "            current_bond_weight = max(0.05, min(0.95, current_bond_weight))\n",
    "            current_cash_weight = max(0.05, min(0.95, current_cash_weight))\n",
    "            \n",
    "            # Re-normalize after applying bounds\n",
    "            total_bounded = current_stock_weight + current_bond_weight + current_cash_weight\n",
    "            current_stock_weight /= total_bounded\n",
    "            current_bond_weight /= total_bounded\n",
    "            current_cash_weight = 1 - current_stock_weight - current_bond_weight\n",
    "            \n",
    "            # Add record to dataset\n",
    "            all_portfolio_data.append({\n",
    "                'Date': date,\n",
    "                'PortfolioID': f'PF_{portfolio_id:03d}',\n",
    "                'RiskLevel': risk_level,\n",
    "                'TotalValue': round(current_value, 2),\n",
    "                'StockWeight': round(current_stock_weight, 3),\n",
    "                'BondWeight': round(current_bond_weight, 3),\n",
    "                'CashWeight': round(current_cash_weight, 3),\n",
    "                'MonthlyReturn': round(monthly_return, 4)\n",
    "            })\n",
    "    \n",
    "    portfolio_df = pd.DataFrame(all_portfolio_data)\n",
    "    print(f\"‚úÖ Generated {len(portfolio_df):,} portfolio records\")\n",
    "    print(f\"üìä Data shape: {portfolio_df.shape}\")\n",
    "    \n",
    "    # Display summary statistics by risk level\n",
    "    print(\"\\nüìà Portfolio Performance Summary by Risk Level:\")\n",
    "    for risk_level in ['Conservative', 'Moderate', 'Aggressive']:\n",
    "        risk_data = portfolio_df[portfolio_df['RiskLevel'] == risk_level]\n",
    "        avg_return = risk_data['MonthlyReturn'].mean() * 12 * 100  # Annualized %\n",
    "        volatility = risk_data['MonthlyReturn'].std() * np.sqrt(12) * 100  # Annualized %\n",
    "        avg_stock_weight = risk_data['StockWeight'].mean() * 100\n",
    "        \n",
    "        print(f\"  {risk_level}: {avg_return:.1f}% return, {volatility:.1f}% volatility, {avg_stock_weight:.1f}% stocks\")\n",
    "    \n",
    "    return portfolio_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_portfolio_data = generate_portfolio_data\n",
    "\n",
    "# Test portfolio data generation\n",
    "print(\"üß™ Testing portfolio data generation...\")\n",
    "test_portfolios = generator.generate_portfolio_data(\n",
    "    n_portfolios=5,  # Small test set\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-06-30'\n",
    ")\n",
    "\n",
    "print(\"\\nüíº Sample Portfolio Data:\")\n",
    "print(test_portfolios.head())\n",
    "\n",
    "# Show one portfolio's evolution over time\n",
    "portfolio_1 = test_portfolios[test_portfolios['PortfolioID'] == 'PF_001']\n",
    "print(f\"\\nüìä Portfolio PF_001 Evolution:\")\n",
    "print(portfolio_1[['Date', 'TotalValue', 'StockWeight', 'MonthlyReturn']].head())\n",
    "\n",
    "print(\"‚úÖ Portfolio data generation working correctly!\")\n",
    "print(\"üí° Data includes realistic risk-based allocations and performance patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf109c-f488-4d2d-99b7-2bcbd51209aa",
   "metadata": {},
   "source": [
    "FinTech Customer Analytics and Risk Modeling\n",
    "===========================================\n",
    "\n",
    "Customer data is crucial for:\n",
    "1. Credit Risk Assessment: Scoring models for lending decisions\n",
    "2. Customer Segmentation: Targeted product offerings and marketing\n",
    "3. Fraud Detection: Identifying unusual transaction patterns\n",
    "4. Regulatory Compliance: KYC (Know Your Customer) requirements\n",
    "5. Product Development: Understanding customer needs and behaviors\n",
    "\n",
    "Key Variables We Model:\n",
    "- Demographics: Age, income (realistic distributions)\n",
    "- Credit Profile: Credit score, existing loans\n",
    "- Account Behavior: Transaction frequency, amounts, tenure\n",
    "- Product Usage: Number of products, account balance\n",
    "- Risk Segmentation: High/Medium/Low risk classification\n",
    "\n",
    "Statistical Distributions Used:\n",
    "- Age: Normal distribution (mean=40, realistic range)\n",
    "- Income: Log-normal distribution (reflects real-world income inequality)\n",
    "- Credit Score: Normal distribution with realistic bounds (300-850)\n",
    "- Transaction Behavior: Poisson distribution for count data\n",
    "- Account Balance: Log-normal distribution\n",
    "\n",
    "This supports:\n",
    "- Credit scoring models\n",
    "- Customer lifetime value analysis\n",
    "- Churn prediction\n",
    "- Fraud detection systems\n",
    "- Regulatory reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d234e0-8193-4eb0-afe3-4db3cba9d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing customer data generation...\n",
      "üë• Generating customer data for 1,000 customers\n",
      "üìä Modeling realistic demographic and behavioral patterns\n",
      "üéØ Creating data suitable for credit scoring, segmentation, and analytics\n",
      "  üë§ Processing customer 1,000/1,000\n",
      "‚úÖ Generated 1,000 customer records\n",
      "üìä Data shape: (1000, 11)\n",
      "\n",
      "üë• Customer Demographics Summary:\n",
      "  Average Age: 40.2 years\n",
      "  Average Income: $41,936\n",
      "  Average Credit Score: 692\n",
      "  Average Account Balance: $7,453\n",
      "\n",
      "üìä Risk Segment Distribution:\n",
      "  Low Risk: 288 customers (28.8%)\n",
      "  Medium Risk: 542 customers (54.2%)\n",
      "  High Risk: 170 customers (17.0%)\n",
      "\n",
      "üí≥ Loan Penetration: 28 customers (2.8%)\n",
      "\n",
      "üë• Sample Customer Data:\n",
      "    CustomerID  Age    Income  CreditScore  AccountAgeDays  AccountBalance  \\\n",
      "0  CUST_000001   53  32516.99          688            1918          610.48   \n",
      "1  CUST_000002   42  21347.37          779            1023         5575.62   \n",
      "2  CUST_000003   53  39070.54          741            1137        12302.13   \n",
      "3  CUST_000004   30  28511.34          652            1620         3961.15   \n",
      "4  CUST_000005   55  46769.92          493            1112          407.36   \n",
      "\n",
      "   MonthlyTransactions  AvgTransactionAmount  NumProducts  HasLoan RiskSegment  \n",
      "0                   47                 30.73            1    False      Medium  \n",
      "1                   50                 33.70            2    False         Low  \n",
      "2                   49                 20.82            2    False      Medium  \n",
      "3                   49                 22.66            1    False      Medium  \n",
      "4                   54                 74.83            1    False        High  \n",
      "\n",
      "üìà Income vs Credit Score Correlation:\n",
      "Correlation coefficient: 0.087\n",
      "\n",
      "üéØ Risk Segment Statistics:\n",
      "  Low: Income=$44,205, Credit=802, Balance=$7,557\n",
      "  Medium: Income=$41,038, Credit=679, Balance=$6,467\n",
      "  High: Income=$40,958, Credit=548, Balance=$10,422\n",
      "‚úÖ Customer data generation working correctly!\n",
      "üí° Data includes realistic correlations and distributions suitable for ML modeling\n"
     ]
    }
   ],
   "source": [
    "def generate_customer_data(self, n_customers: int = 10000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate realistic customer demographic and account data for FinTech analysis.\n",
    "    \n",
    "    Creates a comprehensive customer database with correlated variables that\n",
    "    reflect real-world patterns in financial services:\n",
    "    - Income correlates with credit score and account balance\n",
    "    - Age affects risk tolerance and product usage\n",
    "    - Account tenure influences transaction behavior\n",
    "    - Risk segmentation based on credit score thresholds\n",
    "    \n",
    "    Args:\n",
    "        n_customers: Number of customer records to generate\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with customer demographics, account details, and risk metrics\n",
    "        \n",
    "    Data Science Applications:\n",
    "    - Feature engineering for ML models\n",
    "    - Customer segmentation analysis  \n",
    "    - Credit risk modeling\n",
    "    - Behavioral analytics\n",
    "    - A/B testing frameworks\n",
    "    \"\"\"\n",
    "    print(f\"üë• Generating customer data for {n_customers:,} customers\")\n",
    "    print(\"üìä Modeling realistic demographic and behavioral patterns\")\n",
    "    print(\"üéØ Creating data suitable for credit scoring, segmentation, and analytics\")\n",
    "    \n",
    "    all_customer_data = []\n",
    "    \n",
    "    # Generate each customer's profile\n",
    "    for customer_id in range(1, n_customers + 1):\n",
    "        if customer_id % 1000 == 0:  # Progress indicator\n",
    "            print(f\"  üë§ Processing customer {customer_id:,}/{n_customers:,}\")\n",
    "        \n",
    "        # Demographics\n",
    "        # Age: Normal distribution centered at 40 with realistic bounds\n",
    "        age = np.random.normal(40, 15)\n",
    "        age = max(18, min(80, int(age)))  # Legal age bounds\n",
    "        \n",
    "        # Income: Log-normal distribution (realistic income inequality)\n",
    "        # This creates a right-skewed distribution like real income data\n",
    "        log_income = np.random.lognormal(10.5, 0.5)  # Parameters chosen for realistic range\n",
    "        income = max(20000, min(500000, log_income))  # Reasonable bounds\n",
    "        \n",
    "        # Credit Score: Normal distribution with income correlation\n",
    "        # Higher income generally correlates with higher credit scores\n",
    "        income_effect = (income - 60000) / 100000 * 50  # Income influence on credit\n",
    "        base_credit_score = np.random.normal(700, 100)  # Base score\n",
    "        credit_score = base_credit_score + income_effect\n",
    "        credit_score = max(300, min(850, int(credit_score)))  # FICO range bounds\n",
    "        \n",
    "        # Account Details\n",
    "        # Account age: Uniform distribution with some bias toward newer accounts\n",
    "        account_age_days = np.random.randint(30, 2000)  # 1 month to ~5.5 years\n",
    "        \n",
    "        # Account Balance: Log-normal with correlation to income and credit score\n",
    "        # Higher income and credit scores lead to higher balances\n",
    "        income_factor = income / 60000  # Normalize around median income\n",
    "        credit_factor = credit_score / 700  # Normalize around good credit\n",
    "        balance_multiplier = (income_factor + credit_factor) / 2\n",
    "        \n",
    "        base_balance = np.random.lognormal(8, 1.5)  # Base log-normal distribution\n",
    "        account_balance = max(0, base_balance * balance_multiplier)\n",
    "        \n",
    "        # Transaction Behavior\n",
    "        # Monthly transactions: Poisson distribution (count data)\n",
    "        # More active users tend to have higher incomes and longer tenure\n",
    "        activity_factor = min(2.0, income / 50000 + account_age_days / 1000)\n",
    "        base_transaction_rate = 25  # Average transactions per month\n",
    "        monthly_transactions = np.random.poisson(base_transaction_rate * activity_factor)\n",
    "        \n",
    "        # Average transaction amount: Log-normal with income correlation\n",
    "        base_transaction_amount = np.random.lognormal(4, 1)  # Base amount\n",
    "        transaction_income_factor = max(0.5, income / 60000)\n",
    "        avg_transaction_amount = base_transaction_amount * transaction_income_factor\n",
    "        \n",
    "        # Product Usage\n",
    "        # Number of products: Poisson with income/age correlation\n",
    "        # Older, wealthier customers typically have more products\n",
    "        age_factor = max(0.5, age / 40)\n",
    "        income_product_factor = max(0.5, income / 60000)\n",
    "        product_rate = 2 * age_factor * income_product_factor\n",
    "        num_products = max(1, np.random.poisson(product_rate))\n",
    "        \n",
    "        # Loan Status: Probability based on age, income, and credit score\n",
    "        # Younger people and those with good credit more likely to have loans\n",
    "        age_loan_factor = max(0.1, (40 - age) / 40)  # Younger = higher probability\n",
    "        credit_loan_factor = max(0.1, (credit_score - 600) / 250)  # Better credit = higher prob\n",
    "        loan_probability = 0.3 * age_loan_factor * credit_loan_factor\n",
    "        has_loan = np.random.choice([True, False], p=[loan_probability, 1 - loan_probability])\n",
    "        \n",
    "        # Risk Segmentation based on credit score (industry standard thresholds)\n",
    "        if credit_score < 600:\n",
    "            risk_segment = 'High'      # Subprime\n",
    "        elif credit_score < 750:\n",
    "            risk_segment = 'Medium'    # Near prime\n",
    "        else:\n",
    "            risk_segment = 'Low'       # Prime\n",
    "        \n",
    "        # Compile customer record\n",
    "        all_customer_data.append({\n",
    "            'CustomerID': f'CUST_{customer_id:06d}',\n",
    "            'Age': age,\n",
    "            'Income': round(income, 2),\n",
    "            'CreditScore': credit_score,\n",
    "            'AccountAgeDays': account_age_days,\n",
    "            'AccountBalance': round(account_balance, 2),\n",
    "            'MonthlyTransactions': monthly_transactions,\n",
    "            'AvgTransactionAmount': round(avg_transaction_amount, 2),\n",
    "            'NumProducts': num_products,\n",
    "            'HasLoan': has_loan,\n",
    "            'RiskSegment': risk_segment\n",
    "        })\n",
    "    \n",
    "    customer_df = pd.DataFrame(all_customer_data)\n",
    "    print(f\"‚úÖ Generated {len(customer_df):,} customer records\")\n",
    "    print(f\"üìä Data shape: {customer_df.shape}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nüë• Customer Demographics Summary:\")\n",
    "    print(f\"  Average Age: {customer_df['Age'].mean():.1f} years\")\n",
    "    print(f\"  Average Income: ${customer_df['Income'].mean():,.0f}\")\n",
    "    print(f\"  Average Credit Score: {customer_df['CreditScore'].mean():.0f}\")\n",
    "    print(f\"  Average Account Balance: ${customer_df['AccountBalance'].mean():,.0f}\")\n",
    "    \n",
    "    print(\"\\nüìä Risk Segment Distribution:\")\n",
    "    risk_counts = customer_df['RiskSegment'].value_counts()\n",
    "    for segment in ['Low', 'Medium', 'High']:\n",
    "        count = risk_counts.get(segment, 0)\n",
    "        percentage = (count / len(customer_df)) * 100\n",
    "        print(f\"  {segment} Risk: {count:,} customers ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüí≥ Loan Penetration: {customer_df['HasLoan'].sum():,} customers ({customer_df['HasLoan'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    return customer_df\n",
    "\n",
    "# Add method to the generator class\n",
    "FinancialDataGenerator.generate_customer_data = generate_customer_data\n",
    "\n",
    "# Test customer data generation\n",
    "print(\"üß™ Testing customer data generation...\")\n",
    "test_customers = generator.generate_customer_data(n_customers=1000)  # Smaller test set\n",
    "\n",
    "print(\"\\nüë• Sample Customer Data:\")\n",
    "print(test_customers.head())\n",
    "\n",
    "# Show correlation analysis\n",
    "print(\"\\nüìà Income vs Credit Score Correlation:\")\n",
    "correlation = test_customers['Income'].corr(test_customers['CreditScore'])\n",
    "print(f\"Correlation coefficient: {correlation:.3f}\")\n",
    "\n",
    "# Risk segment analysis\n",
    "print(\"\\nüéØ Risk Segment Statistics:\")\n",
    "for segment in ['Low', 'Medium', 'High']:\n",
    "    segment_data = test_customers[test_customers['RiskSegment'] == segment]\n",
    "    if len(segment_data) > 0:\n",
    "        avg_income = segment_data['Income'].mean()\n",
    "        avg_credit = segment_data['CreditScore'].mean()\n",
    "        avg_balance = segment_data['AccountBalance'].me# Cell 8: Complete Dataset Generation and Export System\n",
    "\"\"\"\n",
    "Production Data Pipeline and Export System\n",
    "==========================================\n",
    "\n",
    "This final cell brings together all our data generation methods into a \n",
    "production-ready pipeline that creates a complete FinTech dataset suitable\n",
    "for all 11 weeks of our Agile development sprints.\n",
    "\n",
    "Data Outputs:\n",
    "1. stock_prices.csv - Daily OHLCV data for major stocks\n",
    "2. crypto_prices.csv - 6-hourly cryptocurrency data  \n",
    "3. economic_indicators.csv - Monthly macroeconomic indicators\n",
    "4. portfolio_data.csv - Monthly portfolio holdings and performance\n",
    "5. customer_data.csv - Customer demographics and behavior\n",
    "\n",
    "File Format: CSV (Comma-Separated Values)\n",
    "- Portable across all platforms and tools\n",
    "- Easy to import into Python, R, SQL databases\n",
    "- Human-readable for data inspection\n",
    "- Compatible with Excel, Google Sheets\n",
    "\n",
    "Data Governance:\n",
    "- Consistent date formats (ISO 8601)\n",
    "- Standardized column naming (snake_case)\n",
    "- Appropriate data types and precision\n",
    "- Comprehensive metadata and documentation\n",
    "\"\"\"\n",
    "\n",
    "def save_all_datasets(self, output_dir: str = 'mock_financial_data') -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate and save all financial datasets to CSV files.\n",
    "    \n",
    "    This method orchestrates the complete data generation pipeline:\n",
    "    1. Creates output directory structure\n",
    "    2. Generates all dataset types with appropriate parameters\n",
    "    3. Saves data in CSV format with proper encoding\n",
    "    4. Provides comprehensive logging and error handling\n",
    "    5. Returns datasets for immediate analysis\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory name for output files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all generated datasets\n",
    "        \n",
    "    Production Considerations:\n",
    "    - Error handling for file system operations\n",
    "    - Progress tracking for long-running operations  \n",
    "    - Memory-efficient processing for large datasets\n",
    "    - Consistent file naming conventions\n",
    "    - UTF-8 encoding for international compatibility\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Created output directory: {output_dir}\")\n",
    "    \n",
    "    print(\"\\nüè≠ Starting complete financial dataset generation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Dictionary to store all generated datasets\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Generate Stock Price Data\n",
    "        print(\"üìà Generating stock market data...\")\n",
    "        print(\"   - 20 major US stocks (S&P 500 components)\")\n",
    "        print(\"   - Daily OHLCV format, business days only\")\n",
    "        print(\"   - 5 years of historical data (2020-2024)\")\n",
    "        \n",
    "        stock_data = self.generate_stock_prices(\n",
    "            symbols=self.stock_symbols[:20],  # Top 20 stocks for performance\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['stock_prices.csv'] = stock_data\n",
    "        print(f\"   ‚úÖ Generated {len(stock_data):,} stock price records\")\n",
    "        \n",
    "        # 2. Generate Cryptocurrency Data  \n",
    "        print(\"\\nüíé Generating cryptocurrency data...\")\n",
    "        print(\"   - 10 major cryptocurrencies by market cap\")\n",
    "        print(\"   - 6-hourly OHLCV format, 24/7 trading\")\n",
    "        print(\"   - Higher volatility modeling\")\n",
    "        \n",
    "        crypto_data = self.generate_crypto_prices(\n",
    "            symbols=self.crypto_symbols[:10],  # Top 10 cryptos\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['crypto_prices.csv'] = crypto_data\n",
    "        print(f\"   ‚úÖ Generated {len(crypto_data):,} crypto price records\")\n",
    "        \n",
    "        # 3. Generate Economic Indicators\n",
    "        print(\"\\nüèõÔ∏è Generating macroeconomic data...\")\n",
    "        print(\"   - 10 key economic indicators\")\n",
    "        print(\"   - Monthly frequency with mean reversion\")\n",
    "        print(\"   - Realistic bounds and relationships\")\n",
    "        \n",
    "        economic_data = self.generate_economic_data(\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31',\n",
    "            frequency='ME'  # Month-end frequency\n",
    "        )\n",
    "        datasets['economic_indicators.csv'] = economic_data\n",
    "        print(f\"   ‚úÖ Generated {len(economic_data):,} economic data points\")\n",
    "        \n",
    "        # 4. Generate Portfolio Data\n",
    "        print(\"\\nüíº Generating portfolio management data...\")\n",
    "        print(\"   - 100 diversified investment portfolios\")\n",
    "        print(\"   - Risk-based asset allocation (Conservative/Moderate/Aggressive)\")\n",
    "        print(\"   - Monthly rebalancing and performance tracking\")\n",
    "        \n",
    "        portfolio_data = self.generate_portfolio_data(\n",
    "            n_portfolios=100,\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['portfolio_data.csv'] = portfolio_data\n",
    "        print(f\"   ‚úÖ Generated {len(portfolio_data):,} portfolio records\")\n",
    "        \n",
    "        # 5. Generate Customer Data\n",
    "        print(\"\\nüë• Generating customer demographics...\")\n",
    "        print(\"   - 10,000 realistic customer profiles\")\n",
    "        print(\"   - Credit scores, income, transaction behavior\")\n",
    "        print(\"   - Risk segmentation for analytics\")\n",
    "        \n",
    "        customer_data = self.generate_customer_data(n_customers=10000)\n",
    "        datasets['customer_data.csv'] = customer_data\n",
    "        print(f\"   ‚úÖ Generated {len(customer_data):,} customer records\")\n",
    "        \n",
    "        # Save all datasets to CSV files\n",
    "        print(f\"\\nüíæ Saving datasets to {output_dir}/...\")\n",
    "        for filename, dataframe in datasets.items():\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Save with UTF-8 encoding and proper formatting\n",
    "            dataframe.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            file_size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            \n",
    "            print(f\"   üìÑ Saved {filename}\")\n",
    "            print(f\"      - {len(dataframe):an()\n",
    "        print(f\"  {segment}: Income=${avg_income:,.0f}, Credit={avg_credit:.0f}, Balance=${avg_balance:,.0f}\")\n",
    "\n",
    "print(\"‚úÖ Customer data generation working correctly!\")\n",
    "print(\"üí° Data includes realistic correlations and distributions suitable for ML modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed9d40-50c0-467e-b8f0-f3916d59c75c",
   "metadata": {},
   "source": [
    "Production Data Pipeline and Export System\n",
    "==========================================\n",
    "\n",
    "This final cell brings together all our data generation methods into a \n",
    "production-ready pipeline that creates a complete FinTech dataset suitable\n",
    "for all 11 weeks of our Agile development sprints.\n",
    "\n",
    "Data Outputs:\n",
    "1. stock_prices.csv - Daily OHLCV data for major stocks\n",
    "2. crypto_prices.csv - 6-hourly cryptocurrency data  \n",
    "3. economic_indicators.csv - Monthly macroeconomic indicators\n",
    "4. portfolio_data.csv - Monthly portfolio holdings and performance\n",
    "5. customer_data.csv - Customer demographics and behavior\n",
    "\n",
    "File Format: CSV (Comma-Separated Values)\n",
    "- Portable across all platforms and tools\n",
    "- Easy to import into Python, R, SQL databases\n",
    "- Human-readable for data inspection\n",
    "- Compatible with Excel, Google Sheets\n",
    "\n",
    "Data Governance:\n",
    "- Consistent date formats (ISO 8601)\n",
    "- Standardized column naming (snake_case)\n",
    "- Appropriate data types and precision\n",
    "- Comprehensive metadata and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "182e25eb-3979-4c36-b05d-86af585a2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting complete FinTech dataset generation pipeline...\n",
      "‚è±Ô∏è  This may take 2-3 minutes depending on your system...\n",
      "üìÅ Created output directory: mock_financial_data\n",
      "\n",
      "üè≠ Starting complete financial dataset generation...\n",
      "============================================================\n",
      "üìà Generating stock market data...\n",
      "   - 20 major US stocks (S&P 500 components)\n",
      "   - Daily OHLCV format, business days only\n",
      "   - 5 years of historical data (2020-2024)\n",
      "üìÖ Generating stock data for 1305 trading days\n",
      "üìà Creating price series for 20 symbols\n",
      "  üìä Processing AAPL (1/20)\n",
      "  üìä Processing GOOGL (2/20)\n",
      "  üìä Processing MSFT (3/20)\n",
      "  üìä Processing AMZN (4/20)\n",
      "  üìä Processing TSLA (5/20)\n",
      "  üìä Processing META (6/20)\n",
      "  üìä Processing NVDA (7/20)\n",
      "  üìä Processing JPM (8/20)\n",
      "  üìä Processing BAC (9/20)\n",
      "  üìä Processing V (10/20)\n",
      "  üìä Processing MA (11/20)\n",
      "  üìä Processing JNJ (12/20)\n",
      "  üìä Processing PG (13/20)\n",
      "  üìä Processing UNH (14/20)\n",
      "  üìä Processing PFE (15/20)\n",
      "  üìä Processing KO (16/20)\n",
      "  üìä Processing WMT (17/20)\n",
      "  üìä Processing DIS (18/20)\n",
      "  üìä Processing HD (19/20)\n",
      "  üìä Processing NKE (20/20)\n",
      "‚úÖ Generated 26,100 stock price records\n",
      "üìä Data shape: (26100, 7)\n",
      "   ‚úÖ Generated 26,100 stock price records\n",
      "\n",
      "üíé Generating cryptocurrency data...\n",
      "   - 10 major cryptocurrencies by market cap\n",
      "   - 6-hourly OHLCV format, 24/7 trading\n",
      "   - Higher volatility modeling\n",
      "‚è∞ Generating crypto data for 7305 6-hour intervals\n",
      "üíé Creating price series for 10 cryptocurrencies\n",
      "üåç Modeling 24/7 global crypto markets\n",
      "  üí∞ Processing BTC (1/10)\n",
      "  üí∞ Processing ETH (2/10)\n",
      "  üí∞ Processing BNB (3/10)\n",
      "  üí∞ Processing XRP (4/10)\n",
      "  üí∞ Processing ADA (5/10)\n",
      "  üí∞ Processing DOGE (6/10)\n",
      "  üí∞ Processing SOL (7/10)\n",
      "  üí∞ Processing TRX (8/10)\n",
      "  üí∞ Processing DOT (9/10)\n",
      "  üí∞ Processing MATIC (10/10)\n",
      "‚úÖ Generated 73,050 cryptocurrency price records\n",
      "üìä Data shape: (73050, 7)\n",
      "   ‚úÖ Generated 73,050 crypto price records\n",
      "\n",
      "üèõÔ∏è Generating macroeconomic data...\n",
      "   - 10 key economic indicators\n",
      "   - Monthly frequency with mean reversion\n",
      "   - Realistic bounds and relationships\n",
      "üìä Generating economic indicators for 60 periods\n",
      "üìÖ Frequency: ME (60 data points)\n",
      "üèõÔ∏è Modeling key macroeconomic relationships\n",
      "  üìà Processing period 1/60: 2020-01\n",
      "  üìà Processing period 2/60: 2020-02\n",
      "  üìà Processing period 3/60: 2020-03\n",
      "  üìà Processing period 4/60: 2020-04\n",
      "  üìà Processing period 5/60: 2020-05\n",
      "  üìà Processing period 6/60: 2020-06\n",
      "  üìà Processing period 7/60: 2020-07\n",
      "  üìà Processing period 8/60: 2020-08\n",
      "  üìà Processing period 9/60: 2020-09\n",
      "  üìà Processing period 10/60: 2020-10\n",
      "  üìà Processing period 11/60: 2020-11\n",
      "  üìà Processing period 12/60: 2020-12\n",
      "  üìà Processing period 13/60: 2021-01\n",
      "  üìà Processing period 14/60: 2021-02\n",
      "  üìà Processing period 15/60: 2021-03\n",
      "  üìà Processing period 16/60: 2021-04\n",
      "  üìà Processing period 17/60: 2021-05\n",
      "  üìà Processing period 18/60: 2021-06\n",
      "  üìà Processing period 19/60: 2021-07\n",
      "  üìà Processing period 20/60: 2021-08\n",
      "  üìà Processing period 21/60: 2021-09\n",
      "  üìà Processing period 22/60: 2021-10\n",
      "  üìà Processing period 23/60: 2021-11\n",
      "  üìà Processing period 24/60: 2021-12\n",
      "  üìà Processing period 25/60: 2022-01\n",
      "  üìà Processing period 26/60: 2022-02\n",
      "  üìà Processing period 27/60: 2022-03\n",
      "  üìà Processing period 28/60: 2022-04\n",
      "  üìà Processing period 29/60: 2022-05\n",
      "  üìà Processing period 30/60: 2022-06\n",
      "  üìà Processing period 31/60: 2022-07\n",
      "  üìà Processing period 32/60: 2022-08\n",
      "  üìà Processing period 33/60: 2022-09\n",
      "  üìà Processing period 34/60: 2022-10\n",
      "  üìà Processing period 35/60: 2022-11\n",
      "  üìà Processing period 36/60: 2022-12\n",
      "  üìà Processing period 37/60: 2023-01\n",
      "  üìà Processing period 38/60: 2023-02\n",
      "  üìà Processing period 39/60: 2023-03\n",
      "  üìà Processing period 40/60: 2023-04\n",
      "  üìà Processing period 41/60: 2023-05\n",
      "  üìà Processing period 42/60: 2023-06\n",
      "  üìà Processing period 43/60: 2023-07\n",
      "  üìà Processing period 44/60: 2023-08\n",
      "  üìà Processing period 45/60: 2023-09\n",
      "  üìà Processing period 46/60: 2023-10\n",
      "  üìà Processing period 47/60: 2023-11\n",
      "  üìà Processing period 48/60: 2023-12\n",
      "  üìà Processing period 49/60: 2024-01\n",
      "  üìà Processing period 50/60: 2024-02\n",
      "  üìà Processing period 51/60: 2024-03\n",
      "  üìà Processing period 52/60: 2024-04\n",
      "  üìà Processing period 53/60: 2024-05\n",
      "  üìà Processing period 54/60: 2024-06\n",
      "  üìà Processing period 55/60: 2024-07\n",
      "  üìà Processing period 56/60: 2024-08\n",
      "  üìà Processing period 57/60: 2024-09\n",
      "  üìà Processing period 58/60: 2024-10\n",
      "  üìà Processing period 59/60: 2024-11\n",
      "  üìà Processing period 60/60: 2024-12\n",
      "‚úÖ Generated 600 economic data points\n",
      "üìä Data shape: (600, 3)\n",
      "\n",
      "üìà Economic Indicator Ranges:\n",
      "  GDP_GROWTH: 1.46 to 3.59\n",
      "  INFLATION_RATE: 1.29 to 4.00\n",
      "  UNEMPLOYMENT_RATE: 3.11 to 6.04\n",
      "  INTEREST_RATE: 0.29 to 1.76\n",
      "  CONSUMER_CONFIDENCE: 85.65 to 119.37\n",
      "  RETAIL_SALES: -0.71 to 3.66\n",
      "  INDUSTRIAL_PRODUCTION: -0.72 to 3.03\n",
      "  HOUSING_STARTS: 1024707.47 to 1381179.57\n",
      "  TRADE_BALANCE: -111225.35 to -27215.41\n",
      "  MONEY_SUPPLY: 15399.62 to 21076.51\n",
      "   ‚úÖ Generated 600 economic data points\n",
      "\n",
      "üíº Generating portfolio management data...\n",
      "   - 100 diversified investment portfolios\n",
      "   - Risk-based asset allocation (Conservative/Moderate/Aggressive)\n",
      "   - Monthly rebalancing and performance tracking\n",
      "üíº Generating portfolio data for 100 portfolios\n",
      "üìÖ Tracking 60 monthly periods\n",
      "üìä Modeling Conservative, Moderate, and Aggressive risk profiles\n",
      "  üíº Processing portfolio 20/100\n",
      "  üíº Processing portfolio 40/100\n",
      "  üíº Processing portfolio 60/100\n",
      "  üíº Processing portfolio 80/100\n",
      "  üíº Processing portfolio 100/100\n",
      "‚úÖ Generated 6,000 portfolio records\n",
      "üìä Data shape: (6000, 8)\n",
      "\n",
      "üìà Portfolio Performance Summary by Risk Level:\n",
      "  Conservative: 5.6% return, 9.1% volatility, 38.3% stocks\n",
      "  Moderate: 7.3% return, 13.5% volatility, 57.0% stocks\n",
      "  Aggressive: 11.0% return, 20.0% volatility, 76.1% stocks\n",
      "   ‚úÖ Generated 6,000 portfolio records\n",
      "\n",
      "üë• Generating customer demographics...\n",
      "   - 10,000 realistic customer profiles\n",
      "   - Credit scores, income, transaction behavior\n",
      "   - Risk segmentation for analytics\n",
      "üë• Generating customer data for 10,000 customers\n",
      "üìä Modeling realistic demographic and behavioral patterns\n",
      "üéØ Creating data suitable for credit scoring, segmentation, and analytics\n",
      "  üë§ Processing customer 1,000/10,000\n",
      "  üë§ Processing customer 2,000/10,000\n",
      "  üë§ Processing customer 3,000/10,000\n",
      "  üë§ Processing customer 4,000/10,000\n",
      "  üë§ Processing customer 5,000/10,000\n",
      "  üë§ Processing customer 6,000/10,000\n",
      "  üë§ Processing customer 7,000/10,000\n",
      "  üë§ Processing customer 8,000/10,000\n",
      "  üë§ Processing customer 9,000/10,000\n",
      "  üë§ Processing customer 10,000/10,000\n",
      "‚úÖ Generated 10,000 customer records\n",
      "üìä Data shape: (10000, 11)\n",
      "\n",
      "üë• Customer Demographics Summary:\n",
      "  Average Age: 39.8 years\n",
      "  Average Income: $41,638\n",
      "  Average Credit Score: 690\n",
      "  Average Account Balance: $7,754\n",
      "\n",
      "üìä Risk Segment Distribution:\n",
      "  Low Risk: 2,855 customers (28.5%)\n",
      "  Medium Risk: 5,391 customers (53.9%)\n",
      "  High Risk: 1,754 customers (17.5%)\n",
      "\n",
      "üí≥ Loan Penetration: 249 customers (2.5%)\n",
      "   ‚úÖ Generated 10,000 customer records\n",
      "\n",
      "üíæ Saving datasets to mock_financial_data/...\n",
      "   üìÑ Saved stock_prices.csv\n",
      "      - 26,100 rows √ó 7 columns\n",
      "      - File size: 1.3 MB\n",
      "   üìÑ Saved crypto_prices.csv\n",
      "      - 73,050 rows √ó 7 columns\n",
      "      - File size: 4.5 MB\n",
      "   üìÑ Saved economic_indicators.csv\n",
      "      - 600 rows √ó 3 columns\n",
      "      - File size: 0.0 MB\n",
      "   üìÑ Saved portfolio_data.csv\n",
      "      - 6,000 rows √ó 8 columns\n",
      "      - File size: 0.4 MB\n",
      "   üìÑ Saved customer_data.csv\n",
      "      - 10,000 rows √ó 11 columns\n",
      "      - File size: 0.6 MB\n",
      "\n",
      "üéâ All datasets successfully saved to 'mock_financial_data' directory!\n",
      "\n",
      "üìä Dataset Generation Summary:\n",
      "   - Total records: 115,750\n",
      "   - Total file size: 6.7 MB\n",
      "   - Data coverage: 2020-2024 (5 years)\n",
      "   - Asset classes: Stocks, Crypto, Economic, Portfolio, Customer\n",
      "\n",
      "======================================================================\n",
      "üìã DATASET PREVIEW AND VALIDATION\n",
      "======================================================================\n",
      "\n",
      "üìä STOCK PRICES:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "      Date Symbol   Open   High    Low  Close   Volume\n",
      "2020-01-01   AAPL 362.42 364.30 362.42 364.09  4598546\n",
      "2020-01-02   AAPL 365.91 365.91 357.94 357.98   367620\n",
      "2020-01-03   AAPL 356.91 356.91 352.20 353.07 29745876\n",
      "\n",
      "Data Info:\n",
      "  Shape: (26100, 7)\n",
      "  Columns: ['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "  Missing values: 0\n",
      "  Symbols: 20, Date range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "üìä CRYPTO PRICES:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "          Timestamp Symbol     Open     High      Low    Close  Volume\n",
      "2020-01-01 00:00:00    BTC 37445.66 37641.73 37445.66 37607.94  513543\n",
      "2020-01-01 06:00:00    BTC 38265.57 38918.27 37993.31 38353.88   14045\n",
      "2020-01-01 12:00:00    BTC 39178.44 39178.44 36829.42 38377.20   20102\n",
      "\n",
      "Data Info:\n",
      "  Shape: (73050, 7)\n",
      "  Columns: ['Timestamp', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "  Missing values: 0\n",
      "  Cryptocurrencies: 10, Time range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "üìä ECONOMIC INDICATORS:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "      Date         Indicator  Value\n",
      "2020-01-31        GDP_GROWTH   2.39\n",
      "2020-01-31    INFLATION_RATE   1.95\n",
      "2020-01-31 UNEMPLOYMENT_RATE   5.10\n",
      "\n",
      "Data Info:\n",
      "  Shape: (600, 3)\n",
      "  Columns: ['Date', 'Indicator', 'Value']\n",
      "  Missing values: 0\n",
      "  Indicators: 10, Value range: -111225.35 to 1381179.57\n",
      "\n",
      "üìä PORTFOLIO DATA:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      "      Date PortfolioID RiskLevel  TotalValue  StockWeight  BondWeight  CashWeight  MonthlyReturn\n",
      "2020-01-31      PF_001  Moderate  1242670.88        0.569       0.382       0.049         0.0273\n",
      "2020-02-29      PF_001  Moderate  1297316.35        0.567       0.383       0.050         0.0440\n",
      "2020-03-31      PF_001  Moderate  1212010.39        0.562       0.388       0.050        -0.0658\n",
      "\n",
      "Data Info:\n",
      "  Shape: (6000, 8)\n",
      "  Columns: ['Date', 'PortfolioID', 'RiskLevel', 'TotalValue', 'StockWeight', 'BondWeight', 'CashWeight', 'MonthlyReturn']\n",
      "  Missing values: 0\n",
      "  Portfolios: 100, Risk distribution: {np.str_('Moderate'): 2640, np.str_('Conservative'): 2100, np.str_('Aggressive'): 1260}\n",
      "\n",
      "üìä CUSTOMER DATA:\n",
      "--------------------------------------------------\n",
      "Sample data:\n",
      " CustomerID  Age   Income  CreditScore  AccountAgeDays  AccountBalance  MonthlyTransactions  AvgTransactionAmount  NumProducts  HasLoan RiskSegment\n",
      "CUST_000001   66 20000.00          621             764         1111.06                   17                 26.79            2    False      Medium\n",
      "CUST_000002   41 36815.04          590            1789       110834.08                   54                 72.19            1    False        High\n",
      "CUST_000003   26 52834.47          748            1853          466.99                   61                124.66            1    False      Medium\n",
      "\n",
      "Data Info:\n",
      "  Shape: (10000, 11)\n",
      "  Columns: ['CustomerID', 'Age', 'Income', 'CreditScore', 'AccountAgeDays', 'AccountBalance', 'MonthlyTransactions', 'AvgTransactionAmount', 'NumProducts', 'HasLoan', 'RiskSegment']\n",
      "  Missing values: 0\n",
      "  Average age: 39.8, Risk segments: {'Medium': 5391, 'Low': 2855, 'High': 1754}\n",
      "\n",
      "======================================================================\n",
      "üéØ DATA GENERATION COMPLETE - READY FOR AGILE SPRINTS!\n",
      "======================================================================\n",
      "\n",
      "üöÄ Your FinTech Data Pipeline is Ready!\n",
      "\n",
      "Next Steps for Week 1 Sprint:\n",
      "1. üìã Complete your project charter (use this data for problem statement)\n",
      "2. üë• Form your squad (5 diverse team members)  \n",
      "3. üìä Set up JIRA board with first sprint tasks\n",
      "4. üíæ Import raw data into PostgreSQL database\n",
      "5. üîó Create your first SQL joins between datasets\n",
      "\n",
      "Week 2 Preview - Data Wrangling Tasks:\n",
      "‚Ä¢ Clean and validate all CSV files\n",
      "‚Ä¢ Handle missing values and outliers  \n",
      "‚Ä¢ Create tidy data formats for analysis\n",
      "‚Ä¢ Build your first exploratory visualizations\n",
      "‚Ä¢ Generate data quality reports\n",
      "\n",
      "üéì Learning Objectives Achieved:\n",
      "‚úÖ Understand financial data structures (OHLCV, customer profiles)\n",
      "‚úÖ Apply statistical distributions to model real-world data\n",
      "‚úÖ Implement Object-Oriented Programming principles\n",
      "‚úÖ Create reproducible data pipelines with proper error handling\n",
      "‚úÖ Generate production-ready datasets for FinTech applications\n",
      "\n",
      "Happy coding! üíªüìà\n",
      "\n",
      "\n",
      "üîç Running final data validation checks...\n",
      "‚úÖ All validation checks passed!\n",
      "üéâ Dataset is ready for production use in your FinTech projects!\n",
      "\n",
      "üìÅ All files saved in: C:\\Users\\georg\\mock_financial_data\n",
      "üéØ Ready to begin your 11-week FinTech development journey!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Complete Dataset Generation and Export System\n",
    "\"\"\"\n",
    "Production Data Pipeline and Export System\n",
    "==========================================\n",
    "\n",
    "This final cell brings together all our data generation methods into a \n",
    "production-ready pipeline that creates a complete FinTech dataset suitable\n",
    "for all 11 weeks of our Agile development sprints.\n",
    "\n",
    "Data Outputs:\n",
    "1. stock_prices.csv - Daily OHLCV data for major stocks\n",
    "2. crypto_prices.csv - 6-hourly cryptocurrency data  \n",
    "3. economic_indicators.csv - Monthly macroeconomic indicators\n",
    "4. portfolio_data.csv - Monthly portfolio holdings and performance\n",
    "5. customer_data.csv - Customer demographics and behavior\n",
    "\n",
    "File Format: CSV (Comma-Separated Values)\n",
    "- Portable across all platforms and tools\n",
    "- Easy to import into Python, R, SQL databases\n",
    "- Human-readable for data inspection\n",
    "- Compatible with Excel, Google Sheets\n",
    "\n",
    "Data Governance:\n",
    "- Consistent date formats (ISO 8601)\n",
    "- Standardized column naming (snake_case)\n",
    "- Appropriate data types and precision\n",
    "- Comprehensive metadata and documentation\n",
    "\"\"\"\n",
    "\n",
    "def save_all_datasets(self, output_dir: str = 'mock_financial_data') -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate and save all financial datasets to CSV files.\n",
    "    \n",
    "    This method orchestrates the complete data generation pipeline:\n",
    "    1. Creates output directory structure\n",
    "    2. Generates all dataset types with appropriate parameters\n",
    "    3. Saves data in CSV format with proper encoding\n",
    "    4. Provides comprehensive logging and error handling\n",
    "    5. Returns datasets for immediate analysis\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory name for output files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all generated datasets\n",
    "        \n",
    "    Production Considerations:\n",
    "    - Error handling for file system operations\n",
    "    - Progress tracking for long-running operations  \n",
    "    - Memory-efficient processing for large datasets\n",
    "    - Consistent file naming conventions\n",
    "    - UTF-8 encoding for international compatibility\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Created output directory: {output_dir}\")\n",
    "    \n",
    "    print(\"\\nüè≠ Starting complete financial dataset generation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Dictionary to store all generated datasets\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Generate Stock Price Data\n",
    "        print(\"üìà Generating stock market data...\")\n",
    "        print(\"   - 20 major US stocks (S&P 500 components)\")\n",
    "        print(\"   - Daily OHLCV format, business days only\")\n",
    "        print(\"   - 5 years of historical data (2020-2024)\")\n",
    "        \n",
    "        stock_data = self.generate_stock_prices(\n",
    "            symbols=self.stock_symbols[:20],  # Top 20 stocks for performance\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['stock_prices.csv'] = stock_data\n",
    "        print(f\"   ‚úÖ Generated {len(stock_data):,} stock price records\")\n",
    "        \n",
    "        # 2. Generate Cryptocurrency Data  \n",
    "        print(\"\\nüíé Generating cryptocurrency data...\")\n",
    "        print(\"   - 10 major cryptocurrencies by market cap\")\n",
    "        print(\"   - 6-hourly OHLCV format, 24/7 trading\")\n",
    "        print(\"   - Higher volatility modeling\")\n",
    "        \n",
    "        crypto_data = self.generate_crypto_prices(\n",
    "            symbols=self.crypto_symbols[:10],  # Top 10 cryptos\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['crypto_prices.csv'] = crypto_data\n",
    "        print(f\"   ‚úÖ Generated {len(crypto_data):,} crypto price records\")\n",
    "        \n",
    "        # 3. Generate Economic Indicators\n",
    "        print(\"\\nüèõÔ∏è Generating macroeconomic data...\")\n",
    "        print(\"   - 10 key economic indicators\")\n",
    "        print(\"   - Monthly frequency with mean reversion\")\n",
    "        print(\"   - Realistic bounds and relationships\")\n",
    "        \n",
    "        economic_data = self.generate_economic_data(\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31',\n",
    "            frequency='ME'  # Month-end frequency\n",
    "        )\n",
    "        datasets['economic_indicators.csv'] = economic_data\n",
    "        print(f\"   ‚úÖ Generated {len(economic_data):,} economic data points\")\n",
    "        \n",
    "        # 4. Generate Portfolio Data\n",
    "        print(\"\\nüíº Generating portfolio management data...\")\n",
    "        print(\"   - 100 diversified investment portfolios\")\n",
    "        print(\"   - Risk-based asset allocation (Conservative/Moderate/Aggressive)\")\n",
    "        print(\"   - Monthly rebalancing and performance tracking\")\n",
    "        \n",
    "        portfolio_data = self.generate_portfolio_data(\n",
    "            n_portfolios=100,\n",
    "            start_date='2020-01-01',\n",
    "            end_date='2024-12-31'\n",
    "        )\n",
    "        datasets['portfolio_data.csv'] = portfolio_data\n",
    "        print(f\"   ‚úÖ Generated {len(portfolio_data):,} portfolio records\")\n",
    "        \n",
    "        # 5. Generate Customer Data\n",
    "        print(\"\\nüë• Generating customer demographics...\")\n",
    "        print(\"   - 10,000 realistic customer profiles\")\n",
    "        print(\"   - Credit scores, income, transaction behavior\")\n",
    "        print(\"   - Risk segmentation for analytics\")\n",
    "        \n",
    "        customer_data = self.generate_customer_data(n_customers=10000)\n",
    "        datasets['customer_data.csv'] = customer_data\n",
    "        print(f\"   ‚úÖ Generated {len(customer_data):,} customer records\")\n",
    "        \n",
    "        # Save all datasets to CSV files\n",
    "        print(f\"\\nüíæ Saving datasets to {output_dir}/...\")\n",
    "        for filename, dataframe in datasets.items():\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Save with UTF-8 encoding and proper formatting\n",
    "            dataframe.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            file_size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            \n",
    "            print(f\"   üìÑ Saved {filename}\")\n",
    "            print(f\"      - {len(dataframe):,} rows √ó {len(dataframe.columns)} columns\")\n",
    "            print(f\"      - File size: {file_size_mb:.1f} MB\")\n",
    "        \n",
    "        print(f\"\\nüéâ All datasets successfully saved to '{output_dir}' directory!\")\n",
    "        \n",
    "        # Generate data summary report\n",
    "        total_records = sum(len(df) for df in datasets.values())\n",
    "        total_size_mb = sum(os.path.getsize(os.path.join(output_dir, f)) for f in datasets.keys()) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"\\nüìä Dataset Generation Summary:\")\n",
    "        print(f\"   - Total records: {total_records:,}\")\n",
    "        print(f\"   - Total file size: {total_size_mb:.1f} MB\")\n",
    "        print(f\"   - Data coverage: 2020-2024 (5 years)\")\n",
    "        print(f\"   - Asset classes: Stocks, Crypto, Economic, Portfolio, Customer\")\n",
    "        \n",
    "        return datasets\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during dataset generation: {str(e)}\")\n",
    "        print(\"üîß Check file permissions and available disk space\")\n",
    "        raise\n",
    "\n",
    "# Add the master method to our generator class\n",
    "FinancialDataGenerator.save_all_datasets = save_all_datasets\n",
    "\n",
    "# Execute the complete data generation pipeline\n",
    "print(\"üöÄ Starting complete FinTech dataset generation pipeline...\")\n",
    "print(\"‚è±Ô∏è  This may take 2-3 minutes depending on your system...\")\n",
    "\n",
    "# Generate all datasets\n",
    "all_datasets = generator.save_all_datasets()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã DATASET PREVIEW AND VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display sample data from each dataset for validation\n",
    "for filename, dataframe in all_datasets.items():\n",
    "    print(f\"\\nüìä {filename.upper().replace('_', ' ').replace('.CSV', '')}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"Sample data:\")\n",
    "    print(dataframe.head(3).to_string(index=False))\n",
    "    \n",
    "    # Show data types and basic statistics\n",
    "    print(f\"\\nData Info:\")\n",
    "    print(f\"  Shape: {dataframe.shape}\")\n",
    "    print(f\"  Columns: {list(dataframe.columns)}\")\n",
    "    \n",
    "    # Show data quality metrics\n",
    "    missing_data = dataframe.isnull().sum().sum()\n",
    "    print(f\"  Missing values: {missing_data}\")\n",
    "    \n",
    "    # Dataset-specific insights\n",
    "    if 'stock_prices' in filename:\n",
    "        unique_symbols = dataframe['Symbol'].nunique()\n",
    "        date_range = f\"{dataframe['Date'].min()} to {dataframe['Date'].max()}\"\n",
    "        print(f\"  Symbols: {unique_symbols}, Date range: {date_range}\")\n",
    "        \n",
    "    elif 'crypto_prices' in filename:\n",
    "        unique_symbols = dataframe['Symbol'].nunique()\n",
    "        timestamp_range = f\"{dataframe['Timestamp'].min()} to {dataframe['Timestamp'].max()}\"\n",
    "        print(f\"  Cryptocurrencies: {unique_symbols}, Time range: {timestamp_range}\")\n",
    "        \n",
    "    elif 'economic_indicators' in filename:\n",
    "        unique_indicators = dataframe['Indicator'].nunique()\n",
    "        value_range = f\"{dataframe['Value'].min():.2f} to {dataframe['Value'].max():.2f}\"\n",
    "        print(f\"  Indicators: {unique_indicators}, Value range: {value_range}\")\n",
    "        \n",
    "    elif 'portfolio_data' in filename:\n",
    "        unique_portfolios = dataframe['PortfolioID'].nunique()\n",
    "        risk_levels = dataframe['RiskLevel'].value_counts().to_dict()\n",
    "        print(f\"  Portfolios: {unique_portfolios}, Risk distribution: {risk_levels}\")\n",
    "        \n",
    "    elif 'customer_data' in filename:\n",
    "        risk_distribution = dataframe['RiskSegment'].value_counts().to_dict()\n",
    "        avg_age = dataframe['Age'].mean()\n",
    "        print(f\"  Average age: {avg_age:.1f}, Risk segments: {risk_distribution}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ DATA GENERATION COMPLETE - READY FOR AGILE SPRINTS!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "üöÄ Your FinTech Data Pipeline is Ready!\n",
    "\n",
    "Next Steps for Week 1 Sprint:\n",
    "1. üìã Complete your project charter (use this data for problem statement)\n",
    "2. üë• Form your squad (5 diverse team members)  \n",
    "3. üìä Set up JIRA board with first sprint tasks\n",
    "4. üíæ Import raw data into PostgreSQL database\n",
    "5. üîó Create your first SQL joins between datasets\n",
    "\n",
    "Week 2 Preview - Data Wrangling Tasks:\n",
    "‚Ä¢ Clean and validate all CSV files\n",
    "‚Ä¢ Handle missing values and outliers  \n",
    "‚Ä¢ Create tidy data formats for analysis\n",
    "‚Ä¢ Build your first exploratory visualizations\n",
    "‚Ä¢ Generate data quality reports\n",
    "\n",
    "üéì Learning Objectives Achieved:\n",
    "‚úÖ Understand financial data structures (OHLCV, customer profiles)\n",
    "‚úÖ Apply statistical distributions to model real-world data\n",
    "‚úÖ Implement Object-Oriented Programming principles\n",
    "‚úÖ Create reproducible data pipelines with proper error handling\n",
    "‚úÖ Generate production-ready datasets for FinTech applications\n",
    "\n",
    "Happy coding! üíªüìà\n",
    "\"\"\")\n",
    "\n",
    "# Optional: Quick data validation checks\n",
    "print(\"\\nüîç Running final data validation checks...\")\n",
    "\n",
    "# Check for data consistency\n",
    "validation_passed = True\n",
    "\n",
    "# Validate date ranges\n",
    "stock_dates = pd.to_datetime(all_datasets['stock_prices.csv']['Date'])\n",
    "if stock_dates.min().year != 2020 or stock_dates.max().year != 2024:\n",
    "    print(\"‚ö†Ô∏è  Stock date range validation failed\")\n",
    "    validation_passed = False\n",
    "\n",
    "# Validate OHLC consistency (High >= Low, etc.)\n",
    "stock_data = all_datasets['stock_prices.csv']\n",
    "ohlc_valid = (\n",
    "    (stock_data['High'] >= stock_data['Low']).all() and\n",
    "    (stock_data['High'] >= stock_data['Open']).all() and  \n",
    "    (stock_data['High'] >= stock_data['Close']).all() and\n",
    "    (stock_data['Low'] <= stock_data['Open']).all() and\n",
    "    (stock_data['Low'] <= stock_data['Close']).all()\n",
    ")\n",
    "\n",
    "if not ohlc_valid:\n",
    "    print(\"‚ö†Ô∏è  OHLC consistency validation failed\")\n",
    "    validation_passed = False\n",
    "    \n",
    "# Validate customer credit scores are in valid range\n",
    "customer_data = all_datasets['customer_data.csv']\n",
    "credit_valid = (\n",
    "    (customer_data['CreditScore'] >= 300).all() and\n",
    "    (customer_data['CreditScore'] <= 850).all()\n",
    ")\n",
    "\n",
    "if not credit_valid:\n",
    "    print(\"‚ö†Ô∏è  Credit score range validation failed\")\n",
    "    validation_passed = False\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"‚úÖ All validation checks passed!\")\n",
    "    print(\"üéâ Dataset is ready for production use in your FinTech projects!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Some validation checks failed - please review the data\")\n",
    "\n",
    "print(f\"\\nüìÅ All files saved in: {os.path.abspath('mock_financial_data')}\")\n",
    "print(\"üéØ Ready to begin your 11-week FinTech development journey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b52cf-d5b5-4ae7-aae1-850648e3daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Agile Sprint Integration Guide and Next Steps\n",
    "\"\"\"\n",
    "Integration with 11-Week FinTech Development Sprints\n",
    "===================================================\n",
    "\n",
    "This data generator supports all phases of your Agile FinTech project:\n",
    "\n",
    "üèÉ‚Äç‚ôÇÔ∏è SPRINT ROADMAP:\n",
    "\n",
    "Week 1 - Startup Onboarding:\n",
    "‚Ä¢ Use generated data in your project charter problem statement\n",
    "‚Ä¢ Import CSVs into PostgreSQL for SQL practice  \n",
    "‚Ä¢ Form diverse squads with complementary skills\n",
    "\n",
    "Week 2 - Data Wrangling:\n",
    "‚Ä¢ Clean and validate all generated datasets\n",
    "‚Ä¢ Practice pandas/polars operations on realistic data\n",
    "‚Ä¢ Create data quality reports and visualizations\n",
    "\n",
    "Week 3 - Classical Econometrics:\n",
    "‚Ä¢ Run OLS regressions on stock prices vs economic indicators\n",
    "‚Ä¢ Test cointegration between BTC and ETH prices\n",
    "‚Ä¢ Build CAPM models using generated returns\n",
    "\n",
    "Week 4 - Time Series Forecasting:\n",
    "‚Ä¢ Forecast stock prices using ARIMA models\n",
    "‚Ä¢ Apply Prophet to cryptocurrency data\n",
    "‚Ä¢ Compare forecasting performance across assets\n",
    "\n",
    "Week 5 - ML & Regularization:\n",
    "‚Ä¢ Use customer data for credit scoring models\n",
    "‚Ä¢ Apply Ridge/Lasso to portfolio optimization\n",
    "‚Ä¢ Implement prompt-assisted feature engineering\n",
    "\n",
    "Week 6 - Tree Ensembles:\n",
    "‚Ä¢ Build fraud detection models with customer transaction data\n",
    "‚Ä¢ Use Random Forest for portfolio risk classification\n",
    "‚Ä¢ Apply SHAP for model interpretability\n",
    "\n",
    "Week 7 - Dimensionality Reduction:\n",
    "‚Ä¢ Apply PCA to economic indicators\n",
    "‚Ä¢ Cluster customers by behavior patterns\n",
    "‚Ä¢ Factor analysis of portfolio returns\n",
    "\n",
    "Week 8 - Deep Learning:\n",
    "‚Ä¢ LSTM forecasting of crypto prices (24/7 data advantage)\n",
    "‚Ä¢ RNN for sequential customer behavior modeling\n",
    "‚Ä¢ Neural networks for portfolio optimization\n",
    "\n",
    "Week 9 - Portfolio Analytics:\n",
    "‚Ä¢ Backtest trading strategies using generated price data\n",
    "‚Ä¢ Risk-parity portfolio construction\n",
    "‚Ä¢ Performance attribution analysis\n",
    "\n",
    "Week 10 - Model Audit:\n",
    "‚Ä¢ Cross-validation on all generated datasets\n",
    "‚Ä¢ Stress testing with economic scenario analysis\n",
    "‚Ä¢ Model validation frameworks\n",
    "\n",
    "Week 11 - Productization:\n",
    "‚Ä¢ Deploy models as FastAPI services\n",
    "‚Ä¢ Create dashboards using generated data\n",
    "‚Ä¢ Final board presentation with real insights\n",
    "\n",
    "üîß TECHNICAL INTEGRATION TIPS:\n",
    "\"\"\"\n",
    "\n",
    "# Helper functions for ongoing sprint work\n",
    "def quick_data_loader(dataset_name: str, data_dir: str = 'mock_financial_data') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Quick loader for sprint work - use in subsequent notebooks.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: One of 'stocks', 'crypto', 'economic', 'portfolio', 'customer'\n",
    "        data_dir: Directory containing the CSV files\n",
    "        \n",
    "    Returns:\n",
    "        Loaded and basic-processed DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    filename_map = {\n",
    "        'stocks': 'stock_prices.csv',\n",
    "        'crypto': 'crypto_prices.csv', \n",
    "        'economic': 'economic_indicators.csv',\n",
    "        'portfolio': 'portfolio_data.csv',\n",
    "        'customer': 'customer_data.csv'\n",
    "    }\n",
    "    \n",
    "    if dataset_name not in filename_map:\n",
    "        raise ValueError(f\"Dataset must be one of: {list(filename_map.keys())}\")\n",
    "    \n",
    "    filepath = os.path.join(data_dir, filename_map[dataset_name])\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "    \n",
    "    # Load with appropriate parsing\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Apply basic preprocessing based on dataset type\n",
    "    if dataset_name in ['stocks', 'crypto']:\n",
    "        # Parse date columns\n",
    "        date_col = 'Date' if dataset_name == 'stocks' else 'Timestamp'\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "        df = df.sort_values([date_col, 'Symbol']).reset_index(drop=True)\n",
    "        \n",
    "    elif dataset_name == 'economic':\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values(['Date', 'Indicator']).reset_index(drop=True)\n",
    "        \n",
    "    elif dataset_name == 'portfolio':\n",
    "        df['Date'] = pd.to_datetime(df['Date'])  \n",
    "        df = df.sort_values(['Date', 'PortfolioID']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {dataset_name} data: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def create_sprint_workspace(sprint_number: int, sprint_name: str):\n",
    "    \"\"\"\n",
    "    Create organized workspace for each sprint.\n",
    "    \n",
    "    Args:\n",
    "        sprint_number: Week number (1-11)\n",
    "        sprint_name: Descriptive name for the sprint\n",
    "    \"\"\"\n",
    "    \n",
    "    workspace_dir = f\"sprint_{sprint_number:02d}_{sprint_name.lower().replace(' ', '_')}\"\n",
    "    \n",
    "    # Create directory structure\n",
    "    dirs_to_create = [\n",
    "        workspace_dir,\n",
    "        os.path.join(workspace_dir, 'notebooks'),\n",
    "        os.path.join(workspace_dir, 'data'),\n",
    "        os.path.join(workspace_dir, 'models'),\n",
    "        os.path.join(workspace_dir, 'reports'),\n",
    "        os.path.join(workspace_dir, 'src')\n",
    "    ]\n",
    "    \n",
    "    for dir_path in dirs_to_create:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Create template files\n",
    "    readme_content = f\"\"\"# Sprint {sprint_number}: {sprint_name}\n",
    "\n",
    "## Objectives\n",
    "- [Add your sprint objectives here]\n",
    "\n",
    "## Datasets Used\n",
    "- Stock prices: Daily OHLCV data\n",
    "- Crypto prices: 6-hourly data\n",
    "- Economic indicators: Monthly data\n",
    "- Portfolio data: Monthly holdings\n",
    "- Customer data: Demographics and behavior\n",
    "\n",
    "## Deliverables\n",
    "- [ ] Jupyter notebook with analysis\n",
    "- [ ] Data quality report\n",
    "- [ ] Model/analysis results\n",
    "- [ ] Brief presentation slides\n",
    "\n",
    "## Team Members\n",
    "- Product Owner: [Name]\n",
    "- Scrum Master: [Name] \n",
    "- Developers: [Names]\n",
    "\n",
    "## Sprint Retrospective\n",
    "- What went well:\n",
    "- What could be improved:\n",
    "- Action items for next sprint:\n",
    "\"\"\"\n",
    "    \n",
    "    with open(os.path.join(workspace_dir, 'README.md'), 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(f\"üìÅ Created sprint workspace: {workspace_dir}\")\n",
    "    print(f\"üìã Template README.md created\")\n",
    "    print(f\"üéØ Ready for Sprint {sprint_number}: {sprint_name}\")\n",
    "\n",
    "def generate_data_dictionary():\n",
    "    \"\"\"Generate comprehensive data dictionary for all datasets.\"\"\"\n",
    "    \n",
    "    data_dict = {\n",
    "        'stock_prices.csv': {\n",
    "            'description': 'Daily stock price data in OHLCV format',\n",
    "            'columns': {\n",
    "                'Date': 'Trading date (business days only)',\n",
    "                'Symbol': 'Stock ticker symbol',\n",
    "                'Open': 'Opening price (USD)',\n",
    "                'High': 'Highest price during trading day (USD)',\n",
    "                'Low': 'Lowest price during trading day (USD)',\n",
    "                'Close': 'Closing price (USD)',\n",
    "                'Volume': 'Number of shares traded'\n",
    "            },\n",
    "            'frequency': 'Daily (business days)',\n",
    "            'date_range': '2020-01-01 to 2024-12-31'\n",
    "        },\n",
    "        \n",
    "        'crypto_prices.csv': {\n",
    "            'description': '6-hourly cryptocurrency price data',\n",
    "            'columns': {\n",
    "                'Timestamp': 'Trading timestamp (6-hour intervals)',\n",
    "                'Symbol': 'Cryptocurrency symbol',\n",
    "                'Open': 'Opening price (USD)',\n",
    "                'High': 'Highest price during 6-hour period (USD)',\n",
    "                'Low': 'Lowest price during 6-hour period (USD)',\n",
    "                'Close': 'Closing price (USD)',\n",
    "                'Volume': 'Number of units traded'\n",
    "            },\n",
    "            'frequency': '6-hourly (24/7 trading)',\n",
    "            'date_range': '2020-01-01 to 2024-12-31'\n",
    "        },\n",
    "        \n",
    "        'economic_indicators.csv': {\n",
    "            'description': 'Monthly macroeconomic indicators',\n",
    "            'columns': {\n",
    "                'Date': 'Month-end date',\n",
    "                'Indicator': 'Economic indicator name',\n",
    "                'Value': 'Indicator value (units vary by indicator)'\n",
    "            },\n",
    "            'frequency': 'Monthly',\n",
    "            'indicators': [\n",
    "                'GDP_GROWTH: GDP growth rate (%)',\n",
    "                'INFLATION_RATE: CPI inflation rate (%)',\n",
    "                'UNEMPLOYMENT_RATE: Unemployment rate (%)',\n",
    "                'INTEREST_RATE: Federal funds rate (%)',\n",
    "                'CONSUMER_CONFIDENCE: Consumer confidence index',\n",
    "                'RETAIL_SALES: Retail sales growth (%)',\n",
    "                'INDUSTRIAL_PRODUCTION: Industrial production growth (%)',\n",
    "                'HOUSING_STARTS: Housing starts (thousands of units)',\n",
    "                'TRADE_BALANCE: Trade balance (million USD)',\n",
    "                'MONEY_SUPPLY: M2 money supply (billion USD)'\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        'portfolio_data.csv': {\n",
    "            'description': 'Monthly portfolio holdings and performance',\n",
    "            'columns': {\n",
    "                'Date': 'Month-end date',\n",
    "                'PortfolioID': 'Unique portfolio identifier',\n",
    "                'RiskLevel': 'Risk profile (Conservative/Moderate/Aggressive)',\n",
    "                'TotalValue': 'Total portfolio value (USD)',\n",
    "                'StockWeight': 'Percentage allocated to stocks (0-1)',\n",
    "                'BondWeight': 'Percentage allocated to bonds (0-1)',\n",
    "                'CashWeight': 'Percentage held in cash (0-1)',\n",
    "                'MonthlyReturn': 'Monthly return rate (decimal)'\n",
    "            },\n",
    "            'frequency': 'Monthly',\n",
    "            'portfolios': 100\n",
    "        },\n",
    "        \n",
    "        'customer_data.csv': {\n",
    "            'description': 'Customer demographics and account information',\n",
    "            'columns': {\n",
    "                'CustomerID': 'Unique customer identifier',\n",
    "                'Age': 'Customer age (years)',\n",
    "                'Income': 'Annual income (USD)',\n",
    "                'CreditScore': 'FICO credit score (300-850)',\n",
    "                'AccountAgeDays': 'Days since account opening',\n",
    "                'AccountBalance': 'Current account balance (USD)',\n",
    "                'MonthlyTransactions': 'Average monthly transaction count',\n",
    "                'AvgTransactionAmount': 'Average transaction amount (USD)',\n",
    "                'NumProducts': 'Number of financial products held',\n",
    "                'HasLoan': 'Boolean - customer has active loan',\n",
    "                'RiskSegment': 'Risk classification (High/Medium/Low)'\n",
    "            },\n",
    "            'frequency': 'Cross-sectional (one record per customer)',\n",
    "            'customers': 10000\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save data dictionary as JSON\n",
    "    import json\n",
    "    with open('mock_financial_data/data_dictionary.json', 'w') as f:\n",
    "        json.dump(data_dict, f, indent=2)\n",
    "    \n",
    "    print(\"üìñ Data dictionary created: mock_financial_data/data_dictionary.json\")\n",
    "    return data_dict\n",
    "\n",
    "# Demo the helper functions\n",
    "print(\"üõ†Ô∏è SPRINT INTEGRATION TOOLS READY!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the quick loader\n",
    "print(\"\\nüìä Testing quick data loader...\")\n",
    "try:\n",
    "    sample_stocks = quick_data_loader('stocks')\n",
    "    print(f\"   Sample stock data loaded: {sample_stocks.shape}\")\n",
    "    print(f\"   Date range: {sample_stocks['Date'].min()} to {sample_stocks['Date'].max()}\")\n",
    "    print(f\"   Symbols: {sorted(sample_stocks['Symbol'].unique())}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Data not yet generated: {e}\")\n",
    "\n",
    "# Create sample sprint workspace\n",
    "print(\"\\nüìÅ Creating sample sprint workspace...\")\n",
    "create_sprint_workspace(1, \"Startup Onboarding\")\n",
    "\n",
    "# Generate data dictionary\n",
    "print(\"\\nüìñ Generating data dictionary...\")\n",
    "data_dict = generate_data_dictionary()\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ READY FOR AGILE DEVELOPMENT!\n",
    "\n",
    "Your FinTech data pipeline is complete and ready to support all 11 sprints.\n",
    "\n",
    "Key Integration Points:\n",
    "‚úÖ Realistic financial data across all major asset classes\n",
    "‚úÖ Production-ready CSV formats for easy import\n",
    "‚úÖ Helper functions for sprint-specific data loading\n",
    "‚úÖ Workspace templates for organized development\n",
    "‚úÖ Comprehensive data dictionary for reference\n",
    "\n",
    "Next Actions:\n",
    "1. üìã Complete your project charter using this data\n",
    "2. üë• Form your cross-functional squad\n",
    "3. üéØ Set up JIRA board with Sprint 1 tasks\n",
    "4. üíæ Import data into PostgreSQL database\n",
    "5. üìà Begin exploratory data analysis\n",
    "\n",
    "Good luck with your FinTech development journey! üöÄ\n",
    "\"\"\")\n",
    "\n",
    "# Final memory cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"\\nüîß Memory cleanup completed - ready for next sprint!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
